# Fundamentals

  + Theoretical background of data visualization

**1. Survey of Popular Data Visualization Tools**

Due to the rise of big data analytics, there has been an increased need for data visualization tools to help understand the data. Besides Tableau, there are several other software tools one can use for data visualization like Sisense, Plotly, FusionCharts, Highcharts, Datawrapper, and Qlikview. This article is from forbes and has a brief, clear introduction about these 7 powerful software options for data visualization. This could be helpful for future reference because for different purposes I may need to use different tools. Each option has its advantages and disadvantages and this article helps highlight them.

Tableau is the most popular of the group and has many users. It is simple to use, making it easy to learn and can handle large datasets. Tableau can handle big data thanks to integration with database handling applications such as MySQL, Hadoop, and Amazon AWS.

Qlikview is the main competitor to Tableau and is also quite popular.  Qlikview is customizable and has a wide range of features which can be a double-edged sword. These features take more time to learn and get acquianted with. However, once one gets past the learning curve, they have a powerful tool at their disposal.

The distinctive aspect of FusionCharts is that graphics do not have to be created from scratch. Users can start with a template and insert their own data from their project.

Highcharts proudly claims to be used by 72% of the 100 biggest companies in the world. It is a simple tool that does not require specialized training and quickly generates the desired output. Unlike some tools, Highcharts focuses on cross-browser support, allowing for greater access and use.

Datawrapper is making a name for itself in the media industry. It has a simple user interface making it easy to generate charts and embed into reports.

Plotly can create more sophisticated visuals thanks to integration with programming languages such as Python and R. The danger is creating something more complicated than necessary. The whole point of data visualization is to quickly and clearly convey information.

Sisense can bring together multiple sources of data for easier access. It can even work with large datasets. Sisense makes it easy to share finished products across departments, ensuring everyone can get the information they need.

https://www.forbes.com/sites/bernardmarr/2017/07/20/the-7-best-data-visualization-tools-in-2017/#3a12b8ea6c30

  
**2. Practitioners Guide to Best Practices in Data Visualization**
  
**Reference**
    Jeffrey D. Camm, Michael J. Fry, Jeffrey Shaffer (2017) A Practitioner’s Guide to Best Practices in Data 
    Visualization.Interfaces 47(6):473-488. https://doi.org/10.1287/inte.2017.0916
  
  These are the best practices of data visualization. Anticipate in advance what kind of questions the viewers will ask and
  then focus your visualization with respect to those questions. 
  
  Brain processes stimuli from our environment to process what is important in 2 ways – unconscious (System 1 represents
  uncontrolled functions such as facial expressions, reactions) and conscious (System 2 – represents controlled function
  such as solving math problems). Data Visualization leverage attributes of System -1 which has can have quick and correct
  impact in a most efficient manner. The three best practices of data visualization are as follows: 

** 1. Design and layout matter **
      The design and layout should facilitate ease of understanding to convey your message to the viewer.
** 2.	Avoid Clutter **
      Keep it simple. To implement this always keep into account the data-ink ratio – the ratio of ink required to convey
      the intended meaning to the total amount of ink used in the table or chart should be as close to 1 as possible. That
      means, avoid ink which do not add any information.
** 3.	Use color purposely and effectively **
      Use of color may be prettier and attractive but can be distractive too. Thus, color should be used only if it assists
      in conveying your message. 
      The above three principles are illustrated with the help of scenarios and examples which helps to comprehend the topic
      in more meaningful and practical way in the article. It also gives various advantages of using the above 
      principles.And the above best practices could be applied to all the 3 types of analytics: descriptive, predictive and 
      prescriptive. 


**3. Guide for Developing Dashboards**

https://www.klipfolio.com/blog/intuitive-dashboard-design
    Three rules to follow in order to develop intuitive dashboards:
    
    1. the dashboard should read left to right
    2. group related information together
    3. find relationships between seemingly unrelated areas and display visuals together to show the relationship.
    
    Often a designer can become too concerned with coming up with a visual that is too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to effective presentation of the data. 
    
    Because we read from top to bottom and left to right, a reader's eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard as dashboards are often used as a quick convenient way to look up data.
    
    Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need.
    
    Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data is trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together.
    
  
**4. Fundamental Components of Design**
          
          Artists use balance, emphasis, movement, pattern, repetition, proportion, rhythm, variety, and 
          unity as the design foundation of any work. If you want to take your data visualization from an 
          everyday dashboard to a compelling data story, incorporate the 9 principles of design from graphic 
          designer Melissa Anderson's article:
                  https://www.idashboards.com/blog/2017/07/26/data-visualization-and-the-9-fundamental-design-principles/
  
          Balance doesn't mean that each side of the visualization needs perfect symmetry, but it is important to have the
          elements of the dashboard/visualiaztion distributed evenly. And it important to remember the non-data elements, such
          as a logo, title, caption, etc., that can affect the balance of the display. 
          
          Another closely related component to balance is variety which could seem counter to balance, but when done
          correctly, variety can help increase the recall of information. However if overdone, too much variety can feel
          cluttered and blur together the images and data in the mind of the viewer.
          
          Arguably the most critical of the components is proportion. Proportion can be subtle but it can go a long way to
          enhancing a viewer's experience and understanding of the data. The danger of proportion though is that it can be
          easy to deceive people subconsciously. Naturally images will have a greater impact on how our brains perceive the
          dashboard or visualization. For example, someone can change the scale of a graph or images to inflate their results
          and even if they write the numbers next to it, the shortcut many people will take is to interpret the data based on
          the image. This is why it is important we take care to accurately reflect proportion in our data visualization and 
          remain critical of how others use proportion in their visualization.
          
          Emphasis was the component that I most related to when reading through the nine principles of design in this
          article. From prior experience with art through photography I understand it is key to be concious of what I am 
          drawing the viewers attention to in my art. When thinking about the art design of data visualization it is also very
          important to remain keen on the main point of your story and how the entire visualization is either drawing the
          viewer to that point of emphasis or how they are being distracted or drawn elsewhere.
          
    
**5. A Brief History of Data Visualization **

Michael Friendly,2006,A Brief History of Data Visualization,York University.http://www.datavis.ca/papers/hbook.pdf
   
    The only new thing in the world is the history you don’t know. — Harry S Truman
    
    This paper provides an overview of the intellectual history of data visualization from medieval to modern times,
    describing and illustrating some significant advances along the way.
    
   1. Data Visualization: modern product?
    
       It is common to think of statistical graphics and data visualization as relatively modern developments in statistics. 
       In fact, the graphic representation of quantitative information has deep roots.These roots reach into the histories of 
       the earliest map-making and visual depiction, and later into thematic cartography, statistics and statistical graphics,
       medicine, and other fields.
       
       Developments in technologies (printing, reproduction) mathematical theory and practice, and empirical observation and  
       recording, enabled the wider use of graphics and new advances in form and content.

  2. Milestones Tour
    
       2.1 Pre-17th Century: Early maps and diagrams
          
          The earliest seeds of visualization arose in geometric diagrams, in tables of the positions of stars and other
          celestial bodies, and in the making of maps to aid in navigation and exploration. 
       
       2.2 1600-1699: Measurement and theory
       
          Among the most important problems of the 17th century were those concerned with physical measurement— of time,
          distance,and space— for astronomy, surveying, map making, navigation and territorial expansion. This century also
          saw great new growth in theory and the dawnof practical application.
       
       2.3 1700-1799: New graphic forms
       
          With some rudiments of statistical theory, data of interest and importance, and the idea of graphic representation
          at least somewhat established, the 18th century witnessed the expansion of these aspects to new domains and new
          graphic forms. 
          
       2.4 1800-1850: Beginnings of modern graphics  
       
          With the fertilization provided by the previous innovations of design and technique, the first half of the 19th
          century witnessed explosive growth in statistical graphics and thematic mapping, at a rate which would not be
          equalled until modern times.
       
       2.5 1850–1900: The Golden Age of statistical graphics
       
          By the mid-1800s, all the conditions for the rapid growth of visualization had been established— a “perfect storm”
          for data graphics. Official state statistical offices were established throughout Europe, in recognition of the
          growing importance of numerical information for social planning,industrialization, commerce, and transportation. 
          
           2.5.1 Escaping flatland
           2.5.2 Graphical innovations
           2.5.3 Galton’s contributions
           2.5.4 Statistical Atlases
           
       2.6 1900-1950: The modern dark ages
       
          If the late 1800s were the “golden age” of statistical graphics and thematic cartography, the early 1900s can be
          called the “modern dark ages” of visualization. There were few graphical innovations, and, by the mid-1930s, the
          enthusiasm for visualization which characterized the late 1800s had been supplanted by the rise of quantification
          and formal, often statistical, models in the social sciences.
       
       2.7 1950–1975: Re-birth of data visualization
       
          Still under the influence of the formal and numerical zeitgeist from the mid-1930s on, data visualization began to
          rise from dormancy in the mid 1960s. 
          
       2.8 1975–present: High-D, interactive and dynamic data visualization
       
          During the last quarter of the 20th century data visualization has blossomed into a mature, vibrant and multi
          disciplinary research area, as may be seen in this Handbook, and software tools for a wide range of visualization
          methods and data types are available for every desktop computer.
   

**6. Contemporary Research Results**
  
  + Next Steps for Data Visualization Research
  + references: https://medium.com/@uwdata/next-steps-for-data-visualization-research-3ef5e1a5e349
  
    With the development, studies and new tools applied in data visualization, more people understand it matters. But given its youth and interdisciplinary nature, research methods and training in the field of data visualization are still developing. So, we asked ourselves: what steps might help accelerate the development of the field? Based on a group brainstorm and discussion, this article shares some of the proposals of ongoing discussion and experiment with new approaches:
  
  1. Adapting the Publication and Review Process
  + As the article states, "both 'good' and 'bad' reviews could serve as valuable guides", so providing reviewer guidelines could be helpful for fledgling practitioners in the field.
     
  2. Promoting Discussion and Accretion
  + Discussion of research papers actively occurs at conferences, on social media, and within research groups. Much of this discussion is either ephemeral or non-public. So ongoing discussion might explicitly transition to the online forum. 
     
  3. Research Methods Training
  + Developing a core curriculum for data visualization research might help both cases, guiding students and instructors alike. For example, recognizing that empirical methods were critical to multiple areas of computer science, Stanford CS faculty organized a new course on Designing Computer Science Experiments(http://sing.stanford.edu/cs303-sp11/). Also, online resources could be reinforced with a catalog of learning resources, ranging from tutorials and self-guided study to online courses. Useful examples include Jake Wobbrock’s Practical Statistics for HCI and Pierre Dragicevic’s resources for reforming statistical practice.



**7. Pick the Right Chart Type!**

  Data divusalization is combining the art and science. As for the art, we can say there are no correct answers for doing the visualization. There are many ways to present the data. However, how to making sense of facts, numbers and measurement for better understanding is still have a logical path to follow. 
  
  To determine which kind of chart is hard for those people new to data visulization. Most people learn it by refering some other people's work without understanding the logic behind. So they don't have the theory in their mind to make the judgement. Here , I will introduce some guidance to choose the charts. 
  
  When we about to choose the type of chart, we need to answer some questions.
  - How many features would you like to show in a chart?
  - how many data points do you want to display for each variable? 
  - Will you display time serious data or among items or groups. 
  
  After answered this question, you shoul able to get a better imagenation of your ideal graph. The simple guidance for using different type of chart is line charts for tracking trends over time, bar charts to compare quantities, scatter plots for joint variation of two data items, bubble charts showing joint variation of three data items, and pie charts to compare parts of a whole.
  
  Let's review the most commonly used chart types and expalin what circumstance should better use typical chart and the pros and conts of each type of chart. Before introduce differnt types of charts, you can use the following website to familiar with different types of charts. 
  [The Data Visualisation Catalogue](https://datavizcatalogue.com/) 
  
  ## Type 1 Column Charts. 
  This should be the most popular chart type. This chart is good to do comparison between different values when specific values are important. TBD 

  
  Still have hard time to choose? There are many resources on line can help you do the decision. For example, Dr. Andre Abela create a chart selection diagram that is helpful to pick the right chart depends on the data type. The link of website is  http://extremepresentation.typepad.com/blog/2015/01/announcing-the-slide-chooser.html

Reference:
Data Visualization – How to Pick the Right Chart Type? , By Jānis Gulbis https://eazybi.com/blog/data_visualization_and_chart_types/

Data Visualization Best Practices by melindasantos | Sep 19, 2017
http://paristech.com/blog/data-visualization-best-practices/

http://paristech.com/blog/data-visualization-best-practices/
http://extremepresentation.typepad.com/blog/2015/01/announcing-the-slide-chooser.html

 Misleading graphs:
  Misleading graphs or distorted graphs, are graphs created which skews the data, intentionally or unintentionally, resulting in a representation of incorrect conclusions.
There are some ways in which distorted graphs can be created:
1.	Improper scaling of y axis: This is one of the classic misleading graphs. Instead of scale starting from zero or a baseline, y axis is scaled conveniently to highlight the differences among bins.
2.	Improper labelling of graphs:  Lack of labels make the graph hard to interpret for the reader and lead to wrong conclusions.
3.	Paired graphs on different scale: It is not a fair comparison if two elements are plotted side-by-side, on a different scale and compared. This makes one graph look better than the other, even when it is not.
4.	Dual axis with different scales: If we are plotting two elements on the same graph with different scales, even if the axes are properly labeled, it is assumed that both axes are on the same scale.
5.	Incomplete data: Short-term graphs are made to manipulate the trend, which will not be seen otherwise. Time-series data are cut intentionally to just show a trend within a particular period to create a more favorable visual impression.

Please find the references below.
http://hypsypops.com/axes-evil-lie-graphs/
http://www.statisticshowto.com/misleading-graphs/


**8. Definions of Date Deception and Graphic Integrity**
  
  **Reference** 
  (1) Pandey, A. V., Rall, K., Satterthwaite, M. L., Nov, O., & Bertini, E. (2015). How deceptive are deceptive visualizations? An empirical analysis of common distortion techniques. In CHI 2015 - Proceedings of the 33rd Annual CHI Conference on Human Factors in Computing Systems: Crossings (Vol. 2015-April, pp. 1469-1478). Association for Computing Machinery. DOI: 10.1145/2702123.2702608
  (2) Tufte, E. R., and Graves-Morris, P. The visual display of quantitative information, vol. 2. Graphics press Cheshire, CT, 1983.

Data visualization becomes more and more pupular to communicate and support arguments nowdays. There are lots of great resources online to create and design amazing data products, in the same time, there are some poorly-designed misleading deceptive data visualizations.

So what does **data deception** mean? 
Data deception, defined by School of Law at the New York University, as “a graphical depiction of information, designed with or without an intent to deceive, that may create a belief about the message and/or its components, which varies from the actual message.”

In reality, decades ago, Edward Tufte already introduced the concept of graphical intergrity in his book and presented six principles of graphic integrity. Here are the principles from book:

1. The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities measured.

2. Clear, detailed, and thorough labeling should be used to defeat graphical distortion and ambiguity. Write out explanations of the data on the graphic itself. Label important events in the data.

3. Show data variation, not design variation.

4. In time-series displays of money, deﬂated and standardized units of monetary measurement are nearly always better than nominal units.

5. The number of information-carrying (variable) dimensions depicted should not exceed the number of dimensions in the data.

6.Graphics must not quote data out of context.

