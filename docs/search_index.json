[
["index.html", "A Reader on Data Visualization Chapter 1 Preface 1.1 References 1.2 Images 1.3 Basic Guidelines", " A Reader on Data Visualization MSIS 2629 Spring 2019 2019-04-22 Chapter 1 Preface This is a collaborative writing project as part of the course MSIS 2629 “Data Visualization” at Santa Clara University. The purpose of the class reader is to collaboratively engage with and reflect on data visualizations, to establish a solid theoretical background, and to collect useful practices and showcases. More information on the background of this project is available in the syllabus. The following text explains how we organize ourselves. 1.1 References EVERY reference must be included in the book.bib file. This file uses the BibTeX notation (Learn how to use BibTeX here). Most literature search engines allow you to export the reference information in BibTeX. For websites we use the following minimal notation (you may add further information - usually the more the better is a good strategy): @misc{great_viz, author = {{A great visualizer}}, year = {1982}, title = {A ficticious web page title}, howpublished = {\\url{http://great_viz_org/}}, note = {Accessed: 2018-04-26} } Particularly important is the note field. Websites change frequently, so links will break. If we do this correctly, [@great_viz] will produce (visualizer 1982). 1.2 Images Images should not be loaded from external website because the links may change. Instead download a version of the image and create a reference that contains the link to the image. For example the following image is a deceptive visualization (the bars do start at zero). An Example of a deceptive visualization Source: (Halper 2012) referenced in (Andalde 2014) The citation for the image looks like this. @misc{halper_2012, author={Halper, Daniel}, year={2012}, title = {Over 100 Million Now Receiving Federal Welfare}, url={https://www.weeklystandard.com/daniel-halper/over-100-million-now-receiving-federal-welfare}, note = {Accessed: 2018-04-26} } You have probably found this image through a different website that explains the visualization. For example the following website explains some problematic aspects of this visualization: @misc{andale_2014, author={Andalde, Stephanie}, year={2014}, title = {Misleading Graphs: Real Life Examples}, url={http://www.statisticshowto.com/misleading-graphs/}, note = {Accessed: 2018-04-26} 1.3 Basic Guidelines Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2018) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["introduction.html", "Chapter 2 Introduction 2.1 What is Data Visualization? 2.2 Importance of Data Visualization 2.3 History of Data Visualization 2.4 Contemporary Visualists 2.5 How to tell stories using data visualization’ and ‘exploratory data visualization’ theory example 2.6 Additional Resources for Aspiring Data Visualists", " Chapter 2 Introduction 2.1 What is Data Visualization? Data visualization is a graphic representation that expresses the significance of data. It reveals insights and patterns that are not immediately visible in the raw data. It is an art through which information, numbers, and measurements can be made more understandable. According to (Friedman 2008): The primary goal of data visualization is to communicate information clearly and effectively through graphical means. It does not mean that data visualization needs to look boring to be functional or extremely sophisticated to look beautiful. To convey ideas effectively, both aesthetic form and functionality need to go hand in hand, providing insights into a rather sparse and complex data set by communicating its key-aspects more intuitively. The main goal of data visualization is to communicate information clearly and effectively through graphical means. It doesn’t mean that data visualization needs to look boring to be functional or extremely sophisticated to look beautiful. To convey ideas effectively, both aesthetic form and functionality need to go hand in hand, providing insights into a rather sparse and complex data set by communicating its key-aspects in a more intuitive way. “Data is the new oil” may be a cliche, but it is true. Like oil, data in its raw, unrefined form is pretty worthless. To unlock its value, data needs to be refined, analyzed and understood (Disney 2017). More and more organizations are seeing potential in their data connections, but how do you allow non-experts to analyze data at scale and extract potentially complex insights? One answer is through interactive graph visualization. Information visualization is the art of representing data so that it is easy to understand and manipulate, thus making the information useful. Visualization can make sense of information by helping to find relationships in the data and support (or disproving) ideas about the data. (???) shares some examples and common uses of information visualization, such as: Benefit Example Presentation: to explain or persuade Source: (“Best Real Estate Investing Example Powerpoint Presentation Examples,PPT:SG-14716000770769” 2019) Exploratory Analysis: to identify relationships or unusual cases in the data Source: (smith 2019) Confirmatory Analysis: to confirm our understanding and analysis of the data Source: (Aarons 2014) Why data visualization is such a powerful tool: It is intuitive presenting a graph as a node-link structure instantly makes sense, even to people who have never worked with graphs before. It is fast because our brains are great at identifying patterns, but only when data is presented in a tangible format. Armed with visualization, we can spot trends and outliers very effectively. It is flexible. The world is densely connected, so as long as there is an interesting relationship in your data somewhere, you will find value in graph visualization. It is insightful. Exploring graph data interactively allows users to gain more in-depth knowledge, understand the context and ask more questions, compared to static visualization or raw data. 2.2 Importance of Data Visualization Pittenturf explains basic criteria that a data visualization should satisfy to be effective (Pittenturf 2018): Criteria Description Informative The visualization should be able to convey the desired information from the data to the reader. Efficient The visualization should not be ambiguous. Appealing The visualization should be captivating and visually pleasing. Interactive and Predictive (Optional) The visualizations can contain variables and filters with which the users may interact to predict results of different scenarios. Pittenturf goes on to give various day-to-day examples where visualization gives a better understanding of the data. One straightforward example used by Pittenturf is that of an energy bill. Pittenturf states that when we, as consumers, receive an energy bill, we usually look at the graph in the bill first before proceeding to read the text in the bill. Pittenturf states that consumers are more likely to analyze and understand the visualizations before reading further along. The article ends with Pittenturf emphasizing the importance of data visualizations in our businesses as well as in our daily lives. It gives a simple, short and crisp understanding of what data visualization is and how it is relevant to everyone. Data visualization is an aid to get a better understanding of the complex insights that any business data provides. Most of the data used by the businesses are highly unstructured, and these businesses can get a better understanding of their businesses by visualizing their data. Another early adopter of graph visualization techniques was the financial services industry. Fraud detection is about finding unusual connections between accounts, transactions, insurance policies, devices, etc. There is great value in visualizing that data as a graph. Known fraud detection is primarily automated with rule scoring and pattern matching. Visualization lets you review edge-cases and outliers more quickly. Speed is important because sometimes analysts only have seconds to approve or deny a transaction. In those cases, visualizations are simple, small and with limited interaction. To get a clear overview quickly, analysts need effective layouts. Other functionalities, like expanding and filtering help fraud analysts to see context on demand. Three things are consistent across both graph visualization use cases: They involve highly connected data (apparently). That highly connected data conceals risk insight. That insight is needed to power quick and confident decision making. When connected data insight is critical, only interactive and robust visualization tools are up to the task. 2.2.1 Increased Value for Increasing Volume of Data The enormous volume of data available to companies, governments and people today means there is a vast (and growing) need for data to be presented so that it delivers value. From business decision making to route navigation, data visualization provides a simple, user-friendly approach to understanding data and making faster, better decisions. In his article on the importance of data visualization to businesses, Chris Pittenturf uses the example of an energy bill to explain the impact of data visualization: before we even read the text of the bill, we look at the graph first (Pittenturf 2018). This simple example demonstrates that data visualization is in every part of our daily lives and that we are more likely to analyze and understand the visualizations before reading further along. Pittenturf further explains most data used by businesses are highly unstructured, so visualization provides a better understanding of the complex insights coming from this information. 2.2.2 Understanding Concepts that are Difficult to Contextualize In his TED talk, David McCandless gives an example of how expenditures or valuations of enormous amounts of money are represented in the billion dollar-o-gram by color-coded, relatively-sized boxes. This allows the synthesis of a breadth of information to deliver in a small, easily-digestible and aesthetically pleasing way. Visuals serve as a sort of map for a vast landscape of information—they direct reader’s eyes to the relevant places and details. Moreover, the eye, as McCandless notes, is uniquely suited to our senses to process large amounts of information and detect patterns (McCandless 2010). (The billion dollar-o-gram is exceptionally readable and rather pretty, but it seems a bit dubious to compare the predicted Iraq War cost to the “mushroomed” actual cost of Iraq and Afghanistan wars since its purpose seems only to conflate two wars for dramatic effect.) McCandless also postulates that we all have a latent “design literacy” that is being developed every day as we continuously bombard with visuals, and that our minds and our eyes are taking in this information and processing it so that we all have an intuitive sense of design, and have actually begun to demand a visual aspect to our information. This is an interesting perspective since everyone does seem to have a sense of visual aspects of space, color, etc. Of course, the time-honored adage tells us that beauty is in the eye of the beholder, so while it might be whimsical to claim that we are all designers, there is still great value in learning formal principles of design (McCandless 2010). In his article on the importance of data visualization to businesses, Chris Pittenturf uses the example of an energy bill to explain the impact of data visualization: before we even read the text of the bill, we look at the graph first (Pittenturf 2018). This simple example demonstrates that data visualization is in every part of our daily lives and that we are more likely to analyze and understand the visualizations before reading further along. Pittenturf further explains most data used by businesses are highly unstructured, so visualization provides a better understanding of the complex insights coming from this information. 2.2.3 Revealing Small and Interesting Patterns It can reveal interesting small patterns and make you a “data detective.” Beyond its ability to make information from several different sources and in large amounts easily understandable, data visualization can also reveal smaller interesting patterns, allowing us to play the “data detective” as McCandless calls it. In other words, as we have already discussed, data visualization can not only be handy in a declarative manner but can also be used as an exploratory tool (McCandless 2010). 2.2.4 Easier Decision-making in Healthcare Today, data visualization solutions can be found everywhere in healthcare systems from hospital operations monitoring and patient profiling to demand projection and capacity planning (Healthcare 2017). Healthcare service providers are increasing their efforts to investigate different visual and interactive methods in creating and examining large graphs, charts, interactive visualizations, and 2D/3D visualization of discrete event simulation (DES) to comprehend complex and large datasets, recognize connections and trends, model and simulate healthcare events, and communicate and interpret the findings. Expected results include more efficient and effective clinical performance monitoring and improvement, patient flow modeling and management, better patient care quality, security and effectiveness, better support for clinical costing and resource coordination, better-planned development and competitive advantage. Traditional visualization strategies often require significant processing time, which restrains high-throughput analysis. Interactive visualization frameworks maintain a closed loop between the user and the system and, thus, need to be very fast. Building such a framework requires the development of new visualization methods, and there exists the need to design new and useful interaction techniques which are being developed by researchers. Informatics for Integrating Biology and the Bedside i2b2, an initiative sponsored by the NIH Roadmap National Centers for Biomedical Computing is another such program that provides a query tool that supplies aggregate counts and fundamental analyses of patient populations from Clinical Data Warehouses (CDWs). i2b2 (i2b2 to Tableau) is useful in estimating patient cohort sizes and has an extendable design where modules with additional features can be developed. Other tools such as R and Python are also helping healthcare a lot. Health informatics databases and networks have amplified benefits with information visualization as it dramatically expands the capacity of patients, clinicians, and public health policymakers to make better decisions. 2.2.5 Law Enforcement and Fraud Detection The police have been using graph visualization, or link analysis as it is commonly known for decades to join the dots in investigations. What has changed is the use of technology to make joining the dots a more automated and scalable process. A failure to analyze the bigger, joined-up picture was cited as a shortcoming of the intelligence services after the 9/11 terror attacks. In the years that followed, law enforcement and security agencies drove graph visualization forward. New approaches and technologies were explicitly created for large-scale data analysis of communications records, open source intelligence (OSINT), and police databases. Lawful interception, the legally mandated interception of personal communications data, provided vast volumes of data on criminal and terrorist activity. Paired with social network analysis, graph visualization techniques allowed non-specialized staff to explore the data and uncover important insight. 2.2.6 Design and Data Literacy McCandless postulates that we all have a latent “design literacy” that is being developed every day as we are constantly bombarded with visuals, and that our minds and our eyes are taking in this information and processing it so that we all have an intuitive sense of design, and have actually begun to demand a visual aspect to our information. This is an interesting perspective, since everyone does seem to have a sense of visual aspects like space, color, etc. Of course, the time-honored adage tells us that beauty is in the eye of the beholder, so while it might be whimsical to claim that we are all designers, there is still great value in learning formal principles of design (McCandless 2010). 2.3 History of Data Visualization “The only new thing in the world is the history you do not know.” Harry S Truman 2.3.1 A Brief history of Data Visualization Given the recent explosion in data availability and visualization tools, it would be natural to assume that statistical graphics and data visualizations are relatively modern developments. However, data visualization is not a modern product it has developed over time to incorporate the tools we use today and the trends we foresee. The graphic representation of quantitative information has deep roots that reach into the histories of the earliest map-making and visual depictions, and up to thematic cartography, statistics, medicine, and other fields. Developments in technologies (printing, reproduction) mathematical theory and practice, and empirical observation and recording, and those developments enabled the broader use of graphics and new advances in form and content. It is essential to gain some understanding of the background of data visualization to help us in the proper application and execution of current visualization concepts. The following section provides an overview of the intellectual history of data visualization from medieval to recent times, as well as describes and illustrates some significant advances along the way (Friendly 2006). Time Phase Description Pre-17th Century Early Maps and Diagrams Data visualization has come a long way. Before the 17th century, data visualization already existed. Though displayed in other formats such as maps, the content is much similar to today’s visualizations, which mostly presented geologic, economic, and medical data. The earliest seeds of visualization arose in geometric diagrams, in tables of the positions of stars and other celestial bodies, and in the making of maps to aid in navigation and exploration. 1600-1699 Measurement and Theory Among the most important problems of the 17th century were those concerned with the physical measurement of time, distance, and space for astronomy, surveying, map making, navigation and territorial expansion. This century also saw considerable new growth in theory as well as the dawn of practical application. 1700-1799 New Graphic Forms With some rudiments of statistical theory, data of interest and importance, and the idea of graphic representation somewhat established the 18th century witnessed the expansion of these aspects to new domains and new graphic forms. 1800-1850 Beginnings of Modern Graphics With the foundation provided by the previous innovations of design and technique, the first half of the 19th century witnessed explosive growth in statistical graphics and thematic mapping at a rate which would not equal until modern times. 1850–1900 The Golden Age of Statistical Graphics By the mid-1800s, all the conditions for the rapid growth of visualization had generated a “perfect storm” for data graphics. Official state statistical offices were established throughout Europe, in recognition of the growing importance of numerical information for social planning, industrialization, commerce, and transportation. 1900-1950 The Modern Dark Ages If the late 1800s were the “golden age” of statistical graphics and thematic cartography, the early 1900s can be called the “modern dark ages” of visualization. There were few graphical innovations, and by the mid-1930s, the enthusiasm for visualization which characterized the late 1800s had been supplanted by the rise of quantification and formal, often statistical, models in the social sciences. 1950–1975 Rebirth of Data Visualization Still under the influence of the formal and numerical zeitgeist from the mid-1930s on, data visualization began to rise from dormancy in the mid-1960s 1975–present High-D, Interactive and Dynamic Data Visualization During the last quarter of the 20th century, data visualization has blossomed into a mature, vibrant and multidisciplinary area of research, as seen in this handbook, and software tools for a wide range of visualization methods and data types are available for every computer. 2.3.2 Key Figures in the History of Data Visualization The idea of visualizing data is old: After all, that’s what a map is—a representation of geographic information—and we’ve had maps for about 8,000 years. But it was rare to graph anything other than geography. (n.d.)(https://www.smithsonianmag.com/history/surprising-history-infographic-180959563/) The history of data visualization is full of incredible stories marked by significant events, led by a few key players. The article (Infogram 2016) introduces some of the fantastic men and women who paved the way by combining art, science, and statistics. One of them is Charles Joseph Minard, whose most famous work is the map of Napoleons Russian campaign of 1812 which could use as a data product for Data Visualization. Below we have some visualizes with their famous works and other stories in the article (Infogram 2016). 2.3.2.1 William Playfair (1759–1823) William Playfair is considered the father of statistical graphics, having invented the line and bar chart are used so often today. He is also credited with having created the area and pie chart. Playfair was a Scottish engineer and political economist who published “The Commercial and Political Atlas” in 1786. This book featured a variety of graphs including the image below. In this famous example, he compares exports from England with imports into England from Denmark and Norway from 1700 to 1780. 2.3.2.2 John Snow (1813–1858) In 1854, a cholera epidemic spread quickly through Soho in London. The Broad Street area had seen over 600 dead, and the surviving residents and business owners had primarily fled the terrible disease. Physician John Snow plotted the locations of cholera deaths on a map. The surviving maps of his work show a method of tallying the death counts, drawn as lines parallel to the street, at the appropriate addresses. Snow’s research revealed a pattern. He saw an evident concentration around the water pump on Broad Street, which helped find the cause of the infection. 2.3.2.3 Charles Joseph Minard (1781–1870) Charles Joseph Minard was a French civil engineer famous for his representation of numerical data on maps. His most famous work is the map of Napoleon’s Russian campaign of 1812 illustrating the dramatic loss of his army over the advance on Moscow and the following retreat. This classic lithograph dates back to 1869, displaying the number of men in Napoleon’s 1812 Russian army, their movements, and the temperatures they encountered along their way. It has been called one of the “best statistical drawings ever created.” The work is an essential reminder that the fundamentals of data visualization lie in a nuanced understanding of the many dimensions of data. Tools like D3.js and HTML are no proper without a firm grasp of your dataset and sharp communication skills. It represents the earliest beginning of data journalism. 2.3.2.4 Florence Nightingale (1820–1910) Florence Nightingale is famous for her work as a nurse during the Crimean War, but she was also a data journalist. She realized soldiers were dying from poor sanitation and malnutrition, so she kept meticulous records of the death tolls in the hospitals and visualized the data. Her coxcomb or rose diagrams helped her fight for better hospital conditions and ultimately save lives. (Source:(Infogram 2016)) 2.3.2.5 Edmond Halley (1656–1742) Edmond Halley was an English astronomer, geophysicist, mathematician, meteorologist, and physicist who is best known for computing the orbit of Halley???s Comet. According to the BBC, Halley developed the use of contour lines on maps to connect and describe areas that display differences in atmospheric conditions from place to place. These lines are now commonly used to describe meteorological variation common to us from weather reports. (Source:(Infogram 2016)) 2.3.2.6 Charles de Fourcroy (1766–1824) Charles de Fourcroy was a French mathematician and scholar. He produced a visual analysis of the work of French civil engineers and a comparison of the demographics of European cities.In 1782 he published Tableau Poléometrique, a treatise on engineering and civil construction. His use of geometric shapes predates the modern treemap, which is widely used today to display hierarchical data. (Source:(Infogram 2016)) 2.3.2.7 Luigi Perozzo (1856–1916) Luigi Perozzo was an Italian mathematician and statistician who stood out for being the first to introduce 3D graphical representations, showing the relationships between three variables on the same graph. Perozzo published one of the first 3D representations of data showing the age group of the Swedish population between the 18th and 19th centuries. (Source:(Infogram 2016)) 2.4 Contemporary Visualists 2.4.1 Hans Rosling Hans Rosling took his interest in global health and developed stunning visualizations about it using statistical methods and data from the UN. He was a noted TED speaker and one of his most interesting TED talks is “Asia’s Rise: How and When” (Rosling 2009). In this video, Hans shows trends of the Western countries vs. Developing countries like India and China and makes predictions using stunning visualizations like the Bubble chart. He also predicts the exact date on which India and China will move ahead of USA as strong economic forces. Hans was the co-founder and developer of the Gapminder Foundation which is committed to promoting global sustainable development through the understanding of statistics and data describing issues at the local, national, and global level. One of the most important goals of the Gapminder foundation is to end ignorance in the world by developing fact-based visualizations to present the world as it is (Ruan et al. 2017). As part of Gapminder, Hans Rosling has developed many interactive and intuitive visualizations. Gapminder provides free teaching material to dismantle misconceptions and promote a fact-based worldview (Rosling, n.d.). 2.4.2 David McCandless David McCandless is a British data-journalist and his blog Information is Beautiful (McCandless 2018) hosts some of the most visually stunning graphs, charts, and maps on a wide range of topics like science, food, dogs and countries. One such chart, International Number Ones: Because every country is good at something (according to data), is a captivating work that displays something each country is the best at (McCandless 2016). The visualizations on this website are updated and revised whenever new data is available. One such chart, International Number Ones: Because every country is good at something (according to data), is a captivating work that displays something each country is the best at (McCandless 2016). The visualizations on this website are updated and revised whenever new data is available. 2.5 How to tell stories using data visualization’ and ‘exploratory data visualization’ theory example 2.5.1 A cool website: MIT Media Lab (Deloitte, Datawheel, and Hidalgo 2016) MIT Media Lab in collaboration with Deloitte has created a new visualization tool, that aggregates US government open source data and mines information to generate trends and stories about cities, jobs, industries, etc. Just looking at any of the open data sources would give us an idea about the vastness (breadth and depth) of the available data. It is impressive that they have brought it all together on a single platform in a convenient format. We think of a topic, and it is possible it is there! The benefits are a better understanding of our consumers, talent pool, jobs, climate, which helps improve our decision-making ability. The best part is that the data is also available for download so we can replicate the visuals, redesign and tell our own stories with this data. There are also other similar websites, that has some good visualizations on census data: (Bureau 2018a) 2.5.2 Standing out categorization of information on the website. What stands out is the categorization of information on the website which enables the following: Easy browsing of various categories of information available at a single glance An easy search on any topic of interest and get more in-depth information Logical construction of information using data and visuals under each category Comparative analysis of cities Variety of exploratory visualizations to learn from Most important - Storytelling through data, such as the evolution of the American Worker, how poverty is bad for people’s health, how men still dominate in the highest paying industries, and opioid addiction damage. 2.5.3 Automatic visualization vs. context-specific visualization Automatic visualization is a bad idea, generally speaking. Some parts of visualization indeed should be automatic, such as standard chart types and recurring geometries. Pieces of visualization, such as annotation and axis construction can be automatic. However, full-on automation where insight fountains out from any dataset is farfetched at this point because this requires automatic analysis. Analytics is usually context-specific and requires more than boilerplate statistics. The most interesting visualizations are context-specific. (Flowingdata 2017) 2.5.4 Data analytics software Data analytics software can analyze vast amounts of data and incredible speeds, but how can it explain the results of that analysis? Today, the only means of doing this is with graphics. Data visualization still leaves room for interpretation. However, technology is catching up. Narrative generation software can run as a plug-in to the dashboards. Tools like Savvy install on a server and allow every dashboard user to get a written summary of demand. This software is fully plugged and play, it takes seconds to install, and it is easy to use. It runs with Microsoft Excel, Qlik Sense 3.0, and is available as an API. It is an example of how automation is making our working lives more comfortable by automating repetitive tasks and allowing us to leverage existing data reserves fully. (Manning 2016) 2.5.5 Data visualization can’t explain data, leaving room for interpretation. According to Alysson Ferreira, a UI Engineer, there is an increasing need to understand the latest trends quickly and efficiently, which means there’s also a need for significant sources of trustworthy information. (Ferreira 2017) This is where data visualization comes in. Data visualization is the art of displaying information by combining the beauty of imagery with the conciseness of statistics, which allows us to organize complex data into useful graphical representations. In simple terms, data visualization is the art of translating complex data into meaningful information. (Towler 2015) Plug in any data set into a magic box and it spits out a beautiful visualization you can show all of your co-workers, friends, and family. That is the promise of many startups, but it does not quite work that way. The problem is that graphics alone don’t fully explain data, and so we are inundated with queries: why did the numbers fall in whatever month? Data visualization cannot explain data, leaving room for interpretation. Although simple visualizations such as standard chart types (bar chart, line chart, etc.) are already automated to a certain extent in Microsoft Office tools and other software available in the market, full on automation where insight fountains out from any data set are far-fetched at this point because this requires automated analysis. The automated analysis here means that the tool or algorithm has to understand the context and also select the best visualization. 2.5.6 One great tool: D3.js. The focus in today’s world has been on open source tools and technologies and these tools although being free for the most part to require more effort to integrate to the current visualization workflow seamlessly. As mentioned in one of the articles about D3.js: D3.js is one of the first data visualization tools that comes to mind when talking about free, open-source alternatives. It is a JavaScript-based library for creating web visualization and displays the results on the web page. However, with high power comes great responsibility. D3.js is one of the first data visualization tools that comes to mind when talking about free, open-source alternatives. It is a JavaScript-based library for creating web visualization and displays the results on the web page. However, with high power comes great responsibility. Ultimately, the focus should be on our goals rather than our tools. 2.6 Additional Resources for Aspiring Data Visualists Data visualization domain is vast and an aspiring visualizes, a person who can link between storytelling and data-experience design can further broaden his/her knowledge through: 2.6.1 Tableau Community (Tableau Software 2018a) helps you to explore Tableau further : It will help us enhance our learning Get answers for most of your doubts In tableau Post new questions and crowd source answers Attend events, seminars and join conferences conducted locally/ globally Give back to the community once you become an expert in that field There are very active Tableau social media groups (Tableau Software 2018b): Tableau Enthusiasts: LinkedIn Group (19K members) Tableau Software Fans &amp; Friends: LinkedIn Group (45k members) 2.6.2 Blogs Here are some blogs recommended by Tableau (Tableau Software 2018c): Blog Description Link Storytelling with Data This blog provides information about the fundamentals of data visualization and how to make data a critcal component of your story. http://www.storytellingwithdata.com/ Information is Beautiful This blog was founded by David McCandless, the author of two bestselling infographics books, and provides a variety of visualizations, all of which are continuously revised and updated with the most recent data. https://informationisbeautiful.net/ Visualizing Data This blog provides a space for data visualizers to share news and thoughts about the field as well as offers diverse content about current and cutting-edge techniques, discussion of both practical and theoretical topics. http://www.visualisingdata.com/ Junk Charts This blog critiques a variety of graphics, providing insights about what works and what doesn’t in each visualization, and how to improve them. http://junkcharts.typepad.com/ The Pudding This blog explores complex and contested issues through visual essays. https://pudding.cool/ The Atlas This blog provides visualizations on a plethora of topics. https://www.theatlas.com/ Graphic Detail This blog is the hub of The Economist’s data journalism; it provides examples of charts, maps, and infographics (all of which are often interactive). https://www.economist.com/blogs/graphicdetail Tableau Blog The Tableau blog is a source of data viz trends, issues important to the Tableau community, and updates about Tableau products. https://www.tableau.com/about/blog Michael Sandberg’s Data Visualization Blog Michael Sandberg’s blog discusses a wide variety of data visualization examples. In addition, the blog covers other topics such as Infographics, Data Science, Business Intelligence, Data Ethics, Storytelling and much more. https://datavizblog.com/ Beautiful Data Blog This blog features discussion of all things data and has a wide range of categories to browse through. http://beautifuldata.net/ 2.6.3 Useful Links on Data Visualization Resources, Trends, and Tutorials Resource Description Link (Catalogue 2018) This is a helpful resource where one can find different types of plots that can be used in data visualization. https://datavizcatalogue.com (Kosara 2018a) Robert Kosara’s website which contains recent developments happening in visualization. https://eagereyes.org (Research 2018) This link to Tableau’s Research webpage includes information about Robert Kosara and his research papers. Here is a link to Robert Kosara’s twitter handle. https://research.tableau.com/user/robert-kosara (FlowingData 2018) Website which offers courses, tutorials and happenings in viz. http://flowingdata.com/ (Infogram 2018) An infogram helps a user making different types of plots and learning the art of visualization. Engaging infographics, reports, charts, dashboards and maps can be easily created in minutes with it. insert reference Improving data visualisation for the public sector (does this link work?) http://www.improving-visualisation.org/ insert reference This resource is a data visualization gallery of weekly explorations of United States Census data https://www.census.gov/dataviz/ (Joerg Blumtritt, n.d.,) This blog features discussion of all things data http://beautifuldata.net/ (Sandberg, n.d.) Michael Sandberg’s blog discusses a wide variety of data visualization examples https://datavizblog.com/ (NA, n.d.) This resource is a data visualization gallery of weekly explorations of United States Census data https://www.census.gov/dataviz/ (Agency 2018) This resource provides a series of interactive data visualizations using FEMA data https://www.fema.gov/data-visualization insert reference This blog features discussion of all things data http://beautifuldata.net/ insert reference Improving data visualisation for the public sector (does this link work?) http://www.improving-visualisation.org/ insert reference Michael Sandberg’s blog discusses a wide variety of data visualization examples https://datavizblog.com/ insert reference This resource is a data visualization gallery of weekly explorations of United States Census data https://www.census.gov/dataviz/ insert reference This resource provides a series of interactive data visualizations using FEMA data https://www.fema.gov/data-visualization insert reference The History of Data Visualization Dashboard Insight, Dashboard Insight, 2013 http://www.dashboardinsight.com/news/news-articles/the-history-of-data-visualization.aspx insert reference Current research: Deceptive visualizations, Infogram, 2016 https://medium.com/@Infogram/study-asks-how-deceptive-are-deceptive-visualizations-8ff52fd81239 insert reference Agata Kwapien in Data Visualization, 2015 https://www.datapine.com/blog/misleading-data-visualization-examples/ insert reference A Brief History of Data Visualization, York University, Michael Friendly, 2006 http://www.datavis.ca/papers/hbook.pdf insert reference Data Visualization and the 9 Fundamental Design Principles, Melissa Anderson, 2017 https://www.idashboards.com/blog/2017/07/26/data-visualization-and-the-9-fundamental-design-principles/ insert reference A Practitioner Guide to Best Practices in Data Visualization.Interfaces 47(6):473-488, Jeffrey D. Camm, Michael J. Fry, Jeffrey Shaffer, 2017 https://doi.org/10.1287/inte.2017.0916 insert reference The 7 Best Data Visualization Tools In 2017 https://www.forbes.com/sites/bernardmarr/2017/07/20/the-7-best-data-visualization-tools-in-2017/#3a12b8ea6c30 insert reference The Data Visualisation Catalogue https://datavizcatalogue.com 2.6.4 Infographics vs. Data Visualizations Data visualization and infographics both present visual information to users. While their purposes may seem similar, they have different use cases. This article explains the differences between an infographic and a data visualization. (Pritchard 2016). 2.6.4.1 Data Visualization Data visualization usually involves the presentation of summary statistics using visual forms such as graphs, plots or charts; its goal is to provide clear and succinct information about your research. Data visualization also typically focuses on the two critical aspects of data and design. However, a design should depend on the data itself; for example, the type of chart used in a data visualization should be selected based on which one best displays the particular data set. Since visualizations are essential in telling stories (such as trends), it should avoid adding extraneous and distracting details. Data visualizations should be self-explanatory, and users should be able to conclude on their own. 2.6.4.2 Infographics An infographic, on the other hand, is typically a combination of illustrations, facts, and text. Infographics might include some components characteristic of data visualization but in general feature less data-driven storytelling. While infographics are not grounded in data, like data visualizations, infographics convey several ideas simultaneously; and like data visualization, the design should be both visually appealing and should base in the function of conveying the visual story. 2.6.4.3 Comparison Data Visualization Infographics Illustrates raw values Visualize stories Delivers information Provide stances Offers objectivity Offer subjectivity 2.6.4.4 When Should You Use Infographics or Data Visualization? While both infographics and data visualizations have their distinct use cases, more often than not they can be used together. Some of the effective ways to choose between them are described below. Data Visualization: Use Case Best Visual Representation Rationale Newsletters Data Visualization Newsletters have to catch the interest of viewers. Putting good data visualizations in newsletters makes them more interesting, and includes informative details such as a company’s unique findings, statistics, or status. White papers &amp; eBooks Data Visualization Including data visualizations can help support the argument you make in the document. Annual Reports Data Visualization Things like an overview of past year, success stories, and company performance can be done well using data visualization. Blog Posts Infographic Blog posts are generally written for a specific purpose. Including infographics can reinforce the point you are trying to make. Case Studies Infographic Paired with a case study, an infographic can provide engaging visuals and succinctly summarize a lengthy report, offering valuable insights to readers. Marketing Content Infographic Marketing content generally tells a story. The best way to tell a story is using proper infographics. These can be great for social media campaigns since infographics can display all the main points. References "],
["fundamentals.html", "Chapter 3 Fundamentals 3.1 Design Principles 3.2 Best Practices 3.3 Data Visualization Tools 3.4 Special Topics 3.5 Data Visualization in Business 3.6 Special Topics 3.7 Contemporary Research Results &amp; What’s Next", " Chapter 3 Fundamentals This chapter covers foundational design principles and both general and more specific best practices, as well as explores popular visualization tools and some special topics relevant to the field of data visualization, and concludes with a discussion of what’s next for the field. 3.1 Design Principles 3.1.1 Melissa Anderson’s Principles of Design The following principles are from (Anderson 2017). Criteria Description Balance A design is said to be balanced if key visual elements such as color, shape, texture, and negative space are uniformly distributed. Balance doesn’t mean that each side of the visualization needs perfect symmetry, but it is important to have the elements of the dashboard/visualization distributed evenly. And it is important to remember the non-data elements, such as a logo, title, caption, etc. that can affect the balance of the display. Emphasis Draw viewers’ attention towards important data by using key visual elements. Emphasis is the component that is most related to when reading the nine principles of design. It is the key to be conscious of what is drawing the viewer’s attention to the art. When thinking about the art design of data visualization it is also very important to remain keen on the main point of your story and how the entire visualization is either drawing the viewer to that point of emphasis or how they are being distracted or drawn elsewhere. Movement Ideally movement should mimic the way people usually read, starting at the top of the page, moving across it, and then down. Movement can also be created by using complementary colors to pull the user’s attention across the page or with use of animation Pattern patterns are ideal for displaying similar sets of information, or for sets of data that equal in value. Disrupting the pattern can also be effective in drawing viewers’ attention; it naturally draws curiosity. Repetition Relationships between sets of data can be communicated by repeating chart types, shapes, or colors. Proportion If a person is portrayed next to a house, the house is going to look bigger. In data visualization, the proportion can indicate the importance of datasets, along with the actual relationship between numbers. Proportion can be subtle, but it can go a long way to enhancing a viewer’s experience and understanding of the data. The danger of proportion though is that it can be easy to deceive people subconsciously. Naturally, images will have a greater impact on how our brains perceive the dashboard or visualization. For example, someone can change the scale of a graph or images to inflate their results and even if they write the numbers next to it, the shortcut many people will take is to interpret the data based on the image. This is why it is important we take care to accurately reflect proportion in our data visualization and remain critical of how others use proportion in their visualization. Proportion can be misused intentionally as well as unintentionally, since images are easier to interpret than data by humans. This is why it is important we take care to accurately reflect proportion in our data visualization and remain critical of how others use proportion in their visualization. Rhythm A design has proper rhythm when the design elements create the movement that is pleasing to the eye. If the design is not able to do so, rearranging visual elements may help. Variety Variety in color, shape, and chart-type draws and keeps users engaged with data. Including more variety can increase information retention by the viewer. But when there is too much variety, important details can be overlooked. Variety, which could seem counter to balance, but when done correctly, variety can help increase the recall of information. However, if overdone, too much variety can feel cluttered and blur together the images and data in the mind of the viewer. Unity Unity across design will happen naturally if all other design principles are implemented. 3.1.2 Gestalt Principles of Design Data is simply a collection of many individual elements (i.e., observations, typically represented as rows in a data table). In data viz, our goal is usually to group these elements together in a meaningful way to highlight patterns and anomalies. Described this way, it makes sense that the following principles by Gestalt are a good set of guidelines to assemble different elements into groups (FusionCharts 2012). Principle Description Proximity White space can be used to group elements together and separate others Similarity Objects that look similar are instinctively grouped together in our minds Enclosure Helps distinguish between groups Symmetry Objects should not be out of balance, or missing, or wrong. If an object is asymmetrical, the viewer will waste time trying to find the problem instead of concentrating on the instruction. Closure We tend to complete shapes and paths even if part of them is missing Continuity We tend to continue shapes beyond their ending points (similar to closure) Connection Helps group elements together Figure and ground We typically notice only one of several main visual aspects of a graph; what we do notice becomes the figure, and everything else becomes the “background”. This one is especially interesting because it is not as obvious as some of the others, but is really important in matching a data viz design to its purpose. 3.1.3 Tufte’s Principles of Design A graph should be impressive and can obtain audience’s attention. How can we achieve this? We must consider several aspects: efficiency, complexity, structure, density and beauty. We also should consider the audience whether they will be confused about the design. 3.1.3.1 Principle 1: Maximizing the data-ink ratio, within reason Data-ink is the non-erasable core of a graphic, the non-redundant ink arranged in response to variation in the numbers represented. It is also the proportion of graphic’s ink devoted to the non-redundant display of data-information. \\[{Data \\ Ink \\ Ratio} = \\frac{{Data \\ Ink}}{{Total \\ Ink}}\\] This basic idea is illustrated in the following visualizations. Erase non-data-ink and redundant data-ink. (Source:(Tufte 1986)) Erase non-data-ink and redundant data-ink. (Source: (Plotly 2017)) (Source: (Plotly 2017)) Always revise and edit (Source: (Tufte 1986)) The graphs will generally be better when more information is displayed per unit of space and unit of ink. Graphics are almost always going to improve as they go through editing, revision, and testing against different design options. Try to figure out whether the audience looking at the new designs will be confused. Nothing is lost to those puzzled by the frame of dashes, and something is gained by those who do understand. We can also assume that if you understand the statistical graphics, most other readers will too, because it is a frequent mistake in thinking about statistical graphics to underestimate the audience. Some of the new designs may appear odd, but this is probably because we have not seen them before. 3.1.3.2 Principle 2: Mobilize every graphical element, perhaps several times over, to show the data. The danger of multifunctioning elements is that they tend to generate graphical puzzles, with encodings that can only be broken by their inventor. Thus design techniques for enhancing graphical clarity in the face of complexity must be developed along with multifunctioning elements. In other words, we should try to make all present graphical elements data encoding elements. We must make every graphical element effective (See the following example). (Source: (Tufte 1986)) 3.1.3.3 Principle 3: Maximize data density and the size of the data matrix, within reason. High preformation graphics should be designed with special care. As the volume of data increases, data measures must shrink (smaller dots for scatters, thinner lines for busy time-series). \\[{Data \\ Density} = \\frac{{Entries \\ in \\ the \\ Data \\ Matrix}}{{Area \\ of \\ Chart}}\\] (Source: (gallery, n.d.)) (Source: (gallery, n.d.)) 3.1.3.4 Principle 4: Escape flatland - small multiples, parallel sequencing. Data is multivariate doesn’t necessarily mean 3D projection. How can we enhance multivariate data on inherently 2D surfaces? We can use small multiple graphs or parallel sequencing skill. (Source: (Tufte 1986)) (Source: (Tufte 1986)) 3.1.3.5 Principle 5: Provide the user with an overview and details on demand. A carefully designed view can show a macrostructure (overview) as well as microstructure (detail) in one space. (Source: (Tufte 1986)) 3.1.3.6 Principle 6: Utilize Layering &amp; Separation. Supported by Gestalt laws (The principles of grouping): Grouping with colors Using Color to separate 1 + 1 = 3 (clutter) Graphics are almost always going to improve as they go through editing, revision, and testing against different design options. Try to figure out whether the audience looking at the new designs be confused? Nothing is lost to those puzzled by the frame of dashes,and something is gained by those who do understand. We can also assume that if you understand the statistical graphics, most other readers will, too because it is a frequent mistake in thinking about statistical graphics to underestimate the audience. (Source: (Tufte 1986)) 3.1.3.7 Principle 7: Utilize narratives of space and time. Tell a story of position and chronology through visual elements. (Source: (Periscope 2018)) (Source: (Periscope 2018)) 3.1.4 Common Mistakes to Avoid: Mistake Description Starting off with too much complexity It’s tempting to provide highly detailed, real-time dashboards. Instead of spending a lot of time working through the first iteration, however, it’s better to work through several short cycles of prototyping, testing and adjusting. Using metrics no one understands Dashboards should use metrics or concepts that a broader audience understands. Esoteric jargon and metrics will not help get a message across. Cluttering the dashboard with unimportant graphics and unintelligible widgets Dashboards should be simple in visual appeal, rather than flashy or over-designed; rapidly and easily informing the audience of the primary message of the dashboard should be the priority, and clutter will only detract from that. Waiting for complex technology and big BI deployment projects Implementations of some of traditional business intelligence tools often take a much longer time than originally anticipated. Waiting for a traditional BI project to materialize may mean delays. A dashboarding solution takes a long time to implement and is a repetitive, iterative process with incremental improvements. Underestimating the time or resources to create and maintain the dashboard Even though a dashboard is typically one page or one screen, it would be injudicious to assume that it will be quick and simple to create and maintain. Failing to match metrics to the goal Instead of showcasing the activities of a single department, a dashboard should connect the department’s efforts to the organization’s actual goals and objectives Using ineffective, poorly designed graphs and charts While designing graphs and charts for dashboard, extreme care should be taken. Principles for designing good data visualizations should be followed to avoid dashboards populated with poorly designed graphs and charts. 3.2 Best Practices Data visualization does not unleash a ready-made story on its own. There are no rules or protocols to guarantee a story. Instead, we need to look for insights, which can be artfully woven into stories in the hands of a good journalist (???)(Anderson 2017)(“5 Data Visualization Tips,” n.d.)(Jeffrey D. Camm 2017). Here is a process for finding insights that tell a story. Each of these steps will be discussed further in this section. 3.2.1 Determine the Story with Insights Storytelling is an essential part of data visualization. It is extremely important to effectively communicate information through the visualization. Stikeleather’s article (Jim Stikeleather 2013) discussed the way in which a visual designer tells a story with a visualization. 3.2.2 How to choose the best form of Visualization Since just loading data into a table format could be a form of visualization, our focus should not be whether visualization is needed but on which form of data visualization is best for the situation. Focus Description 5 Second Rule Research shows that the average modern attention span for viewing anything online is less than 5 seconds, so if you can’t grab attention within 5 minutes, you’ve likely lost your viewer. Include clear titles and instructions, and tell people succinctly what the visualization shows and how to interact with it. Design and layout matter The design and layout should facilitate ease of understanding to convey your message to the viewer. Artists use design principles as the foundation of any visual work. If you want to take your data visualization from an everyday dashboard to a compelling data story, incorporate graphic designer Melissa Anderson’s principles of design: balance, emphasis, movement, pattern, repetition, proportion, rhythm, variety, and unity, discussed in more detail in the design principles section (Anderson 2017). Keep it simple Keep charts simple and easy to interpret. Instead of overloading viewers’ brains with lots of information, keep only necessary elements in the chart and help the audience understand quickly what is going on. Pretty doesn’t mean effective There is a misconception that aesthetically pleasing visualization is more effective. To draw attention, sometimes we want them to be pretty and eye-catching. But if it fails to communicate the data properly, you’ll lose your audience’s interest as quickly as you gained it. Use color purposely and effectively Use of color may be prettier and attractive but can be distracting too. Thus, the color should be used only if it assists in conveying your message. Also another thing to keep in mind is to be consistent with the color scheme that the organization/consumer is used to and also try and follow the same color across dashboards while communicating a story. 3.2.3 Analyze and Interpret Once the data is visualized, the next step is to learn something from the visualization that is created. Questions that can be asked based on the picture can be: 3.2.3.1 Macro/Micro-Provide the user with both views (overview and detail)- (Tufte’s Design Principle 2) A carefully designed view can show a macro structure (overview) as well as micro structure (detail) in one space. What can be seen in this image? Is it what that was expected? Are there any interesting patterns? What does this mean in the context of the data? Sometimes we might end up with visualization that, in spite of its beauty, might seem to tell that nothing of interest can be found from data. But there is almost always something that we can learn from any visualization, however trivial. 3.2.4 Document Your Insights and Steps If you think of this process as a journey through the dataset, the documentation is your travel diary. It will tell you where you have traveled to, what you have seen there and how you made your decisions for your next steps. You can even start your documentation before taking your first look at the data. In most cases when we start to work with a previously unseen dataset, we are already full of expectations and assumptions about the data. Usually, there is a reason why we are interested in that dataset that we are looking at. It’s a good idea to start the documentation by writing down these initial thoughts. This helps us to identify our bias and reduces the risk of misinterpretation of the data by just finding what we originally wanted to find. Personally speaking, the documentation is the most important step of the process, and it is also the one people most likely to skip. As you will see in the example below, the described process involves a lot of plotting and data wrangling. Looking at a set of 15 charts you created might be very confusing, especially after some time has passed. In fact, those charts are only valuable (to you or any other person you want to communicate your findings) if presented in the context in which they have been created. 3.2.5 Transform Data Naturally, with the insights that you have gathered from the last visualization, you might have an idea of what you want to see next. You might have found some interesting pattern in the dataset which you now want to inspect in more detail. Possible transformations are the following. Focusing the attention: What can be removed? Realize that consistency can help eliminate unnecessary distractions. There may be a trade-off between losing information but conveying the ultimate meaning more clearly. Label important things rather than relying on a legend, which requires the viewer to hold on to too much information at once. Transformation Description Zooming This allows us to have look at a certain detail in the visualization Aggregation To combine many data points into a single group Filtering This helps us to (temporarily) remove data points that are not in our major focus Outlier handling This allows us to get rid of single points that are not representative of 99% of the dataset. Let’s consider the following example: You have visualized a graph and what came out of this was nothing but a mess of nodes connected through hundreds of edges (a very common result when visualizing so-called densely connected networks), one common transformation step would be to filter some of the edges. If, for instance, the edges represent money flows from donor countries to recipient countries, we could remove all flows below a certain amount (n.d.). 3.2.6 Adapt your story to a different set of audiences Jonathon Corum is a graphics designer for The New York Times and he provided a very informative talk to a strictly scientific audience on how to create and design visualizations that explain material originally created for a certain audience, i.e. the scientific community, but now is to be related to a different audience (in his case, the readership of the Times or maybe the public at large). The talk is filled with examples and breakdowns of how he has moved from his base content to the final product, all of which are illuminating examples by themselves. There is also great power in the broader themes that he is trying to convey. Of course, it is easy to assume that we know the audience we are producing the work for, but even in this step, we should focus on the ultimate goal of conveying, understanding and explaining a concept. Some of the main highlights to help make this connection with the audience involved are mentioned below: Principle Description Focusing the attention What can be removed? Realize that consistency can help eliminate unnecessary distractions. There may be a trade-off between losing information but conveying the ultimate meaning more clearly. Label important things rather than relying on a legend, which requires the viewer to hold on to too much information at once. Involving your audience: Give them opportunities to connect their own general knowledge on the topic. Use real world comparisons or examples to help build and relate context. Encourage comparisons and make this easy for the viewer to process and see. Explaining why Providing context, adding time sequence details, showing movement, change and mechanism will all guide your audience in connecting the dots and understanding the significance of what you are trying to communicate. 3.2.7 More on Best Practices Five Practices Explanation Find the compelling narrative Along with giving an account of the facts and establishing the connections between them, don’t be boring. You are competing for the viewer’s time and attention, so make sure the narrative has a hook, momentum, or a captivating purpose. Finding the narrative structure will help you decide whether you actually have a story to tell. If you don’t, then perhaps this visualization should support exploratory data analysis (EDA) rather than convey information. Think about the audience If you think about data visualization as storytelling, then you realize you need to tailor your story to your audience; Novice: first exposure to the subject, but doesn’t want oversimplification; Generalist: aware of the topic, but looking for an overview understanding and major themes; Managerial: in-depth, actionable understanding of intricacies and interrelationships with access to detail; Expert: more exploration and discovery and less storytelling with great detail; Executive: only has time to glean the significance and conclusions of weighted probabilities. When you tell the right story to the right audience you are able to identify data points that resonate with the audience. Be objective and offer balance A visualization should be devoid of bias. Even if it is arguing to influence, it should be based upon what the data says–not what you want it to say. There are simple ways to encourage objectivity: labeling to avoid ambiguity, have graphic dimensions match data dimensions, using standardized units, and keeping design elements from compromising the data. Balance can come from alternative representations (multiple clustering’s; confidence intervals instead of lines; changing timelines; alternative color palettes and assignments; variable scaling) of the data in the same visualization. Don’t censor Don’t be selective about the data you include or exclude, unless you’re confident you’re giving your audience the best representation of what the data “says”. This selectivity includes using discrete values when the data is continuous; how you deal with missing, outlier and out of range values; arbitrary temporal ranges; capped values, volumes, ranges, and intervals. Viewers will eventually figure that out and lose trust in the visualization (and any others you might produce). Edit, Edit, Edit Take care to really try to explain the data, not just decorate it. Don’t fall into “it looks cool” trap, when it might not be the best way explain the data. As journalists and writers know, if you are spending more time editing and improving your visualization than creating it, you are probably doing something right. 3.3 Data Visualization Tools Due to the rise of big data analytics, there has been an increased need for data visualization tools to help understand the data. Besides Tableau, there are several other software tools one can use for data visualization like Sisense, Plotly, FusionCharts, Highcharts, Datawrapper, and QlikView. This article is from Forbes and has a brief, clear introduction about these 7 powerful software options for data visualization. This could be helpful for future reference because for different purposes I may need to use different tools. Each option has its advantages and disadvantages and this article helps highlight them. 3.3.1 Brief Description of popular tools Tool Description Tableau The most popular in the group and has many users. It is simple to use, making it easy to learn and can handle large datasets. Tableau can handle big data thanks to integration with database handling applications such as MySQL, Hadoop, and Amazon AWS. Qlikview The main competitor to Tableau and also quite popular. Qlikview is customizable and has a wide range of features which can be a double-edged sword. These features take more time to learn and get acquainted with. However, once one gets past the learning curve, they have a powerful tool at their disposal. FusionCharts The distinctive aspect of FusionCharts is that graphics do not have to be created from scratch. Users can start with a template and insert their own data from their project. Highcharts: It proudly claims to be used by 72% of the 100 biggest companies in the world. It is a simple tool that does not require specialized training and quickly generates the desired output. Unlike some tools, Highcharts focuses on cross-browser support, allowing for greater access and use. Datawrapper: It is making a name for itself in the media industry. It has a simple user interface making it easy to generate charts and embed into reports. Plotly: It can create more sophisticated visuals thanks to integration with programming languages such as Python and R. The danger is creating something more complicated than necessary. The whole point of data visualization is to quickly and clearly convey information. Sisense: It can bring together multiple sources of data for easier access. It can even work with large data sets. Sisense makes it easy to share finished products across departments, ensuring everyone can get the information they need. Altair: It is a statistical visualization library for Python, based on Vega and Vega-Lite. Its sources are widely available on GitHub. With Altair, we can understand the data and its meaning in a better way. Altair’s API is very simple to use. This is simple, elegant and produces beautiful and effective visualizations with a minimal amount of code. Shiny Shiny is an open package from RStudio, which provides a web application framework to create interactive web visualization called Shiny apps. The ease of working with Shiny has what popularized it among R users. 3.3.2 Interactive Data Visualization Interactive or Dynamic data visualization delivers today’s complex sea of data in a graphically compelling and an easy-to-understand way. It enables direct actions on a plot to change elements and link between multiple plots. It enables users to accomplish traditional data exploration tasks by making charts interactive (???). Interactive Data Visualization Software has the following benefits: Benefit Description Absorb information in constructive ways With the volume and velocity of data created every day, dynamic data viz enables enhanced process optimization, insight discovery and decision making. Visualize relationships and patterns Helps in better understanding of correlations among operational data and business performance. Identify and act on emerging trends faster Helps decision makers to grasp shifts in behaviors and trends across multiple datasets much more quickly. Manipulate and interact directly with data Enables users to engage data more frequently. Foster a new business language Ability to tell a story through data that instantly relates the performance of a business and its assets. There are multiple ways by which interactive data visualizations can be developed. D3.js is one of the ways to build an interactive data visualization. 3.3.3 Python for Data Visualization：10 Useful Python Data Visualization Libraries (???) It starts with the insights of learning d3.js by showing interviews with those top visualization practitioners. Then the author gives key concepts and useful features for learning visualization like d3-shape, d3 selection, d3-collection, ds-hierarchy, ds-zoom as well as d3-force. Sample charts for each Library Description Matplotlib Because matplotlib was the first Python data visualization library, many other libraries are built on top of it or designed to work in tandem with it during analysis. While matplotlib is good for getting a sense of the data, it’s not very useful for creating publication-quality charts quickly and easily. Seaborn Seaborn harnesses the power of matplotlib to create beautiful charts in a few lines of code. The key difference is Seaborn’s default styles and color palettes, which are designed to be more aesthetically pleasing and modern. Since Seaborn is built on top of matplotlib, you’ll need to know matplotlib to tweak Seaborn’s defaults. Ggplot ggplot is based on ggplot2, an R plotting system, and concepts from The Grammar of Graphics. ggplot operates differently than matplotlib: it lets you layer components to create a complete plot. For instance, you can start with axes, then add points, then a line, a trendline, etc. Although The Grammar of Graphics has been praised as an “intuitive” method for plotting, seasoned matplotlib users might need time to adjust to this new mindset. Bokeh Like ggplot, Bokeh is based on The Grammar of Graphics, but unlike ggplot, it’s native to Python, not ported over from R. Its strength lies in the ability to create interactive, web-ready plots, which can easily give the output as JSON objects, HTML documents, or interactive web applications. Bokeh also supports streaming and real-time data. Pygal Like Bokeh and Plotly, pygal offers interactive plots that can be embedded in the web browser. Its prime differentiator is the ability to output charts as SVGs. As long as you’re working with smaller datasets, SVGs will do you just fine. But if you’re making charts with hundreds of thousands of data points, they’ll have trouble rendering and SVG will become sluggish. Plotly You might know Plotly as an online platform for data visualization, but did you also know you can access its capabilities from a Python notebook? Like Bokeh, Plotly’s forte is making interactive plots, but it offers some charts you won’t find in most libraries, like contour plots, dendograms, and 3D charts. Geoplotlib geoplotlib is a toolbox for creating maps and plotting geographical data. You can use it to create a variety of map-types, like choropleths, heatmaps, and dot density maps. You must have Pyglet (an object-oriented programming interface) installed to use geoplotlib. Nonetheless, since most Python data visualization libraries don’t offer maps, it’s nice to have a library dedicated solely to them. Gleam Gleam is inspired by R’s Shiny package. It allows you to turn analyses into interactive web apps using only Python scripts, so you don’t have to know any other languages like HTML, CSS, or JavaScript. Gleam works with any Python data visualization library. Once you’ve created a plot, you can build fields on top of it so that users can filter and sort data. Missingno Dealing with missing data is a pain. Missingno allows you to quickly gauge the completeness of a dataset with a visual summary, instead of trudging through a table. You can filter and sort data based on completion or spot correlations with a heatmap or a dendrogram. Leather Leather’s creator, Christopher Groskopf, puts it best: “Leather is the Python charting library for those who need charts now and don’t care if they’re perfect.” It’s designed to work with all data types and produces charts as SVGs, so you can scale them without losing image quality. Since this library is relatively new, some of the documentation is still in progress. The charts you can make are pretty basic but that’s the intention. 3.3.4 R for Data Visualization: Grammar of Graphics Chapter 3 of Grolemund and Wickham’s “R for Data Science” (Grolemund and Wickham 2017) 3.3.4.1 Layered Grammar of Graphics: The grammar of graphics is based on the implication that you can uniquely describe any plot as a combination of a dataset a geom a set of mappings a stat a position adjustment a coordinate system a faceting scheme. 3.3.4.2 Aes/Mapping: Global Mapping and Local Mapping Formula: \\[ggplot(data = DATA) + GEOMFUNCTION (mapping = aes(MAPPINGS),stat =STAT, position = POSITION ) + COORDINATEFUNCTION + FACETFUNCTION\\] library(&quot;tidyverse&quot;) ## ── Attaching packages ──────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.1 ✔ purrr 0.3.2 ## ✔ tibble 2.1.1 ✔ dplyr 0.8.0.1 ## ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ─────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(&quot;gapminder&quot;) ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Here, “mapping = aes(x = displ, y = hwy)” is a global mapping, where “mapping = aes(color = class)” is a local mapping. 3.3.4.3 Position Adjustment “Identity” position will place each object exactly where it falls in the context of the graph. This is not very useful for bars. “Fill” position works like stacking, but makes each set of stacked bars the same height. This makes it easier to compare proportions across groups. “Dodge” position places overlapping objects directly beside one another, which makes it easier to compare individual values. “Jitter” position adds a small amount of random noise to each point. This spreads the points out because no two points are likely to receive the same amount of random noise. 3.3.4.4 Coordinate Systems The default coordinate system is Cartesian. Command Description coord_flip() It switches the x- and y-axes. Very useful if you want horizontal boxplots. coord_quickmap() It sets the aspect ratio correctly for maps. This is very important if you draw a map. coord_polar() It uses polar coordinates. Polar coordinates reveal interesting connections between a bar chart and a Coxcomb chart. ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() + coord_flip() coord_quickmap() sets the aspect ratio correctly for maps. This is very important if you draw a map. coord_polar() uses polar coordinates. Polar coordinates reveal interesting connections between a bar chart and a Coxcomb chart. 3.3.5 R Shiny R Shiny enables us to produce interactive data visualizations with a minimum knowledge of HTML, CSS, or Java using a simple web application framework that runs under the R statistical platform (Castañón 2016). Standalone apps can be hosted on a webpage or embedded in R Markdown documents and dashboards can be built using R shiny. It combines the computational power of R with the interactivity of the modern web. The main advantage of using R Shiny is : Its flexibility of pulling in whatever package in R that you want to solve your problem, reaping the benefits of an open source ecosystem for R and JavaScript visualization libraries, thereby allowing to create highly custom applications and enabling timely, high quality interactive data experience without (or with much less) web development and without the limitations or cost of proprietary BI tools. It combines the computational power of R with the interactivity of the modern web. The main advantages of using R Shiny are : Its flexibility of pulling in whatever package in R that you want to solve your problem, reaping the benefits of an open source ecosystem for R and JavaScript visualization libraries, thereby allowing to create highly custom applications and enabling timely, high quality interactive data experience without (or with much less) web development and without the limitations or cost of proprietary BI tools. 3.3.6 D3.js D3.js stands for Data-Driven Document, a JS library for interactive Big Data visualization in literally ANY way required real-time(Cabot Technology Solution 2017). This is not a tool, mind you, so a user should have a solid understanding of JavaScript to work with the data and present it in a humanly-understandable form. To say more, this library renders the data into SVG and HTML5 formats, so older browsers like IE7 and 8 cannot leverage D3.js capabilities. The data gathered from disparate sources like huge-scale datasets is bind in real-time with DOM to produce interactive animations ( 2D and 3D alike) in an extremely rapid way. The D3 architecture allows the users to intensively reuse the codes across a variety of add-ons and plug-ins. Some of the key advantages are: It is a dynamic, free and open source and very flexible with all web technologies, the ability to handle big data and the functional style allows to reuse the codes. The Hitchhiker’ Guide to d3.js is a wonderful guide for self-teaching d3.js. This guide is meant to prepare readers mentally as well as give readers some fruitful directions to pursue. There is a lot to learn besides the d3.js API, both technical knowledge around web standards like HTML, SVG, CSS and JavaScript as well as communication concepts and data visualization principles. Chances are you know something about some of those things, so this guide will attempt to give you good starting points for the things you want to learn more about. It starts from the insights of learning d3.js by showing interviews with those top visualization practitioners. Then the author gives key concepts and useful features for learning visualization like d3-shape, d3 selection, d3-collection, ds-hierarchy, ds-zoom as well as d3-force. The guide is helpful as it lists a lot of useful resources links for learning d3.js. For example, it recommends d3 API Reference, 2000+ d3 case studies and tutorials for d3. It contributes tremendously in doing exploratory analysis version of group project of this class on d3. Further, the guide provides information such as some meetup groups in the bay area, which can be helpful in connecting with data professionals and building up networks. 3.3.7 Tableau Tableau is amid the market leaders for the Big Data visualization, especially efficient for delivering interactive data visualization for the results derived from Big Data operations, deep learning algorithms and multiple types of AI-driven apps (AbsentData 2018). Tableau can be integrated with Amazon AWS, MySQL, Hadoop, Teradata ,and SAP, making this solution a versatile tool for creating detailed graphs and intuitive data representation. This way the C-suite and middle-chain managers are able to make grounded decisions based on informative and easily-readable Tableau graphs. Tableau is a business intelligence (BI) and analytics platform created for the purposes of helping people see, understand and make decisions with data. It is the industry leader in interactive data visualization tools, offering a broad range of maps, charts, graphs, and more graphical data presentations. It is a painless option when cost is not a concern and you do not need advanced and complex analysis. The application is very handy for quickly visualizing trends in data, connecting to a variety of data sources, and mapping cities/regions and their associated data. The following tips for Tableau are still missing: Running totals Common Baseline Weighted averages Moving average Grouping by aggregates Different years comparison Appending excel sheets Bar chart totals Fixed axis when re-drawing charts Auto-fitting screen behavior depending on data selection Key advantages: It provides a non-technical user the ability to build complex reports and dashboard with zero coding skills. Using drag-n-drop functionalities of Tableau, user can create a very interactive visual within minutes. It can handle millions of rows of data with ease and users can make live to connections to different data sources like SQL etc (“Data Visualization Best Practices” 2017)(“The Extreme Presentation Method,” n.d.). The key advantages are: It provides non-technical users the ability to build complex reports and dashboard with zero coding skills. Using drag-n-drop functionalities of Tableau, a user can create a very interactive visual within minutes. It can handle millions of rows of data with ease and users can make live connections to different data sources like SQL etc. (“Data Visualization Best Practices” 2017)(“The Extreme Presentation Method,” n.d.). Building advanced analytics application with TabPy: Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the y variable!!! Here is a link that shows how to integrate and visualize data from Python in Tableau. This is especially relevant to all data science students, as this is one of the tools used for visualizing advanced analytics. The author here has given an example using data from Seattle’s police department’s 911 calls and he tries to identify criminal hotspots in the area. The author uses machine learning (spatial clustering) and creates a great interactive visualization, where you can click on the type of criminal activity and the graph will show various clusters. There are other examples and use cases that may be downloaded, and the scripts are also given by the author to anyone who is interested in trying it out. (Beran 2017) 3.3.8 Google chart A free and powerful integration of all Google power. The tool is rendering the resulting charts to HTML5/SVG, so they are compatible with any browser. Support for VML ensures compatibility with older IE versions, and the charts can be ported to the latest releases of Android and iOS. What’s even more important, Google chart combines the data from multiple Google services like Google Maps. This results in producing interactive charts that absorb data real-time and can be controlled using an interactive dashboard (“Top 4 Big Data Visualization Tools” 2018). 3.4 Special Topics 3.4.1 Data Mining and Data Visualization (EDUCBA 2018) According to a paper in 2018, we can tell the difference between data mining and data visualizations. Here is a chart that helps us understand this better. Data Mining involves different processes such as data extraction, data management, data transformations, data pre-processing, etc. Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. The author has also listed top 7 comparisons between data mining and data visualization, and 12 key differences between them. The article provides a very clear understanding of each of these techniques. BASIS FOR COMPARISON Data Mining Data Visualization Definition Searches and produces a suitable result from large data chunks Gives a simple overview of complex data Preference This has different applications and is preferred for web search engines Preferred for data forecasting and predictions Area Comes under data science Comes under the area of data science Platform Operated with web software systems or applications Supports and works better in complex data analyses and applications Generality New technology but underdeveloped More useful in real time data forecasting Algorithm Many algorithms exist in using data mining No need of using any algorithms Integration Runs on any web-enabled platform or with any applications Irrespective of hardware or software, it provides visual information 3.5 Data Visualization in Business 3.5.1 Data Visualizations in Industry Companies tend to rely on dashboards (a compilation of several related data visualizations) to give them high-level insights on company-wide, market-level, or employee-level performance. The following are some common applications of dashboards in business. Application Description Sales &amp; Marketing This is one of the most popular uses for dashboards. Companies like to regularly track their revenue, conversions, lead sources, etc. and rely on data visualization to synthesize these large and constantly updated data into visual summaries.Funnel reporting in terms of sales velocity and efficiency, Camparing ROI, distribution of opportunities and leads across region, time, etc are some of the matrices which requires dashboards and visualization on latest as well as historic data. Sales and Marketing teams are one of the major consumers of BI tools driven reporting and monitoring dashboards. Customer Success These dashboards can be created by the team, but are also often built into customer service platforms such as Zendesk. They include various KPIs of the customer success team, such as the ratio of tickets open to tickets closed and time to resolution. Product Management These dashboards tend to synthesize sales, marketing, and customer research data together and are typically used for executive reporting. The visuals display metrics such as dollars and hours devoted to various projects and most requested features by customers. Data visualization is also used across many different industries. One popular area right now is healthcare, especially involving big data. The benefits and uses of interactive data viz are detailed in a paper from the University of Maryland (2013). (Schneiderman 2013) The paper highlights three types of data that can and should be visualized to help in decision-making: personal, clinical, and public health information. Examples include: exploration of prescription patterns of different drugs and tracking personal health and fitness statistics. (Even the nice, clean Fitbit app home screen is a comprehensive dashboard!) Importantly, making sense of all this data collected from individuals will help healthcare organizations and companies provide more personalized and effective health treatment. 3.5.2 How visualization impacts Industry/business (Lazarevich 2018b) According to an Experian report, 95% of U.S. organizations say that they use data to power business opportunities, and another 84 percent believe data is an integral part of forming a business strategy. Visualization helps data impact business in following ways: 3.5.2.1 Cleaning The simplest way to explain the importance of visualization is to look at visualization as a means of making sense of data. Even the most basic, widely-used data visualization tools that combine simple pie charts and bar graphs help people comprehend large amounts of information fast and easily, compared to paper reports and spreadsheets. In other words, visualization is the initial filter for the quality of data streams. Combining data from various sources, visualization tools perform preliminary standardization, shape data in a unified way and create easy-to-verify visual objects. As a result, these tools become indispensable for data cleansing and vetting and help companies prepare quality assets to derive valuable insights. Data cleansing is typically done by using instance reduction techniques. Instance reduction: It helps to reduce the size of the data set without compromising the quality of insights that can be extracted from the data. It removes instances and generates new ones to make the data set compact. There are two major instance reduction algorithms: Instance selection: It is used to identify the best examples from a very large dataset with many instances in order to curate them as the input for the analytics system. It aims to select a subset of the data that can act as a replacement for the original dataset while completely fulfilling the goal. It will also remove redundant instances and noise. Instance generation: It involves replacing the original data with artificially generated data in order to fill regions in the domain of an issue with no representative examples in the master data. A common approach is to relabel examples that appear to belong to wrong class labels. Instance generation thus makes the data clean and ready for the analysis algorithm. Tools you can use: Drake, DataWrangler, OpenRefine 3.5.2.2 Extraction Known versatile tools for data visualization and analytics like Elastic Stack, Tableau, Highcharts, and more complex database solutions like Hadoop, Amazon AWS,and Teradata, have wide applications in business, from monitoring performance to improving customer experience on mobile tools. The new generation of data visualization based on AR and VR technology, however, provides formerly unfeasible advantages in terms of identifying patterns and drawing insights from various data streams. Building 3D data visualization spaces, companies can create an intuitive environment that helps data scientists grasp and analyze more data streams at the same time, observe data points from multiple dimensions, identify previously unavailable dependencies and manipulate data by naturally moving objects, zooming, and focusing on more granulated areas. Moreover, these tools allow us to expand the capabilities of data visualization by creating collaborative 3D environments for teams. As a result, new technology helps extract more valuable insights from the same volume of data. Data has shown phenomenal growth over the past decade and its widespread application by businesses as a growth catalyst continues to deliver positive results. The scale of data is massive and the volume, velocity, and variety of data call for more efficient processing to make it machine-ready. Although there is a multitude of ways to extract data such as public APIs, custom web scraping services, internal data sources, etc., there would always remain the need to do some pre-processing to make the data perfectly suitable for business applications. Data pre-processing techniques like: Data cleansing Data Manipulation Data normalization Data Transformation Missing values imputation Noise identification Minimizing the pre-processing tasks play a key role in the process. 3.5.2.3 Strategizing As the amount of data grows, it becomes harder to catch up with it. Therefore, data strategy becomes the necessary part of the success in applying data to businesses. Then how data visualization become an important tool in your strategic kit? First, it helps you clean your data. Secondly, it allows you to identify and extract meaningful information from it. Finally, data visualization tools enable continuous real-time monitoring of how your strategy and now data-driven decisions influence performance and business outcomes. In other words, these tools visualize not only the data, but also the results, and help correct and optimize strategy on the go. Data visualization is one of the initial and most important steps made to derive value from data. It determines how efficiently analysts can work with data assets, what insights they are able to extract and how their data strategy will develop over time. Therefore, the quality and capabilities of data visualization directly influence how data impacts your business strategy and what benefits data applications can bring to the companies and their industries. 3.5.3 Corporate Scorecards and Data Visualization Corporate transparency, flat organizations, open book policies, etc. are terms executives and entrepreneurs learn about all the time (Boost Labs 2015). As the corporate world shifts towards a more open culture, the demand for open data and insights have increased dramatically. This shift has helped the overall corporate strategic planning and management process easing the alignment of business activities towards a series of goals. Being transparent top down aligns the culture to sail towards the same North Star. The growth of corporate transparency is not only important internally, but externally as well. Corporate certifications like B Corporations certifications (B Corp), require companies to provide a transparent view of their social conscious efforts to the general public. Achieving the certification is one step of the process; the true goal is to show the world how and why the certification is truly deserved. Here’s the process on how to get it done. Step Name Description 1 Perform Data Discovery and Determine the Story Before this step it is easy to underestimate the effort level it takes to pull the best insights from the data. Data manipulation products like Tableau, Domo, Pentaho, IBM’s Many Eyes, and R, among others, make insight extraction that much easier to gain understanding of data using a visual medium. The key is to start with a simple portion of your data and to start pulling basic insights to visualize and correlate with each other. This process leads towards a compound series of questions, which helps provide an overall vision to the end product. We see the effect during our discovery process, which leads to unforeseen avenues for data intelligence. 2 Data Infrastructure Setup Data infrastructures can be simple or complex depending what the end goal is. Many clients prefer to go the route of complete data integration in order to centralize their data repositories. Technologies such as Hadoop have helped by unifying disparate data sources, but other options such as data cloud environments can help produce API’s for future product deployments. Why is this important? Accessibility of data is an important foundation not only within the context of dashboards, but also the possibility of branching out to other products. 3 Product Design &amp; Development Wireframing, prototyping, and application development are the main engines to transform an idea into a final product. Products can range from static presentations/reports to full interactive applications. Mobile, tablet, TV, and workstation platforms can all be mediums to help deliver the final product. The secret to a great end product is how well the data story is conceptualized. If the story is weak then the end product will also suffer. 4 QA &amp; Product Release The best part of any project is to get it finalized and released for all to see. All data gets verified for accuracy, functionality testing (if applicable), application flow (if applicable), design testing, and remaining items are all completed. The end result is an engaging visual product for all intended audiences to see and use. 3.6 Special Topics 3.6.1 Typography and Data Visualization Typography is the art and technique of arranging type to make written language legible, readable and appealing when displayed. (WIKI) The arrangement of type involves selecting typefaces, point sizes, line lengths, line-spacing (leading), and letter-spacing (tracking), and adjusting the space between pairs of letters. 3.6.1.1 Preattentive visual attributes and typography While data components such as quantitative or categorical data are commonly represented by visual features like colors, sizes or shapes, utilization of boldface, font variation, other typographic elements in data visualization are less prevalent. Preattentive attributes are those that perceptual psychologists have determined to be easily recognized by the human brain irrespective of how many items are displayed. Therefore, “preattentive visual attributes are desirable in data visualization as they can demand attention only when a target is present, can be difficult to ignore, and are virtually unaffected by load.” Examples of preattentive attributes are size/area, hue, and curvature. This brings us to the disparate situation of the popularity of visual aspects like color and size and typographic aspects such as font variation, capitalization and bold. The authors present several possible reasons for this, beginning with the preattentiveness of visual attributes like size and hue. However, some typographic attributes such as line width or size, intensity, or font weight (a combination of the two) are considered preattentive as well. Furthermore, these visual attributes are inherently more viscerally powerful, and they are easy to code in a variety of programming languages. Technology has also perhaps previously limited the use of typographic attributes, for only recently have fine details such as serifs, italics, etc. been made readily visible to the audiences of data visualizations by technological advances. 3.6.1.2 Why typography is not currently popular in data visualizations The authors remark that it is possible the lack of variety of typographic elements used in data visualizations is due to the limited knowledge of computer scientists and other individuals pursuing data visualization in how to apply these elements effectively. While the first few proposed explanations make sense from personal experience with technology and exposure to data visualizations and design in general, the hypothesis that lack of knowledge of typographic elements in data visualization seems more plausible if it was being applied to a small group of people rather than all of the data visualization design community. It is more likely that the use of typographic elements in data visualization is less popular because there are fewer instances in which it can be used appropriately, or a status quo bias if current visual attributes are received well, the prevailing attitude may be not to fix what is not broken. However, the authors also point out that despite the dearth of typographic attributes in data visualization, other spheres like cartography, mathematics, chemistry, and programming have a rich history with type and font attributes that informs the scope of the parameter space? 3.6.1.3 Tips for using typographic attributes in visualizations The authors continue by pointing out some tips for using typographic attributes to encode different data types, since certain attributes may be suited to particular purposes. For example, font weight (size and intensity) is ideal for representing quantitative or ordered data, and font type (shape) is better suited to denote categories in the data. Furthermore, as in typography and cartography, use of typographic attributes in data visualization raises concerns of legibility and the ability to read lines and blocks of words. Often, interactivity of a visualization will not only improve functionality, but also provide a solution to readability issues by providing a means to zoom in on small text. There are a few examples of unusual/innovative use of typography for data visualization in the article, not all of which we agree are made more effective by the interesting utilization of typographic attributes, but the “Who Survived the Titanic” visualization’s use of typographic attributes allowed it to not only answer macro-questions very quickly, such as if women and children were actually first to be evacuated across classes, but also to provide answers to micro-questions, like whether or not the Astors survived. It used common visual elements like color and area to indicate whether or not a person survived and number/proportion of people, as well as typographic aspects like italic and simple text replacement to indicate gender and the passengers’ names. 3.6.1.4 Criticisms of typography The authors round out the article by addressing the most common criticisms of typography in data visualization, the foremost one being whether or not text should even be considered an element of data visualization, since visualization connotes preattentive visual encoding of information, and text or sequential information necessitates more investment of attention to understand. Another criticism is that textual representations are not as visually appealing even when used effectively. However, the authors counter that &quot;this criticism indicates both the strength and weakness of type? that while text may not be suited for adding style or drama to a visualization, it can be particularly powerful in situations where a finer level of detail is needed, without sacrificing representation of higher-level patterns. Lastly, a label length problem is common when using text in visualizations; differing lengths of names or labels may skew perception so that longer labels seem more important than shorter labels. This problem was encountered in the Titanic visualization with the varying lengths representations of passengers’ names and was corrected by only including a given name and a surname, the length of which could only vary so much. 3.6.2 Infographics vs. Data Visualizations Data visualization and infographics both present visual information to users. While their purposes may seem similar, they actually have different use cases. This article explains the differences between an infographic and a data visualization (Pritchard 2016). 3.6.2.1 Data Visualization vs Infographics Data visualization usually involves the presentation of summary statistics using visual forms such as graphs, plots or charts; its goal is to provide clear and succinct information about your research. Data visualization also typically focuses on the two important aspects of data and design. However, design should actually depend on the data itself; for example, the type of chart used in a data visualization should be selected based on which one best displays the particular data set. Since visualizations are important in telling stories (such as trends), it should avoid adding extraneous and distracting details. Data visualizations should be self-explanatory, and users should be able to draw conclusions on their own. An infographic on the other hand, is typically a combination of illustrations, facts, and text. Infographics might include some components characteristic of data visualization, but in general feature a less data-driven storytelling. While infographics are not grounded in data, like data visualizations, infographics convey several ideas simultaneously; and like data visualization, the design should be both visually appealing and should be based in the function of conveying the visual story. Furthermore, as in typography and cartography, use of typographic attributes in data visualization raises concerns of legibility, the ability to understand both individual characters and commonalities that identify a font family, and readability, the ability to read lines and blocks of words. Often, the interactivity of a visualization will not only improve functionality but also provide a solution to readability issues by providing a means to zoom in on small text. 3.6.2.2 When Should You Use Infographics or Data Visualization? While both infographics and data visualizations have their own distinct use cases, more often than not they can be used together. Some of the effective ways to choose between them are described below. Use Case Best Visual Representation Rationale Newsletters Data Visualization Newsletters have to catch the interest of viewers. Putting good data visualizations in newsletters makes them more interesting and includes informative details such as a company’s unique findings, statistics, or status. White papers &amp; eBooks Data Visualization Including data visualizations can help support the argument you make in the document. Annual Reports Data Visualization Things like an overview of past year, success stories, and company performance can be done well using data visualization. Blog Posts Infographic Blog posts are generally written for a specific purpose. Including infographics can reinforce the point you are trying to make. Case Studies Infographic Paired with a case study, an infographic can provide engaging visuals and succinctly summarize a lengthy report, offering valuable insights to readers. Marketing Content Infographic Marketing content generally tells a story. The best way to tell a story is using proper infographics. These can be great for social media campaigns since infographics can display all the main points. 3.6.3 Handbooks to improve your visualization design How do we turn findings from a dense spreadsheet into something that really makes our point? Good information design is the key. There are many free handy ebooks that offer guidance. The ones listed below might not relate to data viz directly, but can guide us in designing better visualizations. Design’s Iron Fist by Jarrod Drysdale (Drysdale 2016) The free ebook, Design’s Iron Fist, is a collection of Drysdale’s previous work all wrapped up in one neat little package. Aside from practical tutorials and processes, this book also offers help on how to get into the mindset of being a truly great designer. The Creative Aid Handbook by Koo Roo (Roo 2013) Creativity doesn’t just happen overnight. It’s something that each and every designer has to work at on a day-to-day basis. If you find that your innovative juices are running dry, The Creative Aid Handbook could be the answer. The helpful guide looks at how you can boost your intellect, foster your well-being, and, most importantly, become more creative. Designbetter.co by InVision (Invision 2018) InVision released three fantastic design books that are available for free. Each book discusses various aspects of design like design process, management, and business. Moreover, some of the materials are available in audio format. Type Classification (“Type Classification Handbook” 2008) Type Classification is a helpful beginner’s guide to typography. It provides the foundations of typography and covers a history of each of the type forms. 3.7 Contemporary Research Results &amp; What’s Next With the development, studies and new tools applied in data visualization, more people understand it matters. But given its youth and interdisciplinary nature, research methods and training in the field of data visualization are still developing. So, we asked ourselves: what steps might help accelerate the development of the field? Based on a group brainstorm and discussion, this article shares some of the proposals of ongoing discussion and experiment with new approaches (???): New Approach Description Adapting Publication and Review Process As the article states, “both ‘good’ and ‘bad’ reviews could serve as valuable guides,” so providing reviewer guidelines could be helpful for fledgling practitioners in the field. Promoting Discussion and Accretion Discussion of research papers actively occurs at conferences, on social media, and within research groups. Much of this discussion is either ephemeral or non-public. So ongoing discussion might explicitly transition to the online forum. Research Methods Training Developing a core curriculum for data visualization research might help both cases, guiding students and instructors alike. For example, recognizing that empirical methods were critical to multiple areas of computer science, Stanford CS faculty organized a new course on designing Computer Science Experiments (Klemmer and Levis 2011). Also, online resources could be reinforced with a catalog of learning resources, ranging from tutorials and self-guided study to online courses. Useful examples include Jake Wobbrock’s Practical Statistics for HCI and Pierre Dragicevic’s resources for reforming statistical practice. References "],
["case-studies.html", "Chapter 4 Case Studies 4.1 Introduction 4.2 Geographic Visualizations 4.3 Demographic Comparisons 4.4 Visualizing Urban Data for Social Change 4.5 Animated Data Visualization 4.6 Dust in the Wind: Visualization and Environmental Problems 4.7 Language 4.8 Political Relationships 4.9 Uncategorized", " Chapter 4 Case Studies This chapter explores some interesting case studies of data visualizations. Critiquing these case studies is a valuable exercise that helps both expand our knowledge of possible visual representations of data as well as develop the type of critical thinking that improves our own visualizations. Furthermore, the examination and evaluation of case studies help show that new designs are just as usable as existing techniques, demonstrating that the field is suitable for future development. 4.1 Introduction Visualization is like art; it speaks where words fail. The usefulness of data visualizations is not just limited to business and analytics; visualizations can explain almost anything in the world. Wars, rescue operations, social issues, etc. can be visualized to synthesize the details important details relevant to the issues. In particular, phenomena like the Syrian war, the number flights during Thanksgiving in the USA, the controversy of ‘#OscarsSoWhite,’ etc. present such complexity that we can write endless paragraphs and still fail to convince readers. Below are visualizations of some of these important and complex topics - visualizations that are much more persuasive than an essay, and with a tiny fraction of the text. Many of the case studies mentioned below come from the following articles: Source Description (Nathan Yau 2015a) This source picks the top 10 best data visualizations of 2015. For each pick, the author displays the project plot and also describes his reasoning for choosing that chart as an exemplary visualization. This article is useful for getting a basic understanding of what characteristics a good visualization should include. (Kayla Darling 2017) The author has chosen fifteen of the best infographics and data visualizations from 2016 and explained the reasoning behind these choices. (Crooks 2017) This author has chosen 16 examples of data visualization that demonstrate how to represent data in a way that’s both compelling and easy to digest. (Stadd 2015) These 15 data visualizations show the vast range that data analysis is applicable to, from pop culture to public good. Take a look at them to get inspiration/understanding for your own work. (Chibana 2016) This source includes 15 data visualizations that cover current events, including politics, Oscar nominations, and immigration. (Andy 2009) Vizwiz is a blog about Tableau-based data visualization. It has case studies about how to improve visualizations, written by Andy Kriebel, a famous Tableau Zen Master. This blog is recommended because it is not only practical but also full of insights. One of the best parts of this blog is the “Makeover Monday,” which develops a new visualization based on an original one. This blog also includes excellent tips for and examples of Tableau. Viz of the Day Tableau has a gallery that displays great data visualization examples created by Tableau. It is useful to see how people are using all kinds of data to create informative yet fun data visuals. Data being used is also attached to the example so we can try to mimic what other people did as well. 4.2 Geographic Visualizations Often, people use maps to visualize data that should not be mapped. Here are some examples of when a map visualization is a good choice. 4.2.1 Spies in the Skies The map below is from a Buzzfeed article (Aldhous and Seife 2016) that shows how common it is for the government to observe people. It was filled with red and blue lines (representing FBI and DHS aircraft, respectively) which illustrate the flight paths of the planes. When planes circle an area more than once, the circles become darker. The circles change by day and time, and individual cities can be typed into a search bar to see the flight patterns over them. The visualization rather creatively looks almost like a hand-drawn map. While presenting an ordinarily uncomfortable topic, this allows individuals to check things for themselves, hopefully providing some peace of mind. Reference: (Kayla Darling 2017) New York Flight Patterns 4.2.2 Two Centuries of U.S. Immigration This interactive map from (Galka 2016) shows the rate of immigration into the U.S. from other countries over the last 200 years in 10-year segments. Each colored dot represents 10,000 people coming from the specified country. Countries then light up when they have one of the highest rates of migration. A tracker on the left indicates what countries sent the most people to the U.S. at what times. This is a good visualization because it is engaging and easy to read and interpret. The movement of the dots draws the reader’s attention while the brightly lit countries make it easy to pick out the highest total migrations. The bright colors and dark background help the information stand out. This map is a bit simple, but effective. Reference: (Kayla Darling 2017). US Immigration 4.2.3 Uber: Crafting Data-Driven Maps Map visualization is essential for companies like Uber that need to track metrics using geo-space points. In this article, the designer from Uber talks about the challenges of designing such visualizations and the possible solutions (Klimczak 2016). The challenges that Uber faced when crafting geospatial visualizations: There are great individual maps but as a whole lack of consistency across the company. Common graphing tools like Sketch does not support GIS file, which is essential to Uber’s insights. The scale of the framework includes more than 400 cities in the world with a variety of different geographic features and data types. To tackle these problems, Uber started by defining base map themes by optimizing detail, color, and typography. Based on that, data layers are added using scatter plots and hex bins, with careful color selection to help their team make decisions. To make it even better, Uber took a further step by adding trip lines (see images below), which became a signature visualization of Uber. Choropleths are also used to help visualize how metrics and values differ across geographic areas. Uber uses US postal codes as geographic boundaries and infuses various datasets to create the color variation. The visualization in this article is a classic problem of visualizing geographic data. The detailed explanation of the problems and how they are solved can be beneficial for people or startups trying to conceptualize and make appropriate visualizations that support the decision-making process. Uber Route Maps (Source:(Klimczak 2016)) 4.3 Demographic Comparisons One common use of visualization is to compare different groups against each other, such as political parties or generations. 4.3.1 Young Voters, Class and Turnout: How Britain Voted in 2017 This article’s goal is to convey the change in party votes in the 2017 UK general election compared to votes in 2015 (Holder, Barr, and Kommenda 2017). The change in party votes was shown with regards to three demographic factors: age, class, and ethnicity. For each factor, there are four graphs (one per political party), each illustrated in the party’s standard color. The change in the percent of votes is shown as an arrow where the arrow’s shaft is the length of the difference from 2015 to 2017 while the x-axis is the demographic factor split into different bins. This a good visualization because it is straightforward to read and interpret. The color-coding of the arrows and party names makes it easy to pick out the different parties. The index is smartly spread across the visualization to reduce cross-referencing, and color in the graph represents the actual party colors in the campaign. The arrow lengths highlight just how significant of a change happened. For example, in the Age section, it is easy to see the pattern between the Labour party gaining many voters aged 18 to 44 and the Conservative party gaining voters aged 45 and up. UK Party Votes by Age (Source: (Holder, Barr, and Kommenda 2017)) 4.3.2 U.S. Migration Patterns The New York Times data team mapped out Americans’ moving patterns from 1900 to present, and the results are fascinating to interact with (Aisch, Gebeloff, and Quealy 2014). We can see where people living in each state were born, and where people are moving to and from. The groupings of the destinations vary based on that state’s trends, preventing unnecessary clutter while still showing detail when vital, as can be seen by the difference between the charts for California and Pennsylvania. Overall, this type of chart can work well to visualize movement in data over time, such as with migration. However, it must be done carefully to maintain clarity. Too many categories with colors and crossing lines can make it difficult for a reader to keep track of what the data is saying and it can quickly go from a very graphic visualization to a chaotic mess of lines. The designer does a pretty good job with these visualizations by limiting the number of categories in grouping states by region (West, South, Midwest, etc.). However, it is not completely clear why so many crossing lines are necessary for the Pennsylvania chart. The crossing lines, along with the use of the same color for different lines within the same regional categories, can introduce unnecessary complexity. Migration from California Migration from Pennsylvania (Source:(Aisch, Gebeloff, and Quealy 2014)) 4.3.3 The American Workday NPR tapped into American Time Use Survey data to ascertain the share of workers in a wide range of industries who are at work at any given time (Quoctrung Bui 2014). The original question of when Americans work, rather than the number of hours worked, is answered in the graph. The chart overlays the traditional 9 AM-5 PM standard workday as a reference point, helping the audience draw exciting conclusions. Below is a screenshot of the data product; the original graph is more interactive and allows the audience to explore when people are working for different occupations. Some interesting findings include: 1. Construction workers both start and finish their workday earlier and generally do not work at lunch hours as there is a massive drop at noon. Servers and cooks’ schedule are the opposite of all other occupations with the peak from lunch through the evening. Protective services, e.g., police officers, firefighters, and detectives, have many workers working throughout the night, which is entirely different from all other occupations. This data product is an excellent example because the analytic design has been applied to contrast specific occupations to the traditional 9-5 working hours. This is easy to understand and make particular occupations stand out more manageable. The use of color for highlighting the selected occupation in the graph helps to categorize different occupations as well. 4.3.4 How People Like You Spend Their Time This visualization from (Yau 2016) lists several categories such as “personal care” and “work” along one side of a graph with a line illustrating the amount of time the average person in a particular demographic spends on each subject. Entering different parameters at the top, such as changing gender or age, causes the lines to shift to feature that demographic. The simplicity of this visualization helps the information get across and avoids bogging down the statistics. Sometimes, less is more. Reference: (Kayla Darling 2017) 4.3.5 Britain’s Diet In Data This is an excellent example about how to present a significant amount of comprehensive data - distributed across different categories and measured in different metrics - in a simple yet effective manner, while still maintaining interest and aesthetics. The data product attempts to show how the average Briton’s diet has changed over the last four decades for the better (Institute 2016). It does this by displaying simple trend lines that show that more harmful and fatty foods are being consumed less while consumed more healthier and leaner foods. It further breaks down every major food category into tens of its constituent products, and in both the overview and deep-dive versions, provides further levers to massage more meaning out of the data. It also shows how the contribution of different foods to the typical diet has changed over the years. Here, we can toggle the year to see exactly how much of each food was consumed, again with another deep-dive into the constituents of every primary food group. Source: (Institute 2016) Such a visualization is ideal for a layman who would want to walk away with an immediate and accurate understanding of the overall dietary changes. It also provides plenty detail on demand for the more discerning viewer who might have more time and inclination to dissect and parse through the graphs. It is difficult to use the same data product to cater to both types of viewers in such an adequate capacity, which is what makes this particular data product so impressive and useful. It satisfies the principles of graphical excellence as stated by Edward Tufte : &gt;“Graphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space.” Reference: (Tufte 1983) 4.3.6 Selfie City Selfie City, a detailed multi-component visual exploration of 3,200 selfies from five major cities around the world, offers a close look at the demographics and trends of selfies (Manovich et al. 2014). This project is based on a unique dataset compiled by analyzing tens of thousands of images from each city, both through automatic image analysis and human judgment. The team behind the project collected and filtered the data using Instagram and Mechanical Turk. Rich media visualizations (imageplots) assemble thousands of photos to reveal interesting patterns. It provides a demographic and regional comparison of selfies. Estimated Age and Gender Distribution (Source: (Manovich et al. 2014)) 4.3.7 Evolving Demographics Another frequent use is to look at how something changes over time. Time-series data can be shown many ways, and these are some examples. 4.3.7.1 Millennial Generation Diversity CNNMoney created an interactive chart using U.S. Census Data to show the size and diversity of the millennial generation compared to baby boomers (Kurtz and Yellin 2018). While the article’s main point is that the millennial generation is bigger and more diverse than the baby boomer generation, it also contains information about all of the other living generations. It turns hard numbers into an intriguing story, illustrating the racial makeup of different age groups from 1913 to present. The author also summarized three key findings from the graph: 1| The most common age in the US is 22 years old. 2| The median age in the US is 37.6 years old. * 3| Among the youngest generation, only 50% of the population is white with the potential of dropping from the biggest race in the US. Racial Diversity of US Generations (Source:(Kurtz and Yellin 2018)) This is an effective graph because while it contains many data points, it makes the overall trends very clear without sacrificing much detail. You can see the drop in some white people and the increasing growth of the other racial categories. 4.3.7.2 How the Recession Reshaped the Economy, in 255 Charts The first large graph contains 255 lines to show how the number of jobs has changed for every industry in America, using color to highlight the lines and let viewers see the specifics for each industry (Ashkenas and Parlapiano 2014). By hovering over a line, viewers can get the detailed information of that industry’s job trend. Keeping this extra data hidden until needd will make it easier for readers to absorb the bigger picture from this vast data visualization. Following charts are subsets categorized by job sector and sub-industries. Readers can choose the industry or sector they are interested in and, similar to the first graph, view the more detailed information by hovering over a line. (Source:(Ashkenas and Parlapiano 2014)) 4.3.7.3 An Aging Population: Projected Number of Children and Older Adults An aging population is always a hot topic in social economics and politics (United States Census Bureau 2018). Here we explore a collection of data visualizations showing the aging population in the U.S. and the world. (Source:(United States Census Bureau 2018)) This example includes a bar chart and a line graph to demonstrate the aging population compared with the population of children. This visualization allows easy comparison, employs color to differentiate the categories, and highlights the intersection point. 4.3.7.4 From Pyramid to Pillar: A Century of Change, Population of the U.S. This is a population pyramid. “A population pyramid is a pair of back-to-back histograms for each sex that displays the distribution of a population in all age groups and in gender” (Bureau 2018b). It is good to visualize changes in population distributions (sex, age, year). The shape of a pyramid is also used to represent other characteristics of a population. To illustrate, A pyramid with a very wide base and a narrow top section suggests a population with both high fertility and death rates. It is a useful tool to make sense of census data. (“An Aging Population,” n.d.) offers an animated pyramid. Comparison of aging population in US and Japan (Source:(“An Aging Population,” n.d.)) This is an animated and multiple-population pyramid. It used to compare different patterns across countries. One additional benefit for the interactive population pyramid is that it shows the shape changes by year, which is useful for time-series comparison. A similar project with R code is here. 4.3.7.5 Music Timeline Google’s Music Timeline illustrates a variety of music genres waxing and waning in popularity from 2010 to the present day, based on how many Google Play Music users have an artist or album in their library, and other data such as album release dates (Google 2014). One useful feature of this graph is the reader’s ability to explore one specific genre and its subgenres at a more detailed level, as well as view the general timeline of all music. The drill-down interaction allows for more details without cluttering the overview of the visualization. Embedding the graph with names (e.g., Rock/Pop) makes similar color lines easy to distinguish. (Source:(Google 2014)) 4.4 Visualizing Urban Data for Social Change (Neira 2016) One field in which visualization can have a meaningful social impact is promoting understanding of and generating discussions around cities. With the development of a city, demographic changes, economic, environmental and social problems become important issues. Visualization plays an important role in promoting understanding of how the cities and the societies within them work, debating the problems that cities face, and engaging citizens to work toward their dream cities. Recently, as part of Habitat III side event , LlactaLAB - Sustainable Cities Research Group, presented a project called Live Infographics. It was an interactive methodology that put citizens and experts opinions about the New Urban Agenda on one platform to help generate a ‘horizontal governance’. The different opinions were materialized with a dynamic map to visualize the generated data. The primary objective of the project is to generate citizen-led data collection and to enable governments to build a better understanding of public sentiment, and then engaging people in the process. A great Urban Data Visualization ought to have the capacity to start “Sociological Imagination”. It should provoke individuals to consider how their individual choices, issues, struggles, and in general their daily lives, are a extension of society, and how their choices collectively influence public opinion. As urban areas continue to develop, diverse and complex issues evolve along with them. Disparity, isolation, loss of biodiversity and environmental quality, etc. are all important but thorny issues, and finding successful solutions will require uniting strategy producers, academics, designers, and citizens. Visualization, if done right, can help jumpstart important discussions between these diverse groups of people and help solve the issues that emerge as the world becomes more urbanized. 4.5 Animated Data Visualization Like evolving demographics, these visualizations are demographics that change over time. These, however, are self-animated instead of interactive. 4.5.1 A Day in the Life of Americans This animated data visualization shows the time people spend on daily activities throughout the day (Nathan Yau 2015b). The plot is simple and easy to interpret, but it also includes a good number of variables including time, activity type, number of people doing each activity, and the order in which activities are done. One of the plot’s biggest strengths is that by using one dot to represent each person in the study and using animation, we can drill down to the level of an individual and follow him or her throughout the day. The accumulation of dots for each particular activity also gives us an aggregate-level view of the same data, so that we get both individual and aggregate insights. A drawback of the plot is that it is hard for our eyes to keep track of 1000 simultaneously moving dots. The author of the post addresses this by creating subsequent plots with stationary lines at crucial times of the day. This represents people’s movements from one activity to another without overwhelming the reader. Overall, this is an engaging, informative, relevant, and fun animated plot that tells a story. (Source:(Nathan Yau 2015b)) 4.5.2 Hans Rosling’s 200 Countries, 200 Years, 4 Minutes Global health data expert Hans Rosling’s famous statistical documentary “The Joy of Stats” aired on BBC in 2010, but it is still turning heads. In the remarkable segment “200 Countries, 200 Years, 4 Minutes”, Rosling uses augmented reality to explore public health data in 200 countries over 200 years using 120,000 numbers, in just four minutes (Rosling, Hans 2010). Screenshot from “200 Countries, 200 Years, 4 Minutes” (Source:(Rosling, Hans 2010)) What makes this visualization so well-known is its use of animation and narration to highlight different stories within the overall data. While the visualization could have been made as an interactive chart where the audience can select the year, instead it is a video. Rosling’s narration of how various regions have fluctuated over the last two hundred years is necessary for his argument since there is no other description or explanation. 4.6 Dust in the Wind: Visualization and Environmental Problems Environmental issues can quickly become extremely complex. When dealing with assessments of site, environmental remediation design, monitoring, environmental litigation, the quantity of data involved can quickly become overwhelming. Maintaining and organizing that data and keep a balance is insufficient. Visualization is the only means for condensing and communicating vast quantities of data. Visualization provides an invaluable tool to communicate complex data in a form that makes it intelligible to all parties. There are many case studies on visualization of environment-related issues. Some of them are mentioned below: 4.6.1 Global Carbon Emissions This data visualization, based on data from the World Resource Institute’s Climate Analysis Indicators Tool and the Intergovernmental Panel on Climate Change, shows how national CO₂ emissions have transformed over the last 150 years and what the future might hold. It also allows the audience to explore emissions by country for a range of different scenarios (World Resources Institute 2014). (Source: (World Resources Institute 2014)) 4.6.2 What’s really warming the world? This case study begins by clearly explaining necessary background information and the analytic questions it seeks to answer. Next, it analyzes each factor separately using both verbal explanations and dynamic graphics to compare the observed temperature movements, and then categorizes related factors into “natural factors” or “human factors.” After that, it combines all the dynamic graphics into one, which makes the results more accessible and more straightforward to compare. Lastly, the authors provide further detailed explanations of dataset sources to support their results. Overall, this case study is straightforward, easy to understand and informative (Roston and Migliozzi 2015) (Crooks 2017). (Source:(Roston and Migliozzi 2015)) 4.6.3 Understanding Plastic pollution using visualization Plastic pollution is the accumulation of plastic products in the environment that adversely affects wildlife, wildlife habitat, or humans. Human usage of plastic has increased manifolds in last few decades. Since plastic is inexpensive and durable, it has a wide variety of uses in our everyday life. Since the 1950’s, an estimated 6.3 billion tons of plastic has been produced, of which only about 9% is recycled (contributors 2019). Usage of plastic in last few decades (Qualman 2017): Plastic has become part of our daily life, and human dependence on plastic has increased over time. The visualization below shows some common plastic products undermining environmental health. (Grün 2016) What is plastic used for. (Grün 2016) With a share of 26 percent, China may be the largest plastic producer in the world; yet the largest plastic consumer is neighboring Japan. The people living in the island nation have consumption that exceeds that of Africa and the rest of Asia combined. Donut chart is a modern version of pie-chart which looks cleaner, and embedded visual imagery makes the distribution easy to understand. (Grün 2016) Plastic Use: Industrial nations top the charts (Grün 2016) This visualization uses a simple line chart to show increasing trends. A positive aspect of this chart is the removal of the vertical grid which creates noise in the visualization when its objective is to show the trend, rather than the numbers. Visualization of Ocean Plastic collection: This worldview visualization shows how much plastic is in our oceans.(Moret 2014) Infographic plastic pollution (ROUTLEY 2018) Infographic plastic pollution (ROUTLEY 2018) How long does plastic remain in the ocean? (Grün 2016) Overall, this visualization is useful in the following ways: It provides content: those plots serve one of the primary purposes of data visualization - storytelling. It naturally leads the audience to understand the effects of plastic pollution. Effective use of charts: the correct use of different types of plots makes the visualization both effective and exciting. Efficient use of color: this visualization is a good example of color playing an essential role in a data visualization by guiding the reader to grasp the relationships in the data. There is no redundant color, and no primary color is missing. 4.7 Language 4.7.1 Green Honey The visualization spans a webpage (Lee 2016) referenced in (Kayla Darling 2017). As you scroll down, the text changes, as do many colored dots that move over the white background. The dots are used to represent not only each colors’ hue but the numbers that fall into each category — for example, what colors are the most famous “base” colors for English and Chinese. The continuous flow of this visualization helps bring it together, allowing users to scroll through the information at their own pace, but also creating a seamless, creative work. (Source:(Lee 2016)) 4.7.2 Linguistic Concepts This case study is about the use of linguistic concepts; it discusses how the data is being used and how visual graphics are used to deliver the central insights. It presents an educational tool that integrates computational linguistics resources for use in non-technical undergraduate language science courses. By using the tool in conjunction with case studies, it provides opportunities for students to gain an understanding of linguistic concepts and analysis through the lens of realistic problems in feasible ways (Alm, Meyers, and Prud’hommeaux 2017). HistoBankVis is a novel visualization system designed for the interactive analysis of complex, multidimensional data to facilitate historical linguistic work (Michael Hund 2015). In this paper, the visualization’s efficacy and power are illustrated utilizing a concrete case study investigating the diachronic interaction of word order and subject case in Icelandic. Much of what computational linguists fall back upon to improve natural language processing and model language “understanding” is the structure that has, at best, only an indirect attestation in observable data. The sheer complexity of these structuresl and the observable patterns on which they are based, however, usually limit their accessibility, often even to the researchers creating or studying them. Traditional statistical graphs and custom-designed data illustrations fill the pages of CL papers, providing insight into linguistic and algorithmic structures, but visual ‘externalizations’ such as these are almost exclusively used in CL for presentation and explanation. There are particular statistical methods, falling under the rubric of “exploratory data analysis,” and visualization techniques just for this purpose are available. However, these are not widely used. These novel data visualization techniques offer the potential for creating new methods that reveal structure and detail in data. Visualization can provide new methods for interacting with large corpora, complex linguistic structures, and can lead to a better understanding of the states of stochastic processes. 4.7.3 State of the Union 2014 Minute by Minute on Twitter Twitter’s data team assembled an impressive interactive data hub that depicts how Twitter users across the globe reacted to each paragraph of President Obama’s 2014 State of the Union address (Belmonte 2014). You can slice and dice the data by topic hashtag (for example, #budget, #defense, or #education) and state, resulting in a powerful detailed and cluttered visualization. Since the visualization is about the topic density in a specific time frame, maybe it’s a good idea for us to use this kind of format when we encounter the expression of a poisson distribution. (Source:(Belmonte 2014)) 4.8 Political Relationships 4.8.1 Connecting the Dots Behind the Election This article in the New York Times lists several different candidates and creates compelling visuals that link their campaigns to previous ones (Aisch and Yourish 2015)(Kayla Darling 2017). Each visual contains several different sized dots that represent a specific campaign, administration, or other governmental organization related to the candidate’s current campaign, which is then connected by arrows. Hovering over a specific dot highlights the connections between the groups. This visual is a great way to summarize what would otherwise require a long slog through years of information into an easily accessible and viewable format so that voters can figure out where the candidates’ experiences lie. Clinton 2016 Campaign Staff 4.8.2 A Guide to Who is Fighting Whom in Syria One of the charts shown in the link (Crooks 2017), the visualization of ‘A Guide to Who is Fighting Whom in Syria’ is an exciting graphic to study. The visualization and its report can be seen at (Keating and Kirk 2015). Who is Fighting Whom in Syria (Source:(Keating and Kirk 2015)) This visualization helps elucidate an extremely complicated topic like the Syrian War. It consists of 3 different emojis in three different colors, with each color and facial expression combination showing the ties and conflicts between the various groups involved in the Syrian War. When you click on each emoji, a small dialogue box pops up that explains the relationships between the various countries and rebel groups involved in the war. This is not only easy to understand but is also pleasing to the eyes. On the other hand, the inherent complexity of relationships between different groups make it difficult to understand the complete picture. If the list of involved parties could be sorted by simplified “sides” (such as Syrian Government on one end with Syrian Rebels on the other) or ranked by how liked they are, then it may be easier for a trend to emerge at first glance. Also, the table format of the visualization means that the data is duplicated, making it appear even more complicated. Instead, one side of the diagonal divide could be greyed-out to simplify the audience’s experience with this visualization. Green emoji shows ‘Friendly’ relationship Red emoji shows the ‘Enemies’ relationship Yellow emoji shows ‘Complicated’ relationship 4.9 Uncategorized 4.9.1 Simpson’s Paradox The Visualizing Urban Data Idealab (VUDlab) out of the University of California-Berkeley put together this visual representation of data that disproves the claim in a 1973 suit that charged the school with sex discrimination. Though the graduate schools had accepted 44% of male applicants but only 35% of female applicants, researchers later uncovered that if the data were properly pooled, there was a small but statistically significant bias in favor of women. This is called a Simpson’s Paradox. By “properly pooled,” the investigators meant broken down by the department. For instance, men were more inclined towards science and women towards humanities. When compared to each other, the science departments required more specialized skills while the humanities would accept applicants with a more standard undergrad curriculum, thus creating the Simpson’s Paradox. Simpson’s Paradox originally from vudlab.com (Source:(Lewis Lehe 2013)) 4.9.2 Every Satellite Orbiting Earth This interactive graph, built using a database from the Union of Concerned Scientists, displays the trajectories of the 1,300 active satellites currently orbiting the Earth. Each satellite is represented by a circular icon, color-coded by country and sized according to launch mass (Yanofsky and Fernholz 2015). Low Earth Orbit Satellites (Source:(Yanofsky and Fernholz 2015)) Interactive graph have its own specific advantages. It helps bridge the gap between programmers and non-programmers. This plot is a good example why using interactive graph is a good idea: - It provides an intuitive way for anyone to understand the data regardless of their technical knowledge. - It helps to identifying causes and trends more quickly - It tells a consistent story through data - It improves efficiency of representing data 4.9.3 Malaria The authors of Vizwiz redesigned “The Seasonality of Confirmed Malaria Cases in Zambia Southern Province” by pointing out what works well, what could be improved, and why their new visualization will be better. This chart above showed relation between health facilities and community health worker in Malaria during years. From that chart we can see when summer come cases of malaria increase and it showed a quite clear trend. But through overlapping the two variables, health facilities and health worker it is hard to see each trend. The better way to improve this is use bar chart or line chart to shwo trend of each variable. Also the color it use is quite dazzling and not comfortable, if the chart mean to explain relation of summer temperature this may proper, however it is health related maybe a cool color here is better. Original Version: New Version: The original visualization effectively shows the seasonality of malaria cases but is unclear if the two reporting categories are stacked or one behind the other and is rather garish. The creator of the redesign made the seasonality more obvious by combining the reporting categories and explaining the spikes better. Furthermore, by adding the yearly data split by districts, we can lead to a possible actionable solution to the study of malaria cases in Zambia which is an important objective of visualization. The author has combined the data to find out what the data looks like when combined with health facilities and health workers. And the usage of the color scheme is much more effective than the previous version which makes seasonality more evident. 4.9.4 Is it Better to Rent or Buy? There are many factors involved in deciding to rent or buy a house which has led to many calculators that are supposed to simplify this decision. This calculator includes several sloping charts, each including a factor that will affect how much you will have to pay, such as the individual cost of your home and your mortgage rates (Bostock, Carter, and Tse 2014). A movable scale along the bottom of each chart allows you to enter different data, such as changing the “cost of rent per month” on the side. This can be useful for price comparison: if you can find a similar house to rent for that much per month or less, it is more cost effective just to rent the home. This visualization is incredibly thorough and a useful tool for homeowners of any age and status. (Source:(Bostock, Carter, and Tse 2014)) 4.9.5 An Interactive Visualization of NYC Street Trees Using data from NYC Open Data, this interactive visualization shows the variety and quantity of street trees planted across the five New York City boroughs (Zapata 2014). As the reader hovers over a tree or bar segment, the connected sections light up, making it easier for the reader to look at what otherwise could have been a very dense chart. We can see what some of the familiar and uncommon trees planted in the five boroughs of New York City are. This visualization allows one to see the distribution quickly. One can make inferences based on the distribution, such as trees in the Bronx and Manhattan seem to be distributed more uniformly compared to the other three boroughs. It gives a direct comparison between the five boroughs which could be used to make a compelling decision by the audience. NYC Street Trees (Source:(Zapata 2014)) The interactive visualization is an advantage that enables the display, and intuitive understanding of multidimensional data provides a variety of visualization chart types and enables the audience to accomplish traditional data exploration tasks by making charts interactive. Moreover, this visualization provides a good example: it enables the audience to explore on their own and finds exciting facts about NYC street trees. 4.9.6 Adding up the White Oscars Winners A visualization of all previous winners of the Best Actor/Actress Oscar winners can be seen in an article by Bloomberg (“Adding up the White Oscar Winners” 2016). From the attributes of past Oscars winners, the authors have developed a set of attributes that they believe will continue to be prevalent in future Oscar winners. It is fascinating to see how the article shows the features of the Best Actress, Actor, movies, etc. in a simple and captivating visual. The visualization is interactive, and we can click on each attribute like ‘Hair Color,’ ‘Eye Color,’ etc. to see the features of the actors and actresses who are likely to win the Oscars. Based on different attributes selected, the visualization changes to give you the data specific to the attributes. For each attribute selected, it gives you a fact about the selected attribute related to the Oscar Winner. For instance, when you select the race, it states “In the entire history of the Oscars all but 8 of the Best Actors and Best Actresses have been white”. Similarly, the visualization also gives information about the different aspects of movies that are more likely to win, like ‘Length,’ ‘Month,’ ‘Budget,’ etc., and also predict about the future nominees who are likely to win Oscar. Best Actor and Best Actress Best Picture (Source:(???)) 4.9.7 Kissmetrics blog: visualization of metrics Kissmetrics blog is a place where people talk about analytics, marketing, and testing through narratives and visualization of metrics. Metrics are essential in the real world, especially when developing/promoting products. Visualization of metrics is also essential so that stakeholders can monitor performance, identify problems and dive deep into potential issues. This example from the Kissmetrics blog is about Facebook’s organic reach (Patel 2018). One crucial point discussed in the blog is whether the Facebook’s organic reach is decreasing drastically. The general trend shows that there is a considerable decline in Facebook’s page organic reach. The following graphs show that the engagement is increasing; that is, while the quantity of content is decreasing, the quantity is increasing. (Source:(Patel 2018)) This resonates with what we have learned at class regarding how different perspectives of interpreting data can lead to different conclusions. 4.9.8 Describe Artists with Emoji Using the data from Spotify, the author listed the ten most distinctive emoji used in the playlists related to favorite artists (Insights 2017). The table being used in this visual is very straightforward to link the artist to the emojis and is very easy to compare among artists. When you hover over the emoji, further information is presented. (Source:(Insights 2017)) 4.9.9 Goldilocks Exoplanets Using data from the Planetary Habitability Laboratory at the University of Puerto Rico, the interactive graph on Astrobiology plots planetary mass, atmospheric pressure, and temperature to determine what exoplanets might be home, or have been home at one point, to living beings (Tomanio and Gonzalez Veira 2014). One highlight of the graph is how color has been used. The red dots represent planets that are too hot, the blue dots mean too cold, and the green ones mean just the right temperature. This is very intuitive for people to understand without the necessity to read through the notes. The dots are semi-transparent so the overlapping of planets does not detract from the audience’s ability to read the graph. Additionally, the size of each dot represents the radius of each planet. At first glance, one might assume that most planets are much larger than Eath, but the visualization includes a note explaining that larger planets are easier to find. This is a good example of how much explanation to include in a visualization, not so much that the audience is distracted from the graph but enough that they have the information needed to interpret it. (Source:[Astrobiology]) 4.9.10 Washington Wizards’ Shooting Stars This detailed data visualization demonstrates D.C.’s basketball team’s shooting success during the 2013 season (Lindeman and Gamio 2014). Using statistics released by the NBA, the visualization allows viewers to examine data for each of 15 players. For example, viewers can see how successful each player was at a variety of types of shots from a range of spots on the court, compared to others in the league. (Source:(Lindeman and Gamio 2014)) Generally this is a data visualization for following reasons because it demonstrates complex infomation in a simple and topic-related format. It highlights fact numbers to tell important information. The use of colr is retrained but efficient. However, it is undefined that what is targeted audience. It can also reduce cognitive overload for lines. 4.9.11 Visualization of big data security: a case study on the KDD99 cup data set This paper utilized a visualization algorithm together with significant data analysis to gain better insights into the KDD99 dataset: Abstract Cybersecurity has been thrust into the limelight in the modern technological era because of an array of attacks often bypassing new intrusion detection systems (IDSs). Therefore, deciphering better methods for identifying attack types to train IDSs more effectively has become a field of great interest. Critical cyber-attack insights exist in big data; however, an efficient approach is required to determine strong attack types to train IDSs to become more active in critical areas. Despite the rising growth in IDS research, there is a lack of studies involving big data visualization, which is crucial. The KDD99 dataset has served as a reliable benchmark since 1999; therefore, this dataset was utilized in the experiment. This study utilized a hash algorithm, a weight table, and sampling method to deal with the inherent problems caused by analyzing big data: volume, variety, and velocity. By utilizing a visualization algorithm, the researchers were able to gain insights into the KDD99 dataset with precise identification of “normal” clusters and described distinct clusters of possible attacks. To read the full paper, please follow the reference link: (Ruan et al. 2017) 4.9.12 The Atlas of Sustainable Development Goals 2018 - Data Visualization of World Development (TEAM 2018) This is an exciting source and an excellent visual guide to data and development. It discusses trends, comparisons, and measurement issues using accessible and shareable data visualizations. As the graphs cite below, they are informative and clean: 1 2 The data draws on the World Development Indicators- the World Bank’s compilation of internationally comparable statistics about global development and the quality of people’s lives. For each of the SDGs, relevant indicators have been chosen to illustrate important ideas. The Atlas features maps and data visualizations, primarily drawn from World Development Indicators (WDI) - the World Bank’s compilation of internationally comparable statistics about global development and the quality of people’s lives. The editors have been selected to emphasize on essential issues by experts in the World Bank’s Global Practices. The Atlas aims to reflect the breadth of the Goals themselves and presents national and regional trends and snapshots of progress towards the UN’s seventeen Sustainable Development Goals related to: poverty, hunger, health, education, gender, water, energy, jobs, infrastructure, inequalities, cities, consumption, climate, oceans, the environment, peace, institutions, and partnerships. Contents of this publication: (Group 2018a). The data is available at (Group 2018b). The code used to generate the majority of figures is available at (Whitby 2018). References "],
["patterns.html", "Chapter 5 Patterns 5.1 Outlier Detection 5.2 Tips to Improve Data Visualization 5.3 Charts 5.4 Maps 5.5 Choosing the Right Baseline in Data Visualization 5.6 Using Design Patterns to Find Greater Meaning in Your Data 5.7 Takeaways From Recreating One Chart Using 24 Tools 5.8 Word Cloud 5.9 Dashboards 5.10 Using Visualization Softwares and Libraries", " Chapter 5 Patterns This chapter is a practical guide to a plethora of data visualizations; it explores different types of visualizations and tools and provides helpful tips for using them effectively. 5.1 Outlier Detection (Arribas-Gil and Romo 2014) We can use data visualization for outlier detection in a data set. Different methods for outlier detection in functional data have been developed over the years. Several of these methods rely on different notions of functional depth, robust principal components, or random projections of infinite-dimensional data into R. Some distributional approaches have also been considered (Gervini 2012). In functional data analysis, we observe curves defined over a given real interval and shape outliers may be defined as those curves that exhibit a different shape from the rest of the sample. Other types of outliers include: Outlier Description Global Outliers (or “point anomalies”) A data point is considered a global outlier if its value is far outside the entirety of the data set in which it is found. Contextual (Conditional) Outliers A data point is considered a contextual outlier if its value significantly deviates from the rest of the data points in the same context. Note that this means that the same value may not be considered an outlier if it occurred in a different context. If we limit our discussion to time series data, the “context” is almost always temporal, because time series data are records of a specific quantity over time. Contextual outliers are common in time series data. Collective outliers A subset of data points within a data set is considered anomalous if those values as a collection deviate significantly from the entire data set, but the values of the individual data points are not themselves anomalous in either a contextual or global sense. In time series data, one way this can manifest is as normal peaks and valleys occurring outside of a time frame when that seasonal sequence is normal or as a combination of time series data that is in an outlier as a group. Below is a simple example. Outlier treatment is important because it can drastically bias/change the fit estimates and predictions. # Inject outliers into data. cars1 &lt;- cars[1:30, ] # original data cars_outliers &lt;- data.frame(speed=c(19,19,20,20,20), dist=c(190, 186, 210, 220, 218)) # introduce outliers. cars2 &lt;- rbind(cars1, cars_outliers) # data with outliers. # Plot of data with outliers. par(mfrow=c(1, 2)) plot(cars2$speed, cars2$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;With Outliers&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) # Plot of original data without outliers. Note the change in slope (angle) of best fit line. plot(cars1$speed, cars1$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;Outliers removed \\n A much better fit!&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) Detection of Outliers is performed using: Univariate Approach Multivariate Approach Multivariate Model Approach 5.2 Tips to Improve Data Visualization (French 2017), (Steier et al. 2012), (Evergreen, Stephanie;Metzner, Chris 2013) 5.2.1 Comparison Include a zero baseline if possible. Although a line chart does not have to start at a zero baseline, it should be included if it gives more context for comparison. If relatively small fluctuations in data are meaningful (e.g., in stock market data), you may truncate the scale to showcase these variances. Always choose the most efficient visualization. Watch your placement - You may have two nice stacked bar charts that are meant to let your reader compare points, but if they’re placed too far apart to “get” the comparison, you’ve already lost. Tell the whole story. Maybe you had a 30% sales increase in Q4. Exciting! But what’s more exciting? Showing that you’ve actually had a 100% sales increase since Q1. 5.2.2 Copy Don’t over explain if the copy already mentions a fact. The subhead, callout, and chart header don’t have to reiterate it. Keep the chart and graph headers simple and to the point. There’s no need to get clever, verbose, or puntastic. Keep any descriptive text above the chart brief and directly related to the chart underneath. Remember: Focus on the quickest path to comprehension. Use callouts wisely. Callouts are not there to fill space. They should be used intentionally to highlight relevant information or provide additional context. Don’t use distracting fonts or elements. Sometimes you do need to emphasize a point. If so, only use bold or italic text to emphasize a point — and don’t use them both at the same time. 5.2.3 Color Use a single color to represent the same type of data. Watch out for positive and negative numbers. Don’t use red for positive numbers or green for negative numbers. Those color associations are so strong it will automatically flip the meaning in the viewer’s mind. Make sure there is sufficient contrast between colors. Avoid patterns. Stripes and polka dots sound fun, but they can be incredibly distracting. If you are trying to differentiate, say, on a map, use different saturation of the same color. On that note, only use solid-colored lines (not dashes). Select colors appropriately. Don’t use more than 6 colors in a single layout. - Tips for Color in Visuals Use Case Tip Rationale Numerical Scales Color for numerical scales should be used with caution. The way you interpret a shade depends on the colors around it and sometimes it can lead to false conclusions. Color Associations Color can be used to leverage long-term memory very quickly. We automatically associated strawberries with red. If we can leverage the how people associate different colors with different things, we will not even need a legend to explicitly match color to meaning. Highlights Bright colors can be used to highlight a certain part of the data. Alarming colors draw the eye quickly to areas that need attention. Color Combinations Use contrasting dark and light colors.Combinations such as red–green or blue– yellow should be avoided. This will cause difficulty for people with color blindness (Jager 2019) 5.2.4 Ordering Order data intuitively. There should be a logical hierarchy. Order categories alphabetically, sequentially, or by value. Order consistently. Order evenly. Use natural increments on your axes (0, 5, 10, 15, 20) instead of awkward or uneven increments (0, 3, 5, 16, 50). 5.2.5 Audience Perspective Let the users lead. Know your audience. Designers should consider the way users prefer to understand the information, even in choosing basic analytic approaches. For users to feel comfortable adopting and sharing insights from analytics, they must be able to explain and defend the data. 5.2.6 Use Layers to Tell a Story While style is one form of customization, layering unique data sets on a single visualization can tell a richer narrative and connect users to the data without getting too crowded. On a map, this can be as simple as zooming in and out, but it can also involve drill-downs (choosing a data point and expanding it to show more detail), links and other shortcuts. 5.2.7 Keep It Simple Analytic results shouldn’t be presented to 10 decimal places when the user doesn’t need that level of precision to make a decision or understand a concept. Effective visual interfaces avoid 3-D effects or ornate gauge designs (a.k.a. “chart junk”) when simple numbers, maps or graphs will suffice. 5.2.8 Graph Integrity “Graphics were used as instruments for reasoning quantitative information. With this example, graphical work has come to flourish. Graphical excellence begins with telling the truth about the data (Tufte,2001)”. In Tufte’s “The Visual Display of Quantitative Information” book, an entire chapter is dedicated to graphical integrity in visualizations. Very useful and important examples can be found in the book. Following are some examples: 5.3 Charts 5.3.1 What makes a chart effective? Data visualization is a combination of art and science. When it comes to the artistic aspect, there are no correct answers for doing the visualization. There are many ways to present the data. However, when making sense of facts, numbers, and measurements, a better understanding and effectiveness is promoted by a logical path to follow. To determine the best type of chart is hard for those new to data visualization. Most people learn it by referring to other people’s work without understanding the underlying logic, so they don’t have the theory in their mind to make the judgment. Therefore, before we begin visualizing our data, we need to start with the following: Know the purpose[@ chart_purpose] - (Analytical or Presentation)(Ref-https://research.tableau.com/sites/default/files/Kosara-C4PGV-2016.pdf): It is important to know the purpose of designing a visualization. In many cases, it is designed to explore or analyze data to enable readers to find insights in data themselves. But there are also cases when its purpose is to present and create awareness about certain findings or even to make a decision. For example, when a journalist creates a visualization for reporting on the current weather situation, the goal there is to mainly present the key trends and create awareness among the general public. When climate scientists create visualizations for communicating their results to policy makers on climate change, they are mainly calling for actions. Know your audience[@ chart_audience]: After we know the why we are designing a visualization, it is important to know who are we targeting with that visual. No matter who your intended audience is, it is important to customize it to their needs, interest, level of expertise and analytical ability. Certain factors like their cultural preferences, expertise level, etc., also play a key role in designing an effective visualization. For eg., colors have a special significance in Chinese culture. They use red to represent a dynamic or/and a positive event, such as growing sales in a region, while in most of the western world blue or green represents positive trends, such as sales revenue, etc. Similarly, a visualization designed for a finance analyst will be different from a visual designed for a marketing manager. Therefore, customization is key in ensuring effectiveness of a visualization. Know the right chart type[@ chart_audience]: Once you know the purpose and have identified the target audience, it is important to choose the right chart type. Choosing the right visual, which could be a chart, map, table, dashboard or infographic, ensures that it resonates well with your audience. Also, it empowers the readers to explore the data, identify insights and make decisions after evaluating different scenarios. After answering these questions, you should be able to get a better image of your ideal graph. The simple guidance for using the different types of the chart is - line charts for tracking trends over time, bar charts to compare quantities, scatter plots for a joint variation of two data items, bubble charts showing the joint variation of three data items, and pie charts to compare parts of a whole. However, let’s delve deeper into the various presentation styles and types of common charts. 5.3.2 How to decide which chart type to use? While it is possible that data can be visualized using multiple charts, however, it is important to choose the ‘right’ chart type that clearly and accurately communicates the key message by separating the noise from the data. Remember, data is only valuable if you know how to visualize it and give context. (Infogram, n.d.) There are four basic presentation types that you can use to present your data: A Comparison chart sets two variables against each other and displays the interaction between those two variables. For eg., a line chart displaying the variation of online sales across different months during a given time period. A Composition chart displays how individual parts make up the whole of something. For eg., a pie chart displaying the market share of a phone company by region. A Distribution chart helps to understand outliers, the normal tendency, and the range of values in the dataset. For eg., a column histogram displaying the distribution of grades on a school exam. A Relationship chart tries to show a connection or correlation between two or more variables. For eg., a scatter plot displaying the relationship between marketing spends and sales revenue. To determine which chart is best suited for each of those presentation types, first you must answer a few questions(Gulbis 2016): How many variables do you want to show in a single chart? One, two, three, many? How many items (data points) will you display for each variable? Only a few or many? Will you display values over a period of time, or among items or groups? After you have answers to these questions, you can refer to a chart selection diagram created by Dr. Andrew Abela that should help you pick the right chart for your data type. Let’s move further and review the most commonly used chart types, some example, and the dos and don’ts for each chart type. 5.3.3 Chart Types (Catalogue 2018) This is a survey of the most commonly used chart types, best use cases for each, and pros and cons of each. 5.3.4 Temporal Visualizations (Ayalasomayajula, n.d.) What are some of the most common data visualizations seen in newspapers, textbooks, and corporate annual reports? Graphs showing a country’s GDP growth trends or charts capturing a company’s sales growth in the last 4 quarters would be high up on the list. Essentially, these are visualizations that track time series data – the performance of an indicator over a period of time – also known as temporal visualizations. Temporal visualizations are one of the simplest and quickest ways to represent important time series data. There are 7 handy temporal visualization styles for your time series data. 5.3.5 Line Graph A line graph is the simplest way to represent time series data. It is intuitive, easy to create, and helps the viewer get a quick sense of how something has changed over time. 5.3.6 Stacked Area Chart Stacked area charts are area charts similar to a line chart. In an area chart, multiple variables are “stacked” on top of each other, and the area below each line is colored to represent each variable. Stacked area charts are useful to show how both a cumulative total and individual components of that total changed over time. The order in which we stack the variables is crucial because sometimes, there can be a difference in the actual plot versus the human perception. The figure below is a stacked area chart showing time series data: (Source: (Ayalasomayajula, n.d.)) 5.3.7 Bar Charts Bar charts represent data as horizontal or vertical bars. The length of each bar is proportional to the value of the variable at that point in time. A bar chart is the right choice when you wish to look at how the variable moved over time or when you wish to compare the variable with each other. Grouped or stacked bar charts help you combine both these purposes in one chart while keeping your visualization simple and intuitive. The chart plots the value vertically whereas we perceive the value to be at right angles to the general direction of the chart. In the figure below, a bar graph would be a cleaner alternative. (Source: (Ayalasomayajula, n.d.)) For instance, the grouped bar chart in this interactive visualization of number of deaths by disease type in India not only lets you compare the deaths due to diarrhea, malaria, and acute respiratory disease across time, but also lets you compare the number of deaths by these three diseases in a given year. By switching to the stacked bar chart view, you get an intuitive sense of the proportion of deaths caused by each disease. We can use two different bar charts to represent time series data. 5.3.8 Column Charts for Time Series Data This should be the most popular chart type. This chart is good to do a comparison between different values when specific values are important. Still have hard time to choose? There are many resources online which can help you make the decision. For example, Dr. Andre Abela creates a chart selection diagram that is helpful to pick the right chart depending on the data type. The link of website is]** (Source: (Ayalasomayajula, n.d.)) (Source: (Ayalasomayajula, n.d.)) To avoid clutter and confusion, make sure not to use more than 3 variables in a stacked or group bar chart. It is also a good practice to use consistent bold colors and leave appropriate space between two bars in a bar chart. 5.3.9 Gantt Chart Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. A Gantt chart is a horizontal bar chart showing work completed in a certain period of time with respect to the time allocated for that particular task. It is named after the American engineer and management consultant Henry Gantt who extensively used this framework for project management. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc. by the use of colors and placement of bars in a Gantt chart. The planning of logistics for a dance concert presents a situation in which a Gantt chart is a good option. There are many activities to be completed, some of which will take place simultaneously while some can only be done sequentially. For instance, the choreographers, soundtrack, and dancers need to be finalized before the choreography can begin. However, the costumes, props, and stage decor can be planned at the same time as the choreography. With careful preparation, Gantt charts can help you plan for complex, long-term projects that are likely to undergo several revisions and have various resource and task dependencies. Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc., by the use of colors and placement of bars in a Gantt chart. 5.3.10 Stream Graph Stream graphs are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. (Source: (Ayalasomayajula, n.d.))is essentially a stacked area graph, but displaced around a central horizontal axis. The stream graph looks like flowing liquid, hence the name. They are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. A stream graph showing a randomly chosen listener’s last.fm music-listening habits over time. (Source: (Ayalasomayajula, n.d.)) 5.3.11 Heat Map Heat maps are perfect for a two-tiered time frame – for instance, 7 days of the week spread across 52 weeks in the year, or 24 hours in a day spread across 30 days of the month, and so on. The limitation, though, is that only one variable can be visualized in a heat map. Comparison between two or more variables is very difficult to represent in a heat map. Geo-spatial visualizations often use heat maps since they quickly help identify “hot spots” or regions of high concentrations of a given variable. When adapted to temporal visualizations, heat maps can help us explore two levels of time in a 2D array. This heat map visualizes birthdays of babies born in the United States between 1973 and 1999. The vertical axis represents the 31 days in a month while the horizontal axis represents the 12 months in a year. This chart quickly helps us identify that a large number of babies were born in the latter half of July, August, and September. (Source: (Ayalasomayajula, n.d.)) 5.3.12 Polar Area Diagram Think beyond the straight line! Sometimes, time series data can be cyclical – a season in a year, time of the day, and so on. Polar area diagrams help represent the cyclical nature time series data cleanly. A polar diagram looks like a traditional pie chart, but the sectors differ from each other not by the size of their angles but by how far they extend out from the center of the circle. Polar area diagrams are useful for representing seasonal or cyclical time series data, such as climate or seasonal crop data. Multiple variables can be neatly stacked in the various sectors of the pie. It is crucial to clarify whether the variable is proportional to the area or radius of the sector. It is a good practice to have the area of the sectors proportional to the value being represented. In that case, the radius should be proportional to the square root of the value of the variable (since the area of a circle is proportional to the square of the radius). This popular polar area diagram created by Florence Nightingale shows causes of mortality among British troops in the Crimean War. Each color in the diagram represents a different cause of death. (Check out the text legend for more details.) (Source: (Ayalasomayajula, n.d.)) 5.3.13 Time Series Data and Its Deceptive Potential (“Avoiding Common Mistakes with Time Series” 2015) This article explains how time series data visualization can sometimes be deceptive. It first takes an example of two random time series data and plots them on a graph which gives an impression that the two are strongly correlated. But if we do some statistical testing, the two do not show any relationship, this is an example of “correlation does not necessarily mean causation”. In another set of examples, the author has taken trending two random time series data and shown how even statistical tests can give a wrong interpretation. The article then explains using visualization how a general trended time series can be different than a more controlled and measured trending time series. 5.3.14 Pie Charts: Oportunities and Obstacles (Quach 2016) Using a pie chart is usually considered as a bad idea when it comes to data visualization. However, many agree there is still often relevance to using them 1. Comparison to bar charts Some information may be difficult to distinguish in a pie chart; however, if the data is presented with bar charts, differences in the data presented may be more obvious. (Source: (Hickey 2013)) (Source: (Hickey 2013)) Simple pie charts may not be worthwhile in this situation, but others they may be: (Source: (Bock 2017)) Slicing up data that is already compared to others is a beautiful way to visualize. The method to make pie charts similar to the above is shared by the article writer: (Source: (Bock 2019)) 2. Distinguishing Categories It is difficult to compare the slices of a circle to figure out the distinctions in size between each pie slice, especially when there are many categories. (Source: (Hickey 2013)) The above graph is a case specific to when the labels need to be in a legend to the side of the pie, rather than inside or just outside connected by a line. In these scenarios, the typical method to distinguish is to have the slices ordered by size. When cascaded in order of volume, it is less difficut to match the chart and legend. 3. Pie Chart Manipulation A pie chart is easily manipulated (e.g. using a 3D pie chart). (Source: (Hickey 2013)) This is a possible method to convey a point the data does not represent, however adding a 3-D effect to any visualization might qualify as deceptive and is not specific to pie charts. 4. Simple Pie Charts A pie chart may be useful when comparing two different categories with different amounts of information. Specifically, it does a better job to distinguish two parts with a 25:75 split or one that is not 50:50 as people are sensitive to a right angle or a dividing line that is not straight. However, this could be done more simply by showing two numbers! (Source: (Henry 2017)) (Source: (Henry 2017)) Comparing the need for pie charts to having numbers displayed defeats the purpose of data visualization. The above numbers are very simple, however the graphs created are very poor, created to make a point. Pie charts should have more color and are meant to make simple numbers into a visual that captures the audiance more effectively: (Source: (Henna 2015)) 5.4 Maps Use Maps Only When Effective (Bradshaw 2015) Maps are a popular choice when it comes to displaying geographical data; they are more exciting and engaging than a simple bar or line chart but still easy to comprehend. Maps are attention-grabbing, so at the first glance they seem like a great option. However, just because the data can be represented on a map does not mean that it should be. When used properly, a map can be an excellent choice for illustrating a story. However, if geographic information is not relevant to convey the desired message, then a visualizing your data using a map is actually counterproductive. As with any visual, maps are not a universal solution simply because they are eye-catching. One good use of a map is to show points or specific locations. This use of a map can show how points are distributed and reveal patterns, for example, certain areas having more high-end restaurants. This is not the right approach if the geographic information does not tell a story. If the story is more about comparing data such as median salary, a map is not the most effective. Caution should also be exercised with map visualizations if there are too many points and the data blurs together, causing the data to lose its meaning. Encoding the data is another potential area for confusion. The most popular methods are using color, shape, and size. Again, each of these can be effective when done properly, but many people misuse them. Using too many colors can make the chart harder to interpret. If necessary, data can be grouped into categories such as good and bad or high, medium and low. Shapes should be easily distinguished, so there shouldn’t be too many unique ones. Also, if the use of shapes does not significantly add to the story, it is probably best to remove them. The size of a marker is a clear way to describe amounts but can easily become a problem if there are outliers. Locations with large values could obscure other data points. The best practice is to use just one of these methods rather than combining two or more. Use of maps can be tricky. Geographical data doesn’t imply that a map is the best choice to represent it. Maps can be useful for application where proximity matters, but for straight “what is higher” type comparisons, they’re not very effective since large regions will draw more attention than smaller regions due to more concentrated color. 5.5 Choosing the Right Baseline in Data Visualization (Yau 2013) The baseline is very important to data visualization. If the baseline is different, the appearance of the data may change drastically. Here is a case study to show the importance of baseline: # Create the data. a &lt;-rep(c(2010,2011,2012,2013,2014,2015),each = 4) b &lt;- seq(1:24) c &lt;- c(64.9,65.33,71.67,79.17,68.78,69.83,78.61,92.68,89.28,90.43,97.96,106.96,100.66,107.53,117.06,119.21,110.05,97.42,93.62,97.99,80,88.74,102.06,83) data &lt;- as.data.frame(cbind(a,b,c)) colnames(data) &lt;-c(&quot;year&quot;,&quot;quater&quot;,&quot;sales&quot;) 1. Regular quarterly sales. We see sales decreased a lot around 2014. The baseline here is historical sales. # Regular time series for sales par(cex.axis=0.7) data.ts &lt;- ts(data$sales, start=c(2010, 1), frequency=4) plot(data.ts, xlab=&quot;years&quot;, ylab=&quot;sales&quot;, main=&quot;sales per quater&quot;, las=1, bty=&quot;n&quot;) 2. Quarterly and yearly change sales. The baseline here is zero and look at the percentage changes. # Quaterly change curr &lt;- as.numeric(data$sales[-1]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-1)]) quaChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(quaChange, function(x) { if (x &lt; 0) { return(&quot;#8E1600&quot;) } else { return(&quot;#2cbd25&quot;) } }) barplot(quaChange, border=NA, space=0, las=1, col=barCols, main=&quot;% sales change, quaterly&quot;) # Year-over-year change curr &lt;- as.numeric(data$sales[-(1:4)]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-4)]) annChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(annChange, function(x) { if (x &lt; 0) { return(&quot;#8E1600&quot;) } else { return(&quot;#2cbd25&quot;) } }) barplot(annChange, border=NA, space=0, las=1, col=barCols, main=&quot;% sales change, annual&quot;) From this plot, it is very clear that the magnitude drops in sales for some quarters. 3. The sales difference compare to now. The baseline here is the current sales. # Relative to current 2015 curr &lt;- as.numeric(data$sales[length(data$sales)]) salesDiff &lt;- as.numeric(data$sales) - curr barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;#8E1600&quot;) } else { return(&quot;#2cbd25&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from last quater 2015&quot;) 4. Sales difference compared to the first quarter. The baseline here is the first quater sales. # Relative to first quater ori &lt;- as.numeric(data$sales[1]) salesDiff &lt;- as.numeric(data$sales) - ori barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;#8E1600&quot;) } else { return(&quot;#2cbd25&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from first quater 2010&quot;) 5. The difference between quarter sales and mean. ** The baseline is mean now.** # difference from the mean mean &lt;- mean(as.numeric(data$sales)) salesDiff &lt;- as.numeric(data$sales) - mean barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from mean&quot;) So before we start to plot, we should decide the baseline we want to use. Different baselines will lead to totally different graphs. 5.6 Using Design Patterns to Find Greater Meaning in Your Data (Julie Rodriguez 2016) Visualizations that show comparisons, connections, and conclusions offer analytical clarity. Patterns based on function can help you see differences and similarities more clearly, understand relationships and behaviors more intimately, and predict future results with a greater level of certainty. When these patterns are presented as visualizations, they help you - 1) see comparisons, 2) make connections, and 3) draw conclusions from your data sets. The major functions can be described with the following examples: 5.6.1 Comparisons As shown in Figure 1, the bar chart with sparkline enables you to review the data at two different levels: a high-level assessment of the short-term three-month returns is represented with the bar chart, while the sparkline (the line chart below the bar) provides the details of the historical returns. Quickly and concisely, the sparkline shows you the path that has led up to the most recent returns. You can then assess that a narrow path provides consistent returns across the years while a wide path provides varied returns. Side-by-side comparisons of funds organized into two columns—% Returns and % Ahead of Benchmark—enables peer comparisons and fund-specific benchmark comparisons. Hence, you can see that not only has Global Large-Cap Core provided positive returns, it has also provided the best and most consistent returns when compared to the benchmark. 5.6.2 Connections The string of charts in Figure 2 shows 10-year to year-to-date (YTD) performance returns, which can be interpreted as individual charts or a group of category charts. Similar to sounds waves, the symmetrical area charts grow equidistant from the source (the zero line) at each time interval to accentuate the returns even further. Here, the y-axis is shown in percentage. Instead of using the zero line to indicate positive or negative returns, it uses color to denote if the category returns are positive (black) or negative (red). For example, Multi-Cap Russell 3000 Growth produced 20% positive returns within the one-year time period and is shown with color fill in both directions from the zero line to purposefully duplicate the large gains and specifically uses black color fill to indicate the returns are positive. As evident from the name, the symmetrical chart doubles the returns to emphasize the amount of color fill. What else can we derive from organizing the information in a spectrum of negative to positive returns? Based on this organization, three groups of categories have resulted in straight losses (red), heavy gains (black), or a mix of gains and losses across a decade of returns. The string of charts makes it easier to see these three groups of categories to assess their distribution. Just like sound waves, each chart is a sound bite that streams the returns for each category with a “scream” announcing a huge gain (e.g., Multi-Cap Russel 3000 Growth) or loss (e.g., Mid-Cap Russel Mid Cap Growth). In some cases (e.g., Large Cap S&amp;P 500), the chart quietly announces mixed returns to adequately demand less attention. Next, we might wonder how we would have fared if we had invested in certain funds. We might ask: if we had purchased this fund five years ago, what would the return be? And what about the YTD returns? Since market timing is key to investment choices, the following presentation of hypothetical investments represents a range of results. 5.6.3 Conclusions In Figure 3, varied performance results become clear with a layered approach to show five potential entry points (10-year, 5-year, 3-year, 1-year, YTD) into an investment. For example, the International Large Cap Core fund provided 27% YTD returns, which contrast the negative returns you would have received had you invested in the fund 1, 5, or 10 years ago. Here, conclusions are derived based on known inputs with a divided review of positive or negative outcomes (shown on the y-axis). The line weights help to identify each entry point and show the range of differences between the entry points. Accordingly so, resulting returns are shown with simplified curves that connect the inputs and outputs. In this case, the chart has been customized to show an instance in which the user has opted to see the YTD return values as percentages listed to the right of each resulting output. 5.7 Takeaways From Recreating One Chart Using 24 Tools (Rost 2016) Lisa Rost’s article “What I learned recreating one chart using 24 tools” describes lessons learned from recreating one chart using many different data visualization tools. The author used apps Excel, Plotly, Easycharts, Google Sheets, Lyra, Highcharts, Tableau, Polestar, Quadrigram, Illustrator, RAW, and NodeBox, as well as charting libraries ggvis, Bokeh, Highcharts, ggplot2, Processing, NVD3, Seaborn, Vega, D3, matplotlib, Vega-Lite, and R. She links her GitHub page on the project which details the data set she used, containing the health expectancy in years as well as GDP per capita and population for about 200 countries in the year 2015, as well as her process and results of visualizing the data using each tool. However, in the article, she focuses on the main takeaways from the exercise, which was especially interesting in the context of our class discussion on different types of tools and their respective strengths. She also provides her own graphics to help illustrate her lessons learned. 5.7.1 Takeaway 1: There is No Perfect Tool, Just Good Tools for People with Certain Goals Since data visualization is used in a wide variety of fields, from science to journalism, data visualization projects will often have differing objectives, as the people working on them will have different requirements. As the author aptly points out, it is impossible for one tool to satisfy the need of every data visualizer. Each tool has its own pros and cons and it is up to the author in decided which is better suited to meet his/her’s specific situation. Hence, when deciding on a tool or tools to use, one should always consider the purpose of the visualization. For example, consider if the visualization is to show exploratory data analysis or to be presented as a finding to the general public or a specific audience. (Source:(Rost 2016)) The author also notes that the flexibility of a tool is a sticking point as well if you need to change your data while developing a data visualization, as certain apps like Illustrator will not be ideal because changing the data even slightly requires you to build the graph again from scratch. Another thing to think about is the type of chart you are trying to create. Is a basic bar or line graph sufficient (in which case something like Excel will do the trick), or does your project require a more innovative or custom chart (using D3.js)? While interactivity is a plus point, relevancy of the visualization is more important. (Source:(Rost 2016)) 5.7.2 Takeaway 2: There Are No Perfect Tools, Just Good Tools for People with Certain Mindsets This section of the article is all about the difference in people’s preferences and opinions; from the people who build the tools to the users, everyone thinks differently. Therefore, certain tools will be inherently more intuitive to use for different people. 5.7.3 Takeaway 3: We Still Live in an ‘Apps Are for the Easy Stuff, Code Is for the Good Stuff in the World’ Basically, writing code can be scary for anyone without a coding background, but it provides more flexibility, and, as mentioned in class, the code is perfectly reproducible. On the other hand, apps are much more user-friendly for the less computer science-savvy. (Source:(Rost 2016)) 5.7.4 Takeaway 4: Every Tool Forces You Down a Path Rost quotes her former NPR Visuals teammate for the final lesson header, pointing out that tools themselves influence the development of a data visualization with their respective features, strengths, and limitations. (Source:(Rost 2016)) 5.8 Word Cloud (McKee 2014) A Word Cloud or Tag Cloud is a visual representation of text data in the form of tags, which are typically single words whose importance is visualized by way of their size and color. It displays how frequently words appear in a given body of text, by making the size of each word proportional to its frequency. (Source:(Unknown 2019)) Word clouds can add clarity to text analysis in order to effectively communicate your data results. Pros of Word Clouds Cons of Word Clouds Impactful and easy to understand Possibly erroneous emphasis based on length of the words Quick to generate and easily shared Words with letters that contain many ascenders and descenders may receive more attention More visually engaging than a data table Not very accurate Reveals essential information Requires a lot of data cleaning Delightful and promote emotional connection Context is lost Ways to generate a word cloud R: (analysis 2018) Creating word clouds is very simple in R with the text mining package (TM) and the word cloud generator package. The major steps involved are: text mining which involves text cleaning and transformation, building term-document matrix and generating word cloud. Python: (Vu 2018) For generating word cloud in Python, modules needed are – matplotlib, pandas and wordcloud. By using a mask, you can generate wordclouds in arbitrary shapes. You can color a word-cloud by using an image-based coloring strategy implemented in ImageColorGenerator. It uses the average color of the region occupied by the word in a source image. You can combine this with masking - pure-white will be interpreted as ‘don’t occupy’ by the WordCloud object when passed as mask. If you want white as a legal color, you can just pass a different image to “mask”, but make sure the image shapes line up. You can also use the recolor method and custom coloring functions. Wordle: (Feinberg 2014) Wordle is a toy for generating “word clouds” from the text that you provide. It is free and easy to use. You do need Java through Chrome. In Wordle, you generate word clouds from text you give as input. Clouds can be tweaked with different color schemes, layouts, and fonts. Images created from this tool can be saved and reused (Feinberg 2014). Other popular tools include ABCya, Tagul, Tag Crowd and CloudArt. 5.9 Dashboards (Taylor 2018),(tableau, n.d.) (Few 2007) &gt; “A dashboard is a visual display of the most important information needed to achieve one or more objectives; consolidated and arranged on a single screen so the information can be monitored at a glance.” -Stephen Few 5.9.1 Rules and Best Practices for Developing Intuitive Dashboards Often, data visuals end up too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to the effective presentation of the data. Best Practice Description The dashboard should read left to right Because we read from top to bottom and left to right, a reader’s eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard since dashboards are often used as a quick convenient way to look up data. Group related information together Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need. Find relationships between seemingly unrelated areas and display visuals together to show the relationship. Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data are trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together. Choose metrics based on why they matter Chosen metrics should be important and relevant to the current task. That doesn’t mean that each metric ought to be incorporated. You ought to be highly selective in determining which metrics earn a spot on your dashboard. Organization’s core objectives, availability of data that can shed light on the objectives, effectiveness of metric to explain contribution to the objectives etc. are some of the aspects to consider while choosing metrics. In short, every metric on your dashboard should connect to the organization objectives. Keep it visual Dashboards are meant to be fast and easy to read. A well-designed, highly visual dashboard will be more widely adopted by audiences. Since metrics are also chosen in line with corporate objective, it will help in speeding peoples’ understanding. This will also help see the translation of individual department objectives into broader organizations objective. Make it interactive Interactive, highly visual dashboards should enable audience to perform basic analytical tasks, such as filtering the views, drilling down, examining underlying data etc. Viewers should be able to get the big picture from the dashboard and then be able to drill down into a view that tells them the information they need to get their jobs done. Keep it current or don’t bother Selected metrics should reflect current business challenges. You don’t need up-to-the-minute data. Data can be current quarterly, weekly, hourly, etc. as relevant to the timeline of the organization. Ability to change and update the metrics represented in the dashboard is an important aspect. Make it simple to access and use Making dashboards easily accessible is critical. Web distribution is ideal for this - especially if dashboards can constantly pull current data and can adhere to IT protocols and security standards. Another alternative is posting files on websites, Wiki’s or blogs. 5.10 Using Visualization Softwares and Libraries 5.10.1 Using Shapes as Filters in Tableau When Your Fields Are Measures (Brett 2018) This article (Brett 2018) introduces the methodologies on how to use shapes as filters in Tableau when your fields are measures. It teaches you how to load custom shapes as action filters and use them for showing different graphs with those filters, which can make your visualization more interesting and interactive. You can also download the Tableau file for practice. 5.10.2 How to Customize a Legend in Python with Matplotlib (Jake 2016) A legend shows descriptive labels and their respective colors or shapes for each plotted data series. A good legend helps us to better understand the graph and what each series represents. 5.10.2.1 Add a Basic Legend First, we need to import the matplotlib library in Python. Then we use the legend() function to add a basic legend. For example, if we already have a line graph with multiple lines, we can add a legend to distinguish them from each other with the ax.legend() function, as shown below: import matplotlib.pyplot as plt plt.style.use(&#39;classic&#39;) #matplotlib inline import numpy as np x = np.linspace(0, 10, 1000) fig, ax = plt.subplots() ax.plot(x, np.sin(x), &#39;-b&#39;, label=&#39;Sine&#39;) ax.plot(x, np.cos(x), &#39;--r&#39;, label=&#39;Cosine&#39;) ax.axis(&#39;equal&#39;) leg = ax.legend(); 5.10.2.2 Add a Legend on Different Position To specify the position of the legend, the ‘loc’ parameter inside the function can be used: ax.legend(loc=&#39;upper left&#39;, frameon=False) fig 5.10.2.3 Customize a Box Surrounding the Legend We can also specify whether we want a box surrounding the legend with the ‘fancybox’ parameter: ax.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1) fig 5.10.2.4 Legend for Size of Points import pandas as pd cities = pd.read_csv(&#39;data/california_cities.csv&#39;) # Extract the data we&#39;re interested in lat, lon = cities[&#39;latd&#39;], cities[&#39;longd&#39;] population, area = cities[&#39;population_total&#39;], cities[&#39;area_total_km2&#39;] # Scatter the points, using size and color but no label plt.scatter(lon, lat, label=None, c=np.log10(population), cmap=&#39;viridis&#39;, s=area, linewidth=0, alpha=0.5) plt.axis(aspect=&#39;equal&#39;) plt.xlabel(&#39;longitude&#39;) plt.ylabel(&#39;latitude&#39;) plt.colorbar(label=&#39;log$_{10}$(population)&#39;) plt.clim(3, 7) # Here we create a legend: # we&#39;ll plot empty lists with the desired size and label for area in [100, 300, 500]: plt.scatter([], [], c=&#39;k&#39;, alpha=0.3, s=area, label=str(area) + &#39; km$^2$&#39;) plt.legend(scatterpoints=1, frameon=False, labelspacing=1, title=&#39;City Area&#39;) plt.title(&#39;California Cities: Area and Population&#39;); 5.10.2.5 Multiple Legends fig, ax = plt.subplots() lines = [] styles = [&#39;-&#39;, &#39;--&#39;, &#39;-.&#39;, &#39;:&#39;] x = np.linspace(0, 10, 1000) for i in range(4): lines += ax.plot(x, np.sin(x - i * np.pi / 2), styles[i], color=&#39;black&#39;) ax.axis(&#39;equal&#39;) # specify the lines and labels of the first legend ax.legend(lines[:2], [&#39;line A&#39;, &#39;line B&#39;], loc=&#39;upper right&#39;, frameon=False) # Create the second legend and add the artist manually. from matplotlib.legend import Legend leg = Legend(ax, lines[2:], [&#39;line C&#39;, &#39;line D&#39;], loc=&#39;lower right&#39;, frameon=False) ax.add_artist(leg); 5.10.2.6 ggplot2 code template for data viz in R (???) This site includes full sets of R code to generate specific types of graphs in ggplot2. Plots in ggplot2 are created by using “layering”. Layering combines a base plot with other aspects such as aesthetics, titles, and labels using additional code. For those who favor Python for data visualization, this layering approach in R is actually quite similar to the syntax in Python’s matplotlib library, in which set_style and specifying the axes labels and title are done separately from the code that generates the plot itself. To provide an example of the “layering” mentioned above, here is a generic snippet of code for creating a scatterplot with ggplot2 and the mtcars data set in R base, using this website’s code as a template: library(ggplot2) theme_set(theme_bw()) #set background theme plot1 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point(aes(col=factor(vs), size = 2)) + geom_smooth(method = &quot;loess&quot;, se = F) + xlim(c(0, 400)) + ylim(c(0, 40)) + labs(title = &quot;Horsepower vs. MPG&quot;, y = &quot;Miles Per Gallon&quot;, x = &quot;Horsepower&quot;) plot(plot1) #we have to actually call the plot() function on the plot object we created The ggplot2 package allows R users to go beyond the simple and often rudimentary-looking graphs in R and offers many ways of customizing data visualizations. The layering technique also makes it easier to remember the code to generate these plots, since geom functions for the layers remain constant and they are all included in a single line of code. 5.10.2.7 Reusable Calendar View Code (Bostock 2018a) We have all seen the calendar views in the various data products that we worked on. Below is an open source code which will help you replicate and create your own calendar: (Bostock 2018b) Reproducible code for reference: This example demonstrates loading of CSV data, which is then quantized into a diverging color scale. The values are visualized as colored cells per day. Days are arranged into columns by week, then grouped by month and years. &lt;!DOCTYPE html&gt; &lt;body&gt; &lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var width = 960, height = 136, cellSize = 17; var formatPercent = d3.format(&quot;.1%&quot;); var color = d3.scaleQuantize() .domain([-0.05, 0.05]) .range([&quot;#a50026&quot;, &quot;#d73027&quot;, &quot;#f46d43&quot;, &quot;#fdae61&quot;, &quot;#fee08b&quot;, &quot;#ffffbf&quot;, &quot;#d9ef8b&quot;, &quot;#a6d96a&quot;, &quot;#66bd63&quot;, &quot;#1a9850&quot;, &quot;#006837&quot;]); var svg = d3.select(&quot;body&quot;) .selectAll(&quot;svg&quot;) .data(d3.range(1990, 2011)) .enter().append(&quot;svg&quot;) .attr(&quot;width&quot;, width) .attr(&quot;height&quot;, height) .append(&quot;g&quot;) .attr(&quot;transform&quot;, &quot;translate(&quot; + ((width - cellSize * 53) / 2) + &quot;,&quot; + (height - cellSize * 7 - 1) + &quot;)&quot;); svg.append(&quot;text&quot;) .attr(&quot;transform&quot;, &quot;translate(-6,&quot; + cellSize * 3.5 + &quot;)rotate(-90)&quot;) .attr(&quot;font-family&quot;, &quot;sans-serif&quot;) .attr(&quot;font-size&quot;, 10) .attr(&quot;text-anchor&quot;, &quot;middle&quot;) .text(function(d) { return d; }); var rect = svg.append(&quot;g&quot;) .attr(&quot;fill&quot;, &quot;none&quot;) .attr(&quot;stroke&quot;, &quot;#ccc&quot;) .selectAll(&quot;rect&quot;) .data(function(d) { return d3.timeDays(new Date(d, 0, 1), new Date(d + 1, 0, 1)); }) .enter().append(&quot;rect&quot;) .attr(&quot;width&quot;, cellSize) .attr(&quot;height&quot;, cellSize) .attr(&quot;x&quot;, function(d) { return d3.timeWeek.count(d3.timeYear(d), d) * cellSize; }) .attr(&quot;y&quot;, function(d) { return d.getDay() * cellSize; }) .datum(d3.timeFormat(&quot;%Y-%m-%d&quot;)); svg.append(&quot;g&quot;) .attr(&quot;fill&quot;, &quot;none&quot;) .attr(&quot;stroke&quot;, &quot;#000&quot;) .selectAll(&quot;path&quot;) .data(function(d) { return d3.timeMonths(new Date(d, 0, 1), new Date(d + 1, 0, 1)); }) .enter().append(&quot;path&quot;) .attr(&quot;d&quot;, pathMonth); d3.csv(&quot;dji.csv&quot;, function(error, csv) { if (error) throw error; var data = d3.nest() .key(function(d) { return d.Date; }) .rollup(function(d) { return (d[0].Close - d[0].Open) / d[0].Open; }) .object(csv); rect.filter(function(d) { return d in data; }) .attr(&quot;fill&quot;, function(d) { return color(data[d]); }) .append(&quot;title&quot;) .text(function(d) { return d + &quot;: &quot; + formatPercent(data[d]); }); }); function pathMonth(t0) { var t1 = new Date(t0.getFullYear(), t0.getMonth() + 1, 0), d0 = t0.getDay(), w0 = d3.timeWeek.count(d3.timeYear(t0), t0), d1 = t1.getDay(), w1 = d3.timeWeek.count(d3.timeYear(t1), t1); return &quot;M&quot; + (w0 + 1) * cellSize + &quot;,&quot; + d0 * cellSize + &quot;H&quot; + w0 * cellSize + &quot;V&quot; + 7 * cellSize + &quot;H&quot; + w1 * cellSize + &quot;V&quot; + (d1 + 1) * cellSize + &quot;H&quot; + (w1 + 1) * cellSize + &quot;V&quot; + 0 + &quot;H&quot; + (w0 + 1) * cellSize + &quot;Z&quot;; } &lt;/script&gt; 5.10.3 Building Advanced Analytics Application with TabPy (Beran 2017) Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the y-variable! TabPy allows us to integrate and visualize data from Python in Tableau. The author here has given an example in which he tries to identify criminal hotspots in the area using data from Seattle’s police department’s 911 calls. The author uses machine learning (spatial clustering) and creates a great interactive visualization which allows viewers to click on the type of criminal activity to show various clusters. There are other examples and use cases that may be downloaded, and the scripts are also given by the author to anyone who is interested in replicating the visualizations. 5.10.4 Creating a Diverging Bar Chart (???) A diverging bar chart shows and compares positive and negative values for a particular variable. One popular use case is survey analysis, in which multiple options are given as the categories, so each option has one bar, and there are two opposite ends of the spectrum for the values. These two sides are usually ‘positive’ vs ‘negative’, but they can also be categorical values such as ‘agree’ or ‘disagree’. Below is the R code template one can use to create a diverging bar chart. library(ggplot2) theme_set(theme_bw()) # Data Prep data(&quot;mtcars&quot;) # load data mtcars$`car name` &lt;- rownames(mtcars) # create new column for car names mtcars$mpg_z &lt;- round((mtcars$mpg - mean(mtcars$mpg))/sd(mtcars$mpg), 2) # compute normalized mpg mtcars$mpg_type &lt;- ifelse(mtcars$mpg_z &lt; 0, &quot;below&quot;, &quot;above&quot;) # above / below avg flag mtcars &lt;- mtcars[order(mtcars$mpg_z), ] # sort mtcars$`car name` &lt;- factor(mtcars$`car name`, levels = mtcars$`car name`) # convert to factor to retain sorted order in plot. # Diverging Barcharts ggplot(mtcars, aes(x=`car name`, y=mpg_z, label=mpg_z)) + geom_bar(stat=&#39;identity&#39;, aes(fill=mpg_type), width=.5) + scale_fill_manual(name=&quot;Mileage&quot;, labels = c(&quot;Above Average&quot;, &quot;Below Average&quot;), values = c(&quot;above&quot;=&quot;#00ba38&quot;, &quot;below&quot;=&quot;#f8766d&quot;)) + labs(subtitle=&quot;Normalised mileage from &#39;mtcars&#39;&quot;, title= &quot;Diverging Bars&quot;) + coord_flip() Diverging bar charts are also convenient to create in Tableau. Below is an example using survey response data. References "],
["ethics.html", "Chapter 6 Ethics 6.1 Importance of Ethics in Visualization 6.2 Implications of (Good/Bad) Data Visualization 6.3 General Guidelines for Ethical Visuals 6.4 Definitions of Data Deception and Graphic Integrity 6.5 Ethical Challenges in Data Visualization 6.6 Ethical Theory and Practice from Journalism and Engineering 6.7 Misinformation Can be beautiful too 6.8 Visual Lies", " Chapter 6 Ethics This chapter covers the ethical implication to data visualizations. Ethics refers to a set of moral principles that dictate a person’s behavior. While the field of ethics is often considered to be a theoretical discipline, ethical conduct is an important objective in practice. In the field of data visualization, there are many opportunities to manipulate viewers with untruthful representations of data; thus, like any other discipline, data visualization faces significant ethical challenges. This chapter will touch on the importance of ethics in visualization, guidelines for ethical visualization, topics relating to data deception, ethical challenges faced when creating visualization, visualization and social change, and more. 6.1 Importance of Ethics in Visualization (Cairo 2014) Alberto Cairo illustrates the importance of ethics in his inforgraphics. He sees data visualization as harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is precisely and concisely conveyed. Cairo explains that as a “rule utilitarian,” he believes it is “morally right” to create graphics in this way. Here, it is useful to review his blog post introducing the article. In short, the responsibility of an ethical data visualizer is to create the most good while doing the least harm. As such, conveying honest and relevant information increases a person’s understanding, and increased understanding and knowledge positively correlates with personal well-being. Alberto Cairo addresses the ethical ‘why’ of data visualization in this article, while still grounding the discussion in a straightforward analysis of harmful and helpful practices. He emphasizes that the effectiveness of the display’s communication of a message is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. Again, since the moral purpose is to improve well-being through understanding, a graphic that is confusing or misleading is unethical, regardless of intent, since it creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphic as “morally wrong,” it is essential to think of the unintended consequences that powerful yet misleading visuals may have on their viewers. 6.2 Implications of (Good/Bad) Data Visualization Raw data is often meaningless or at the very least is difficult to derive immediate meaning from. When people face a broad set of measurements and/or in large quantities, they are unable or unwilling to spend the time required to process it. Technological advances of the Digital Age contribute to an ever-growing pool of “big data” and have dramatically improved our ability to collect such large amounts of information. Thus, filtering, visualization, and interpretation of data becomes increasingly important. We should understand how to best derive meaning from data, but first we should understand why its presentation in graphical format is so powerful. Furthermore, while the ideal purpose of data visualization is to facilitate understanding of data, visualization can also be used to mislead. Some of the main methods of doing so are omitting baselines, axis manipulation, omitting data, and ignoring graphing convention. Examples of these methods will be explored later in this chapter. SNo. Principle Description 1. Easy Recall People can process images quicker than words. When data is transformed into images, the readability and cognition of the content greatly improves. While people can only remember just 10% of what they hear and 20% of what they read, retention jumps up to 80% for visual information with interaction. 2. Providing Window for Perspective With infographics, you can pack a lot of information into a small space. Colors, shape, movement, the contrast in scale and weight, and even sound can be used to denote different aspects of the data allowing for multi-layered understanding (Mullis 2015). 3. Enable Qualitative Analysis Color, shape, sounds, and size can make evident relationships within data very intuitive. When data points are represented as images or components of an entire scene, readers are able to see the correlation and analytical insights can be easily derived. 4. Increase in User Participation Interactive infographics can substantially increase the amount of time someone will spend with the content and the degree to which they participate in the information, both in its collection and its dissemination. 6.3 General Guidelines for Ethical Visuals (Skau 2012) Data visualization is an up-and-coming field that currently does not have many established regulations. This makes it easy to manipulate readers without technically reporting false information. However, certain standards should be followed in order to generate meaningful and accurate visuals. The process can be broken down into three steps, each with its own set of guiding rules. 6.3.1 Data Collection The first step in any project is gathering the data. This is relatively simple and does not offer much of an opportunity to introduce confusion. The one thing to remember is to always get data from a reliable source. The data provides the foundation for the entire project and must, therefore, be trustworthy and verifiable. Furthermore, special care should be taken for identification of inherent biases while using an existing dataset or creating a new one. In addition, Cairo briefly addresses four guidelines that are applicable in all information gathering fields: 1. Beware of selection bias when choosing preexisting datasets, validate the data, and include essential context. 2. False or irrelevant information does not improve anyone’s decision-making capacity, so it cannot enhance well-being. 3. Even if the information is both accurate and relevant, moral pitfalls may remain. 4. To avoid the unethical trap of inscrutable or misleading graphics, Cairo exhorts us to take an evidence-based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity. 6.3.2 Data Analysis This is the stage where the discoveries are made and thus, is the first opportunity to manipulate the story. There is usually a lot of data cleaning to do before creating a visual representation, but all data wrangling steps should be deliberate and reasonable. If possible the underlying code should be publicly shared so anyone can follow the entire process. It is also important to explicitly state any assumptions taken, though these ideally should be kept to a minimum. Here, it is important to look at what the source data actually shows. It is the ethical responsibility of presenters to perform careful analysis of the data and extract true stories from them. As the amount of data grows, it becomes increasingly difficult to keep the insight derivation up to speed with the collection of data. Therefore, data strategy becomes an imperative part of successfully applying data to the business. 6.3.3 Design Once a visualizer decides on an argument, it is important to present it honestly. While there is an inherent tradeoff between truthfulness of the visualization and effectiveness of its argument, visualizers should strive to maximize both. Deceptive techniques may be tempting to make a stronger argument, but besides being ethically wrong, the intentional use of deceptive visualization techniques will hurt the credibility of the author and anyone else involved in the publication since an experienced individual will know how to spot and disregard these deceptions. Visualization should not be used to intentionally hide or confuse the truth. It should not seek to mislead the uninformed. Visualization has great power, and as they say, with great power comes great responsibility. Guiding rules for designing the visuals according to Skau are as follows: * Use the visuals you chose to depict the data and analysis accurately. * Be attentive to labelling best practices and hierarchy of importance of visual properties, such as colors. * Read on topics related to visualization, study any visualizations critically, and be open to criticism. 6.4 Definitions of Data Deception and Graphic Integrity (???),(???) Data visualization is a powerful communication tool to support arguments with numbers in a way that is accessible and engaging. It is an increasingly popular way to communicate and support arguments. More people than ever before are making their own charts and infographics, creating a unique problem. Despite the availability of great charting resources and resources online to create and design amazing data products, we are witnessing an influx of poorly-designed, misleading, or downright deceptive data visualizations. What does data deception mean? Data deception, defined by School of Law at the New York University, is “a graphical depiction of information, designed with or without an intent to deceive, that may create a belief about the message and/or its components, which varies from the actual message.” Deceptive, misleading, or distorted graphs are those that intentionally or unintentionally skew the data, and result in a representation of incorrect conclusions. Edward Tufte already introduced the concept of graphical integrity in his book and presented six principles of graphic integrity. Here are the principles of the book: The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities measured. Clear, detailed, and thorough labeling should be used to defeat graphical distortion and ambiguity. Write out explanations of the data on the graphic itself. Label important events in the data. In time-series displays of money, deﬂated and standardized units of monetary measurement are nearly always better than nominal units. The number of information-carrying (variable) dimensions depicted should not exceed the number of dimensions in the data. Show data variation, not design variation. Graphics must not quote data out of context. There are some ways in which distorted graphs can be created: (Robertson 2018),(???) Tool Description Improper scaling of y-axis This is one of the classic way of creating misleading graphs. Instead of scale starting from zero or a baseline, the y-axis is scaled conveniently to highlight the differences among bins. Improper labeling of graphs Lack of labels makes the graph hard to interpret for the reader and leads to wrong conclusions. Paired graphs on different scale It is not a fair comparison if two elements are plotted side-by-side, on a different scale and compared. This makes one graph look better than the other, even when it is not. Dual axis with different scales If we are plotting two elements on the same graph with different scales, it is assumed that both axes are on the same scale even if the axes are properly labeled. Especially if the two elements are represented in a similar way ( bargraph or line graph) Incomplete data Short-term graphs are made to manipulate the trend, which will not be seen otherwise. Time-series data are cut intentionally to show a trend within a particular period to create a more favorable visual impression. 6.5 Ethical Challenges in Data Visualization (Stempeck 2016) Matt Stempeck’s article recaps a brainstorming session concerning data visualization ethics, and provides a fairly comprehensive list of considerations for data visualizers to use as a guide to evaluate how ethical their data products actually are. From replicability of a data visualization, to persuasiveness and ambiguity in the data, this article challenges data visualizers to assess how to ethically present data. The discussion on perspective is an interesting one; it asks how data visualizers might show different perspectives on the same data. Clearly from the “deceptive versions” we have created for Vox’s gun violence article’s visualizations, the same data can be used to show vastly different perspectives, or make extremely contrasting claims. This may counteract common opinion of data, since most people perhaps believe there is an inherent truth to the data, but the data visualizer is in control of what the audience sees; the person creating the visualization cultivates a perspective to argue the claim. The data is at the heart of this argument, but how the data visualizer presents it to the audience may or may not include the whole story or the most truthful story. Furthermore, while this challenge to show different perspectives proposed by the article clearly should be undertaken by data visualizers for the ethical good; when the goal of a data visualizer is to persuade his/her audience to accept the visualizer’s perspective, being fair and thorough in considering the other side of the argument may contradict the data visualizer’s objective. Of course, the challenge posed by the tug-of-war between ethics and utility ( not to say that they are always contradictory in nature) remains central in many sciences, including the data sciences, and it makes the discussion of finding a balance between the two all the more important. 6.6 Ethical Theory and Practice from Journalism and Engineering (Zinovyev 2011) The fundamental objective of data visualization is to provide an efficient graphical display for summarizing quantitative information and supporting an argument. During the last decades, political science has accumulated a large corpus of various kinds of data, and has gradually evolved into a more scientific field, requiring the use of quantitative information in analysis of relevant data. Under U.S. law, research institutions receiving federal fundings must consider ethical aspects of their research. Over time, researchers and lawyers have established rules and practices for proper data collection and utilization, with particular attention on human subject research. Consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting the anonymity of data are some of the rules that must be considered in ethical research methods. However, these rules continue to evolve. The ability to use data visualization to manipulate and mislead also presents an issue. Research has found that even if viewers do not originally support an idea, data presented in charts can persuade viewers on the subject matter. Thus, many deceptive techniques can be used to intentionally produce a dangerous visualization. Techniques such as truncated axis (where the y-axis does not start at zero) or using the area to represent a quantity (for instance comparing the size of two adjacent circles) were found leading to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. There is no shortage of techniques for deception through data visualization, and researchers have an ethical responsibility to give a correct and faithful representation of data and subjects. 6.7 Misinformation Can be beautiful too (Harford 2013) Camouflage usually means blending in. That wasn’t an option for the submarine-dodging battleships of a century ago, which advertised their presence against an ever-changing sea and sky with bow waves and smokestacks. So, dazzle camouflage was born, an abstract riot of squiggles and harlequin patterns. It wasn’t hard to spot a dazzle ship but the challenge for the periscope operator was to quickly judge a ship’s speed and direction before firing a torpedo on a ponderous intercept. Dazzle camouflage was intended to provoke misjudgments, and there are some evidence proving that it worked. Now let’s talk about data visualization, the latest fashion in numerate journalism, albeit one that harks back to the likes of Florence Nightingale. She was not only the most famous nurse in history but also the creator of a beautiful visualization technique, the “Coxcomb diagram”, and the first woman to be elected as a member of the Royal Statistical Society. (Source: (Ayalasomayajula, n.d.)) Data visualization creates powerful, elegant images from complex data. It’s like good prose: a pleasure to experience and a force for good in the right hands, but also seductive and potentially deceptive. Because we have less experience of data visualization than of rhetoric, we are naive, and allow ourselves to be dazzled. Too much data visualization is the statistical equivalent of dazzle camouflage: striking looks grab our attention but either fail to convey useful information or actively misdirect us. For a relatively harmless example, consider The New Yorker’s recent online subway map of inequality. “New York has a problem with inequality,” we are told. Then we are invited to click on different subway maps to see a cross-sectional graph, showing us the peaks and troughs of median income along different subway lines. The result is gorgeous but far less informative than a map would have been. It is a piece of art pretending to be a piece of statistical analysis. A more famous example is David McCandless’s unforgettable animation “Debtris”, in which large blocks fall slowly against an eight-bit soundtrack in homage to the addictive computer game Tetris. Their size indicates their dollar value. “$60bn: estimated cost of Iraq war in 2003” is followed by “$3000bn: estimated total cost of Iraq war”, and then Walmart’s revenue, the UN’s budget, the cost of the financial crisis, and much else. The animation is pure dazzle camouflage. Statistical apples are compared with statistical oranges throughout. The Iraq comparison, for instance, is not one of “then versus now” as it first appears - but one of what the US Department of Defense once thought it would spend versus a broader estimate, including a financial value on the lives of dead soldiers, and over a trillion dollars of “macroeconomic costs”. The war was a disaster- No need for a statistical bait-and-switch to make that case. Information can be beautiful, McCandless tells us. Unfortunately misinformation can be beautiful too. Or, as statistical guru Michael Blastland puts it, “We are in danger of making the same statistical mistakes that we’ve always made - only prettier.” Those beautiful Coxcomb diagrams are no exception. They show the causes of mortality in the Crimean war, and make a powerful case that better hygiene saved lives. But Hugh Small, a biographer of Nightingale, argues that she chose the Coxcomb diagram in order to make exactly this case. A simple bar chart would have been clearer: too clear for Nightingale’s purposes, because it suggested that winter was as much of a killer as poor hygiene was. Nightingale’s presentation of data was masterful. It was also designed not to inform but to persuade. When we look at modern data visualizations, we should remember that. 6.8 Visual Lies (Bishop 2017a) This article focuses on a few methods that data visualizers utilize to mislead users about research findings. For each method, the author has highlighted the signifiers that are manipulated to promote an unrealistic understanding of the visualized data. The author has concentrated on examples of three areas to create deceptive data visualization: size, segmentation, and graph type. 6.8.1 Size Size signifies quantity, volume or degree of variables within a data. In the first figure, the y-axis from the graph to the right is cut when transcribed onto the graph on the left. Here, both the graphs show the same data but the one on the left represents the data in a misleading fashion because of the way the axis is cut, and the result is that interest rates have increased drastically from 2008 to 2012 – a misinterpretation that is avoided in the graph on the right. (Source:(Kwapien 2015)) 6.8.2 Quantity Quantity measures size. When depicting points on a scatter plot, it is helpful to manipulate the size of the points to represent differing values of a variable that is not represented on the x and y axes. The following graph shows quantity as two completely different measures. One chart uses quantity as area and other uses it as radius. The result is that the differences in quantity between points on such a scatter plot would appear more dramatic than they should. (Source:(Bishop 2017b)) 6.8.3 Segmentation The figure below is an example of segmentation with a deceptive instance of binning given in the legend on the left. Segmentation can be used to show category, parts, domains or ranges within a chart. The author states that correct use of segmentation can be a powerful tool to enhance understanding, but can be deceptive if used incorrectly. This example shows how binning can be misleading; in the left figure, binning is not done appropriately, and it is therefore difficult to come up with actual values of the data. (Source:(Bishop 2017a)) 6.8.4 Graph Two graphs that are often misrepresented are pie-charts and maps. In the following figure, the author explains that pie-charts cannot be compared accurately to one another. When striving for an accurate portrayal of values, they should be avoided. The author further states that it would be difficult to understand the pie-charts had the numbers not been given. Pie charts should not be used in cases of too many vairables or when the difference is not substantial between the vairables. Clubbing of multiple variables into “Others” category is mostly used in Pie Charts but “Others” category should not be one of the major pie in the chart. (Source:(Bishop 2017a)) The author also asserts that when showing spatial data analysis, always show population density when visualizing values that are person-dependent. On a heat map where color signifies quantity, the author suggests that a user will be drawn to the colors that a legend indicates as most extreme. In the following figure, areas that are darkest are simply the most population-dense regions of the United States. Without accounting for population density, the newly created map may look the same as hundreds of maps bearing a striking resemblance to the figure, which are falsely considered informative and are regularly shared across social media sites. (Source:(Bishop 2017a)) The above pointers are helpful when analyzing a deceptive version of a data product. However, data visualizers need to carefully draw the line between creating misleading graphs that tell a different story and developing deceptive versions that intend to exaggerate. This should be applied in our projects and can also be used to enhance our understanding of data visualization products. Misleading graphs are sometimes deliberately misleading and sometimes, it’s just a case of people not understanding the data behind the graph they create (Andalde 2014). But some real-life misleading graphs go above and beyond the classic types. Some are intended to mislead, others are intended to shock. The “classic” types of misleading graphs include cases such as: 6.8.5 The Missing Baseline For example, the vertical scale is too big or too small, skips numbers, or does not start at zero. For example, in the graph below, you might be thinking that the graph on the right shows that The Times makes double the sales of The Daily Telegraph. However, a closer look at the scale reveals that although The Times does make more sales, it is only beating the competition by about 10%. Misleading Graphs: The Missing Baseline (source:(Stephanie 2014)) 6.8.6 The Graph is not Labeled Properly Misleading Graphs: The Missing Baseline (source:(Stephanie 2014)) A graph may have the correct figures but still mislead its audience. This one used a big headline that suggests to its audience that 5.3% of children get spinal cord injuries, which is a pretty scary statistic for parents. But the real figure is about .0000003% (based on 2000 injuries per year out of a population of around 74,000,000). And for the figure 1 used in this article, “Misleading Graphs: Displaying a Change in One Variable Using Area or Volume” (Robbins 2012), the label for the smaller triangle in this graph says $26.4 while the label for the larger triangle says $114.6. $114.6 is 4.34 times $26.4. It certainly looks to me as if more than 4.34 smaller triangles will fit in the larger triangle. It is the altitudes of the triangles that are proportional to the numbers in the labels. 6.8.7 Data is left Out Hiding relevant data or highlighting a particular data point (cherry-picking data) can lead learners to focus on a small fraction of the data story—at the expense of accurate understanding of the bigger picture. Any individual parameter or statistic can reveal interesting or useful information. But taken out of context, it can also be misleading. For more examples and inspirations on misleading or deceptive graphs refer the following articles: Not including all the dimensions of data: (Hogle 2018) Bar charts without zero &amp; evenly spaced tick marks for uneven intervals: (Robbins 2011) Graphs not drawn to scale:(Robbins 2012) 6.8.8 Treating Correlation as Causation Even if the labels and data in your graph are correct, the conclusion is not necessarily logically correct. A correlation between X and Y does not automatically indicate that the change in one variable is caused by the change in the values of the other one, i.e. correlation does not imply causation. Viewers should bear in mind that such visuals only present the correlation between ice cream sold and murders, not than causation. Figure 6.1: A strange correlation between ice cream sales and murders (Source: (Harlin 2013)) Another trick for creating misleading graphs is an axis change: Changing the y-axis maximum affects how the information in the graph is perceived. A higher maximum will make the graph appear less volatile or steep than a lower maximum. The axis can also be altered to deceive by changing the ratio of a graph’s dimensions, as demonstrated in the below graphs. While not technically wrong, improper extraction, tactic omitting data or including only a certain chunk of data is certainly misleading. This is more common in graphs that have time as one of their axes. Visualizations should be simple and easy to understand, but at the same time they should contain the essence of responsible visualization. To make final results pure, ethical procedures need to be practiced throughout all the steps of visualization. In the data visualization terms, we call it truncated graph. A truncated graph (also known as a torn graph) has a y-axis that does not start at 0. These graphs can create the impression of important change where there is relatively little change.Truncated graphs are useful in illustrating small differences.[16] Graphs may also be truncated to save space. Commercial software such as MS Excel tend to truncate graphs by default if the values are all within a narrow range. Truncating graphs makes a small difference look like a huge one, thereby changing the readers’ judgement An example of using good data in a misleading graph to fool readers comes from Fox News. (Source:(“Data Mining Vs Data Visualization - Which One Is Better” 2018)) The question of ethics in data visualization is not something that comes to the fore when we start working. It is rarely the case that one sets out to deceive without altering data. The topic of good ethics in data visualization is very important and it is the duty of the creator to take care of it. At VisWeek2011, Jason Moore suggested a hippocratic oath for visualization. It is intended to be succinct and easy to remember, while still containing the essence of responsible visualization: “I shall not use visualization to intentionally hide or confuse the truth which it is intended to portray. I will respect the great power visualization has in garnering wisdom and misleading the uninformed. I accept this responsibility willfully and without reservation, and promise to defend this oath against all enemies, both domestic and foreign.” References "],
["conclusion.html", "Chapter 7 Conclusion 7.1 The Future of Data Visualization 7.2 Key Lessons Going Forward 7.3 Additional Resources for Aspiring Data Visualizers", " Chapter 7 Conclusion As we conclude our brief survey of data visualization, it is clear that the field is rich in potential applications in diverse disciplines, as well as in practical and ethical complexities to be aware of. In the previous chapters, we have presented some important theoretical and practical principles to keep in mind when designing a data visualization. We have also discussed and critiqued several examples of data visualizations, learning common pitfalls and helpful tricks along the way. As we have seen, developing an effective and ethical data visualization is a complex process. The journey from raw data to successful data visualization involves representing the data of interest, processing the data to extract relevant information for the desired argument, designing a mapping of this information to a visual representation, rendering this representation, and combining all this functionality in an easy-to-use product. 7.1 The Future of Data Visualization Towler (2015) Data visualization is entering a new era. Emerging sources of intelligence, theoretical developments and advances in multidimensional imaging are reshaping the potential value that analytics and insights can provide, with visualization playing a key role. The principles of effective data visualization won’t change. However, nextgen technologies and evolving cognitive frameworks are opening new horizons, moving data visualization from art to science. Looking back, much attention has been given to the principles of effective data visualization, such as substance, context and actionability. As timeless tenets that will continue to be important, regardless of medium or format, a brief review seems in order: As with any form of communication, effectively conveying a message with data requires that it be substantive. And while creative visuals can enhance interest and memory, embellishment can’t make up for lack of substance. According to purist Edward Tufte, “Every single pixel should testify directly to content.” Visualization should be accurate and contextual. David McCandless’s Billion Dollar O’Gram provides an example of how greater meaning can be added by incorporating the bigger picture. According to McCandless, “Absolute figures in a connected world don’t give you the whole picture. They’re not as true as they could be. We need relative figures that are connected to other data so that we can see a fuller picture.” Billion Dollar O’Gram (Source: Towler (2015)) More than anything else, data visualization should facilitate decision-making, a goal that is difficult to achieve for many. According to a recent KPMG study, while data and analytics are deemed increasingly important to organizations, generating actionable insights remains a top challenge. Looking forward, nextgen technologies and evolving cognitive frameworks will boost the role that data visualization can play in organizations and society. Consider the Internet of Things, Network and Complexity Theories, and recent developments in multidimensional visualization: The Internet has transformed the way we visualize information through a better understanding of networks and an explosion in profile, behavioral and attitudinal data. Sociograms, for example, have gone from relatively simple graphs to multifaceted relational maps, as illustrated in the following two charts, courtesy of the Journal of Social Structure and the Leadership Learning Community. Figure 2:Pre-Internet sociogram (Source: Towler (2015)) Figure 3:Internet-age sociogram (Source: Towler (2015)) The Internet of Things is expected to have a similar impact, with billions of connected devices capturing human and machine activity. Fully capitalizing on the data generated will require further advances in our ability to synthesize and display spatiotemporal activities. Network Theory has been in use for decades, with its earliest applications largely in social structure analysis. More recently, Network Theory is being applied to understand relationships and interactions in a variety of domains, such as crime prevention and disease management. Dirk Brockmann and Dirk Helbling’s work modeling the spread of infectious diseases provides an example of the power that Network Theory holds. 7.2 Key Lessons Going Forward Don’t try to be too cute. Using all the fancy features of a visualization tool can lead to complex and confusing graphics. Just because you have a flashy hammer, it does not mean that everything is a nail. Don’t lose your purpose in your infatuation with a new tool or feature. Stick to good design principles, and keep it simple (as was mentioned in the discussion about Patterns). Don’t provide more data than you need to tell your story. Humans have a tendency to want to create visualizations with multi-drill downs, filters, and tables. This is fine for ad hoc analysis, but if we are presenting a visual with a single story or argument, we must make sure every piece of data included plays a meaningful part in the story. Have more data to show what-ifs. A great way to provide more information in a visualization is to use filters to provide what-if views. Having filters for different scenarios, options, and time slices provide the user a way to review and discover various perspectives on your data. Just make sure the user does not have to work too hard to get there and that they do not get lost in the data. Deliver value in your visualization. Many graphs may be aesthetically pleasing or exciting but deliver no value. A graph with good value should deliver important insights to aid decision-making or prompt an action. Keep in mind, the main objective of a visualization is to deliver value, and each design decision should help achieve this. Understanding your audience is the most difficult and important part of developing a visualization. Different audiences will feel differently about the same chart. So when we develop the argument from the data, we should keep our intended audience in mind. Share what you have found. A visualization can be an effective influencer if used in the correct way and at the correct time. Think as author / reader When designing graphs, try to stand at the reader side, to check whether the graph is making sense or if there is any misleading information being showcased. As a reader, one needs to detect if there is any visualization deception in the graph. Before making any conclusion, understanding details and information the graph is providing like legend, caption, numbers, etc. is important. Do Calculations Accurate representation of data is necessary. Sometimes the original data cannot strongly support the main thesis. In that case, some extra calcuations based on the original dataset could make the idea more clear. It should be ethical Visualization: Research has found that even if viewers do not support an idea, data presented in charts can persuade viewers on the subject matter. It means that visualization can also be used to mislead either unintentionally or intentionally. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. So, certain standards should be followed in order to generate meaningful, accurate and ethical visuals. Laying the groundwork for data visualization (SAS 2014) Before implementing new technology, there are some steps you need to take. Not only do you need to have a solid grasp on your data, you also need to understand your goals, needs and audience. Preparing your organization for data visualization technology requires that you first: Understand the data you’re trying to visualize, including its size and cardinality (the uniqueness of data values in a column). Determine what you’re trying to visualize and what kind of information you want to communicate. Know your audience and understand how it processes visual information. Use a visual that conveys the information in the best and simplest form for your audience. Once you’ve answered those initial questions about the type of data you have and the audience who’ll be consuming the information, you need to prepare for the amount of data you’ll be working with. Big data brings new challenges to visualization because large volumes, different varieties and varying velocities must be taken into account. Plus, data is often generated faster that it can be managed and analyzed. How Is It Being Used? (SAS 2014) Regardless of industry or size, all types of businesses are using data visualization to help make sense of their data. Here’s how. Comprehend information quickly By using graphical representations of business information, businesses are able to see large amounts of data in clear, cohesive ways – and draw conclusions from that information. And since it’s significantly faster to analyze information in graphical format (as opposed to analyzing information in spreadsheets), businesses can address problems or answer questions in a more timely manner. Identify relationships and patterns Even extensive amounts of complicated data start to make sense when presented graphically; businesses can recognize parameters that are highly correlated. Some of the correlations will be obvious, but others won’t. Identifying those relationships helps organizations focus on areas most likely to influence their most important goals. Pinpoint emerging trends Using data visualization to discover trends – both in the business and in the market – can give businesses an edge over the competition, and ultimately affect the bottom line. It’s easy to spot outliers that affect product quality or customer churn, and address issues before they become bigger problems. Communicate the story to others Once a business has uncovered new insights from visual analytics, the next step is to communicate those insights to others. Using charts, graphs or other visually impactful representations of data is important in this step because it’s engaging and gets the message across quickly. 7.3 Additional Resources for Aspiring Data Visualizers The field of data visualization is huge, and the capability of linking storytelling and data-experience design is a commodity. An aspiring visualizer seeking to further broaden his/her knowledge might find these additional resources helpful. 7.3.1 Tableau Community (Tableau Software 2018a) helps you to explore Tableau further : It will help us enhance our learning Get answers for most of your doubts In tableau Post new questions and crowd source answers Attend events, seminars and join conferences conducted locally/ globally Give back to the community once you become an expert in that field There are very active Tableau social media groups (Tableau Software 2018b): Tableau Enthusiasts: LinkedIn Group (19K members) Tableau Software Fans &amp; Friends: LinkedIn Group (45k members) Describe Artists with Emoji. Using the data from Spotify, the author listed the 10 most distinctive emoji used in the playlists related to popular artists. The table being used in this visual is very straight-forward to link artist to the emojis and is very easy to compare among artists. When you hover over the emoji, further information is presented. 7.3.2 Blogs Here are some blogs recommended by Tableau (Tableau Software 2018c): Blog Description Link Storytelling with Data This blog provides information about the fundamentals of data visualization and how to make data a critical component of your story. link Information is Beautiful This blog was founded by David McCandless, the author of two bestselling infographics books, and provides a variety of visualizations, all of which are continuously revised and updated with the most recent data. link Flowing Data This blog not only provides articles about data viz best practices and charts on a variety of topics, but also offers tutorials and courses for honing the skill of data visualizations link Visualizing Data This blog provides a space for data visualizers to share news and thoughts about the field as well as offers diverse content about current and cutting-edge techniques, discussion of both practical and theoretical topics. link Junk Charts This blog critiques a variety of graphics, providing insights about what works and what doesn’t in each visualization, and how to improve them. link The Pudding This blog explores complex and contested issues through visual essays. link The Atlas This blog provides visualizations on a plethora of topics. link Graphic Detail This blog is the hub of The Economist’s data journalism; it provides examples of charts, maps, and infographics (all of which are often interactive). link Tableau Blog The Tableau blog is a source of data viz trends, issues important to the Tableau community, and updates about Tableau products. link 7.3.3 Useful Links on Data Visualization Resources, Trends, and Tutorials Resource Description Link (Catalogue 2018) You can find different types of plots used in data visualization link (Kosara 2018a) Robert Kosara’s website which contains recent developments happening in visualization and are likely to have an impact. link (Research 2018) About Robert Kosara and his research papers. link (Kosara 2018b) Robert Kosara’s twitter handle. link (FlowingData 2018) Website which offers courses, tutorials and happenings in viz. link (Infogram 2018) An infogram helps a user making different types of plots and learning the art of visualization. Engaging infographics, reports, charts, dashboards and maps can be easily created in minutes with it. link (beautifuldata.net 2018) This blog features discussion of all things data link (Sandberg 2018) Michael Sandberg’s blog discusses a wide variety of data visualization examples link (Bureau, n.d.) This resource is a data visualization gallery of weekly explorations of United States Census data link (Agency 2018) This resource provides a series of interactive data visualizations using FEMA data link (Marr 2017) This article describes “The 7 Best Data Visualization Tools In 2017” link (Tableau Software 2018b) This is Tableau social media groups on LinkedIn link (Lazarevich 2018a) | This article discusses how data visualization can impact business strategy | link (McCeady 2017) | This article discusses how writers can use data visualizations to manipulate their audiences | link References "],
["references-1.html", "References", " References "]
]
